{"title":"Hacker News","items":[{"id":"http://npmjs.com/package/ezff","title":"Show HN: Ez FFmpeg – Video editing in plain English","link":"http://npmjs.com/package/ezff","hnCommentsUrl":"https://news.ycombinator.com/item?id=46400251","content":"<a href=\"https://news.ycombinator.com/item?id=46400251\">Comments</a>","date":1766825146000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://react-networks-lib.rackout.net/fibre","title":"Splice a Fibre","link":"https://react-networks-lib.rackout.net/fibre","hnCommentsUrl":"https://news.ycombinator.com/item?id=46401190","content":"<a href=\"https://news.ycombinator.com/item?id=46401190\">Comments</a>","date":1766836637000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://nesbitt.io/2025/12/25/cursed-bundler-using-go-get-to-install-ruby-gems.html","title":"Cursed Bundler: Using go get to install Ruby Gems","link":"https://nesbitt.io/2025/12/25/cursed-bundler-using-go-get-to-install-ruby-gems.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46400927","content":"<a href=\"https://news.ycombinator.com/item?id=46400927\">Comments</a>","date":1766833546000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div itemprop=\"articleBody\"> <p>Here’s a thought experiment. What if Ruby had <code>require \"github.com/rails/rails\"</code> and you used <code>go get</code> to fetch it? Set GOPATH to a Ruby load path, and Go’s module fetcher becomes your transport layer. The Go team did not intend this. But it works. Consider this a gift from the Ghost of Package Managers Yet to Come.</p> <p>The setup would look something like this:</p> <div><pre><code>export GOPATH=/usr/local/lib/ruby/vendor_gems go get github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"790b181a12390f4a57485741\">[email&nbsp;protected]</a> </code></pre></div> <p>Go fetches the module, and now you have:</p> <div><pre><code>/usr/local/lib/ruby/vendor_gems/pkg/mod/ github.com/ rack/ <a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"344655575f7442071a051a0c\">[email&nbsp;protected]</a>/ lib/ rack.rb rack/ request.rb response.rb ... </code></pre></div> <p>Build your load path from the lockfile:</p> <div><pre><code>RUBYLIB=/usr/local/lib/ruby/vendor_gems/pkg/mod/github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"770516141c3701445946594f\">[email&nbsp;protected]</a>/lib </code></pre></div> <p>Now <code>require \"rack\"</code> just works. Ruby doesn’t care how the files got there. The version resolution happened once, when you built the load path. And because each version lives in its own directory on disk, multiple versions coexist without conflict. Go’s filesystem layout handles what Ruby’s load path never did gracefully.</p> <h3 id=\"self-describing-paths\">Self-describing paths</h3> <p>Go’s import path convention makes this possible. When you write <code>import \"github.com/foo/bar\"</code>, Go doesn’t look up “bar” in some central index. The path itself contains everything needed to find the code: the hosting domain, the org, the repo. It’s self-describing. Compare this to <code>gem install foo</code>, where “foo” is a magic string that only means something if you know to ask <a href=\"https://rubygems.org/\">rubygems.org</a>. Without the registry, “foo” is just noise.</p> <p>This decentralisation is unusual in package management. Most systems work the other way: short names resolve through a central index. npm’s <code>lodash</code> is meaningless without npmjs.com. PyPI’s <code>requests</code> is meaningless without pypi.org. Central indexes come with social costs too: governance, trust, gatekeeping, decisions about who gets to publish what. Go’s approach embeds the registry into the import path itself. You can host your own modules anywhere, and the path tells clients exactly where to find them.</p> <h3 id=\"the-proxy-and-the-sumdb\">The proxy and the sumdb</h3> <p>Now here’s where it gets interesting. Go doesn’t just fetch code from GitHub directly. It goes through <a href=\"https://proxy.golang.org/\">proxy.golang.org</a>, a caching proxy run by Google that mirrors every public Go module. And every module version gets an entry in <a href=\"https://sum.golang.org/\">sum.golang.org</a>, a transparency log that records cryptographic hashes of module contents. First fetch wins: once a hash is logged, it’s permanent. This matters because a compromised maintainer can’t silently replace a version. If they try, the hash won’t match and every Go client will refuse the download. Anyone can audit the log for tampering. The security properties are genuinely good.</p> <p>When you run <code>go get github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"403221232b0036736e716e78\">[email&nbsp;protected]</a></code>, here’s what actually happens:</p> <div><pre><code>1. Ask proxy.golang.org for github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"dfadbebcb49fa9ecf1eef1e7\">[email&nbsp;protected]</a> 2. Proxy checks its cache, or fetches from GitHub 3. Proxy returns a zip file of the module contents 4. Go computes SHA-256 hash of the zip 5. Ask sum.golang.org: \"what's the hash for this module?\" 6. If first fetch ever: sumdb records the hash permanently 7. If seen before: verify hash matches the logged one 8. Unzip to $GOPATH/pkg/mod/github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"7d0f1c1e163d0b4e534c5345\">[email&nbsp;protected]</a>/ </code></pre></div> <p>Your Ruby gem just got the same integrity guarantees as a Go module. The hash is in a Merkle tree. It’s auditable. It’s permanent.</p> <p>What does the proxy actually check? Not much. It would like a go.mod file in the repo, but versions come from git tags. The go.mod doesn’t even need to be valid Go. Run <code>go mod init github.com/you/your-gem</code> in your Ruby project, push, and you’re done. The sumdb hashes whatever zip file it receives. It doesn’t parse Go code. It doesn’t verify that the module contains valid Go packages. It just slurps up the zip and logs the hash.</p> <p>People already abuse this. You’ll find protobuf definitions hosted as Go modules, with no Go code at all. JSON schemas. Terraform modules. Random data files. As long as there’s a go.mod at the root, proxy.golang.org will cache it and sum.golang.org will log it. The Go infrastructure doesn’t care what’s inside.</p> <p>So: put a go.mod in your Ruby gem’s repo. Push a tag. Run <code>go get</code>. Your gem is now cached forever in Google’s infrastructure, with a cryptographic hash in a tamper-evident transparency log. You’ve achieved better supply chain integrity than actual RubyGems by pretending your gems are Go modules. RubyGems doesn’t have a transparency log. sum.golang.org does. And you’ve quietly sidestepped rubygems.org entirely.</p> <p>To make this a real package manager, you’d need recursion. Parse the gemspec, find dependencies, <code>go get</code> those too. You’re one SAT solver away from reinventing <a href=\"https://bundler.io/\">Bundler</a> with Go as the transport layer. The dependency resolution logic doesn’t change. Only the fetching does.</p> <div><pre><code># Hypothetical go-bundler 1. go get github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"f48695979fb482c7dac5dacc\">[email&nbsp;protected]</a> 2. Parse rack.gemspec, find: depends on \"github.com/rack/rack-session\" 3. go get github.com/rack/<a href=\"https://nesbitt.io/cdn-cgi/l/email-protection\" data-cfemail=\"394b585a52144a5c4a4a505657794f0b17081709\">[email&nbsp;protected]</a> 4. Parse rack-session.gemspec, find: depends on \"github.com/rack/rack\" 5. Already have rack, skip 6. Write go.sum (it's a lockfile now) </code></pre></div> <p>The dependency graph is the same graph Bundler would compute. You’ve just outsourced the fetching and integrity checking to Google.</p> <p>One difference: Go uses <a href=\"https://research.swtch.com/vgo-mvs\">Minimal Version Selection</a>. If you require v1.2.0, you get v1.2.0, not the latest. This makes go.sum almost an afterthought. Bundler and most package managers prefer the newest matching version, which means <a href=\"https://bundler.io/guides/rationale.html\">Gemfile.lock</a> is load-bearing. Without it, you get whatever’s latest today, which might not be what you tested against yesterday. Go’s approach trades “always up to date” for “boringly predictable.” If you actually built this, you might find yourself adopting MVS too. It’s simpler than SAT solving and doesn’t need backtracking. Faster, more deterministic, but more restrictive.</p> <p>There are some cursed details. Go has case-folding escapes because macOS and Windows treat <code>A</code> and <code>a</code> as the same file. A repo named <code>BurntSushi/toml</code> becomes <code>!burnt!sushi/toml</code> on disk. If you’re building Ruby tooling on top of this, you inherit Go’s filesystem workarounds whether you want them or not. Your <code>require</code> statements would get weird.</p> <p>Native extensions are where this falls apart. Go expects source or pre-compiled binaries. Ruby gems often need to run <code>make</code> to compile C code. Pure Ruby gems work fine; anything with native code doesn’t.</p> <h3 id=\"trade-offs\">Trade-offs</h3> <p>Why hasn’t anyone done this for real? Partly because it’s absurd. But also because the Go import style has real trade-offs, and most language communities decided they weren’t worth it.</p> <p>Deno tried URL imports. <code>import { serve } from \"https://deno.land/std/http/server.ts\"</code> looks a lot like Go imports. It has the same self-describing property: the URL tells you exactly where the code lives. No central registry required. It also has the same problems: verbose paths, no human-friendly short names, squatting is hard because you’d need to squat the domain. Deno eventually <a href=\"https://deno.com/blog/http-imports\">retreated to JSR</a>, a more traditional registry with short names.</p> <p>The trade-offs stack up differently depending on what you value:</p> <p>Self-describing paths mean no registry lookup, but they’re long and ugly. <code>require \"github.com/rails/rails\"</code> is worse than <code>require \"rails\"</code> if you’re typing it by hand. Decentralisation means no single point of failure, but also no single point of governance. Who removes malware from GitHub? Central registries can act on abuse reports. Git hosting is a different trust model.</p> <p>Short names are ergonomic but enable squatting. Anyone can register <code>request</code> on npm and hope you typo <code>requests</code>. Domain-based paths are squatting-resistant because you’d need to actually control the domain. But they’re verbose, and nobody wants to type <code>require \"github.com/psf/requests\"</code> in every Python file.</p> <p>Go’s approach works for Go because Go chose it from the start and the community built around it. Retrofitting it onto Ruby or Python or JavaScript would require changing how everyone writes import statements. The tooling works. The migration doesn’t.</p> <p>Still, the underlying idea is sound. What if every package manager shared a content-addressed, transparency-logged, globally-cached distribution layer? You wouldn’t need to pretend your gems are Go modules. You’d just have the same infrastructure available natively. The costs of running a reliable package CDN are substantial.</p> <p>In the meantime, Go’s module system sits there, accidentally universal, logging hashes of whatever you throw at it. The FOSDEM talk writes itself: “We achieved cryptographic supply chain integrity for Ruby by pretending all gems were Go modules. The Go team was confused about why their sumdb was full of .rb files.”</p> <p>Nobody should actually do this. I couldn’t resist anyway: <a href=\"https://github.com/andrew/go-bundler\">go-bundler</a> is a proof of concept. But it reveals something interesting about package management design.</p> <p>This thought experiment is part of a larger question I’ve been exploring: <a href=\"https://nesbitt.io/2025/12/02/what-is-a-package-manager/\">what are the fundamental components of a package manager</a>, and which ones could be shared across ecosystems? Most people think of package managers as monolithic, but they’re really several systems bolted together:</p> <ul> <li><strong>Naming</strong> - how you refer to packages</li> <li><strong>Discovery</strong> - finding what exists</li> <li><strong>Resolution</strong> - solving the version constraint problem</li> <li><strong>Transport</strong> - fetching bits</li> <li><strong>Integrity</strong> - verifying you got what you expected</li> <li><strong>Installation</strong> - putting files where they need to go</li> </ul> <p>Go made unusual choices at naming, transport, and integrity that happen to be language-agnostic. That’s what makes the Ruby hack possible. It hints at infrastructure we maybe should have built intentionally. Go built an anonymous, transparency-logged package proxy with minimal governance, then let anyone use it for free.</p> <p>Somewhere in Mountain View, a Go module proxy is serving a zip file full of Ruby code, hashing it into a Merkle tree, and wondering what it did to deserve this.</p> </div>"},{"id":"https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html","title":"How uv got so fast","link":"https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46393992","content":"<a href=\"https://news.ycombinator.com/item?id=46393992\">Comments</a>","date":1766769187000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div itemprop=\"articleBody\"> <p>uv installs packages faster than pip by an order of magnitude. The usual explanation is “it’s written in Rust.” That’s true, but it doesn’t explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.</p> <p>Charlie Marsh’s <a href=\"https://www.janestreet.com/tech-talks/uv-an-extremely-fast-python-package-manager/\">Jane Street talk</a> and a <a href=\"https://xebia.com/blog/uv-the-engineering-secrets-behind-pythons-speed-king/\">Xebia engineering deep-dive</a> cover the technical details well. The interesting parts are the design decisions: standards that enable fast paths, things uv drops that pip supports, and optimizations that don’t require Rust at all.</p> <h2 id=\"the-standards-that-made-uv-possible\">The standards that made uv possible</h2> <p>pip’s slowness isn’t a failure of implementation. For years, Python packaging required executing code to find out what a package needed.</p> <p>The problem was <a href=\"https://setuptools.pypa.io/\">setup.py</a>. You couldn’t know a package’s dependencies without running its setup script. But you couldn’t run its setup script without installing its build dependencies. <a href=\"https://peps.python.org/pep-0518/\">PEP 518</a> in 2016 called this out explicitly: “You can’t execute a setup.py file without knowing its dependencies, but currently there is no standard way to know what those dependencies are in an automated fashion without executing the setup.py file.”</p> <p>This chicken-and-egg problem forced pip to download packages, execute untrusted code, fail, install missing build tools, and try again. Every install was potentially a cascade of subprocess spawns and arbitrary code execution. Installing a source distribution was essentially <code>curl | bash</code> with extra steps.</p> <p>The fix came in stages:</p> <ul> <li><a href=\"https://peps.python.org/pep-0518/\">PEP 518</a> (2016) created pyproject.toml, giving packages a place to declare build dependencies without code execution. The TOML format was borrowed from Rust’s Cargo, which makes a Rust tool returning to fix Python packaging feel less like coincidence.</li> <li><a href=\"https://peps.python.org/pep-0517/\">PEP 517</a> (2017) separated build frontends from backends, so pip didn’t need to understand setuptools internals.</li> <li><a href=\"https://peps.python.org/pep-0621/\">PEP 621</a> (2020) standardized the <code>[project]</code> table, so dependencies could be read by parsing TOML rather than running Python.</li> <li><a href=\"https://peps.python.org/pep-0658/\">PEP 658</a> (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.</li> </ul> <p>PEP 658 went live on PyPI in May 2023. uv launched in February 2024. uv could be fast because the ecosystem finally had the infrastructure to support it. A tool like uv couldn’t have shipped in 2020. The standards weren’t there yet.</p> <p>Other ecosystems figured this out earlier. Cargo has had static metadata from the start. npm’s package.json is declarative. Python’s packaging standards finally bring it to parity.</p> <h2 id=\"what-uv-drops\">What uv drops</h2> <p>Speed comes from elimination. Every code path you don’t have is a code path you don’t wait for.</p> <p>uv’s <a href=\"https://docs.astral.sh/uv/pip/compatibility/\">compatibility documentation</a> is a list of things it doesn’t do:</p> <p><strong>No .egg support.</strong> Eggs were the pre-wheel binary format. pip still handles them; uv doesn’t even try. The format has been obsolete for over a decade.</p> <p><strong>No pip.conf.</strong> uv ignores pip’s configuration files entirely. No parsing, no environment variable lookups, no inheritance from system-wide and per-user locations.</p> <p><strong>No bytecode compilation by default.</strong> pip compiles .py files to .pyc during installation. uv skips this step, shaving time off every install. You can opt in if you want it.</p> <p><strong>Virtual environments required.</strong> pip lets you install into system Python by default. uv inverts this, refusing to touch system Python without explicit flags. This removes a whole category of permission checks and safety code.</p> <p><strong>Stricter spec enforcement.</strong> pip accepts malformed packages that technically violate packaging specs. uv rejects them. Less tolerance means less fallback logic.</p> <p><strong>Ignoring requires-python upper bounds.</strong> When a package says it requires <code>python&lt;4.0</code>, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare <code>python&lt;4.0</code> because they haven’t tested on Python 4, not because they’ll actually break. The constraint is defensive, not predictive.</p> <p><strong>First-index wins by default.</strong> When multiple package indexes are configured, pip checks all of them. uv picks from the first index that has the package, stopping there. This prevents dependency confusion attacks and avoids extra network requests.</p> <p>Each of these is a code path pip has to execute and uv doesn’t.</p> <h2 id=\"optimizations-that-dont-need-rust\">Optimizations that don’t need Rust</h2> <p>Some of uv’s speed comes from Rust. But not as much as you’d think. Several key optimizations could be implemented in pip today:</p> <p><strong>HTTP range requests for metadata.</strong> <a href=\"https://packaging.python.org/en/latest/specifications/binary-distribution-format/\">Wheel files</a> are zip archives, and zip archives put their file listing at the end. uv tries PEP 658 metadata first, falls back to HTTP range requests for the zip central directory, then full wheel download, then building from source. Each step is slower and riskier. The design makes the fast path cover 99% of cases. None of this requires Rust.</p> <p><strong>Parallel downloads.</strong> pip downloads packages one at a time. uv downloads many at once. Any language can do this.</p> <p><strong>Global cache with hardlinks.</strong> pip copies packages into each virtual environment. uv keeps one copy globally and uses <a href=\"https://en.wikipedia.org/wiki/Hard_link\">hardlinks</a> (or copy-on-write on filesystems that support it). Installing the same package into ten venvs takes the same disk space as one. Any language with filesystem access can do this.</p> <p><strong>Python-free resolution.</strong> pip needs Python running to do anything, and invokes build backends as subprocesses to get metadata from legacy packages. uv parses TOML and wheel metadata natively, only spawning Python when it hits a setup.py-only package that has no other option.</p> <p><strong>PubGrub resolver.</strong> uv uses the <a href=\"https://github.com/dart-lang/pub/blob/master/doc/solver.md\">PubGrub algorithm</a>, originally from Dart’s pub package manager. Both pip and PubGrub use backtracking, but PubGrub applies conflict-driven clause learning from SAT solvers: when it hits a dead end, it analyzes why and skips similar dead ends later. This makes it faster on complex dependency graphs and better at explaining failures. pip could adopt PubGrub without rewriting in Rust.</p> <h2 id=\"where-rust-actually-matters\">Where Rust actually matters</h2> <p>Some optimizations do require Rust:</p> <p><strong>Zero-copy deserialization.</strong> uv uses <a href=\"https://rkyv.org/\">rkyv</a> to deserialize cached data without copying it. The data format is the in-memory format. Libraries like FlatBuffers achieve this in other languages, but rkyv integrates tightly with Rust’s type system.<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\" role=\"doc-noteref\">1</a></sup></p> <p><strong>Thread-level parallelism.</strong> Python’s GIL forces parallel work into separate processes, with IPC overhead and data copying. Rust can parallelize across threads natively, sharing memory without serialization boundaries. This matters most for resolution, where the solver explores many version combinations.<sup id=\"fnref:1:1\"><a href=\"#fn:1\" rel=\"footnote\" role=\"doc-noteref\">1</a></sup></p> <p><strong>No interpreter startup.</strong> Every time pip spawns a subprocess, it pays Python’s startup cost. uv is a single static binary with no runtime to initialize.</p> <p><strong>Compact version representation.</strong> uv packs versions into u64 integers where possible, making comparison and hashing fast. Over 90% of versions fit in one u64. This is micro-optimization that compounds across millions of comparisons.</p> <p>These are real advantages. But they’re smaller than the architectural wins from dropping legacy support and exploiting modern standards.</p> <h2 id=\"design-over-language\">Design over language</h2> <p>uv is fast because of what it doesn’t do, not because of what language it’s written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.</p> <p>pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesn’t, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.</p> <p>Other package managers could learn from this: static metadata, no code execution to discover dependencies, and the ability to resolve everything upfront before downloading. Cargo and npm have operated this way for years. If your ecosystem requires running arbitrary code to find out what a package needs, you’ve already lost.</p> </div>"},{"id":"https://github.com/mruby/mruby","title":"Mruby: Ruby for Embedded Systems","link":"https://github.com/mruby/mruby","hnCommentsUrl":"https://news.ycombinator.com/item?id=46351457","content":"<a href=\"https://news.ycombinator.com/item?id=46351457\">Comments</a>","date":1766379614000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div dir=\"auto\"> <h2 tabindex=\"-1\" dir=\"auto\">mruby</h2> <p><a href=\"https://github.com/marketplace/actions/super-linter\"> <img src=\"https://github.com/mruby/mruby/actions/workflows/super-linter.yml/badge.svg\" alt=\"GitHub Super-Linter\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p></div> <h3 tabindex=\"-1\" dir=\"auto\">Table of contents</h3> <ul dir=\"auto\"> <li><a href=\"#what-is-mruby\">What is mruby</a></li> <li><a href=\"#how-to-get-mruby\">How to get mruby</a></li> <li><a href=\"#mruby-homepage\">mruby homepage</a></li> <li><a href=\"#mailing-list\">Mailing list</a></li> <li><a href=\"#how-to-compile-test-and-install-mruby-and-gems\">How to compile, test, and install (mruby and gems)</a></li> <li><a href=\"#building-documentation\">Building documentation</a></li> <li><a href=\"#how-to-customize-mruby-mrbgems\">How to customize mruby (mrbgems)</a></li> <li><a href=\"#index-of-document\">Index of Document</a></li> <li><a href=\"#license\">License</a></li> <li><a href=\"#note-for-license\">Note for License</a></li> <li><a href=\"#how-to-contribute\">How to Contribute</a></li> <li><a href=\"#star-history\">Star History</a></li> <li><a href=\"#contributors\">Contributors</a></li> </ul> <h2 tabindex=\"-1\" dir=\"auto\">What is mruby</h2> <p dir=\"auto\">mruby is the lightweight implementation of the Ruby language complying to (part of) the <a href=\"https://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=59579\" rel=\"nofollow\">ISO standard</a> with more recent features provided by Ruby 3.x. Also, its syntax is Ruby 3.x compatible except for pattern matching.</p> <p dir=\"auto\">You can link and embed mruby within your application. The \"mruby\" interpreter program and the interactive \"mirb\" shell are provided as examples. You can also compile Ruby programs into compiled byte code using the \"mrbc\" compiler. All these tools are located in the \"bin\" directory. \"mrbc\" can also generate compiled byte code in a C source file. See the \"mrbtest\" program under the \"test\" directory for an example.</p> <p dir=\"auto\">This achievement was sponsored by the Regional Innovation Creation R&amp;D Programs of the Ministry of Economy, Trade and Industry of Japan.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to get mruby</h2> <p dir=\"auto\">To get mruby, you can download the stable version 3.4.0 from the official mruby GitHub repository or clone the trunk of the mruby source tree with the \"git clone\" command. You can also install and compile mruby using <a href=\"https://github.com/postmodern/ruby-install\">ruby-install</a>, <a href=\"https://github.com/rbenv/ruby-build\">ruby-build</a> or <a href=\"https://github.com/rvm/rvm\">rvm</a>.</p> <p dir=\"auto\">The latest development version of mruby can be downloaded via the following URL: <a href=\"https://github.com/mruby/mruby/zipball/master\">https://github.com/mruby/mruby/zipball/master</a></p> <p dir=\"auto\">The trunk of the mruby source tree can be checked out with the following command:</p> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"$ git clone https://github.com/mruby/mruby.git\"><pre>$ <span>git clone https://github.com/mruby/mruby.git</span></pre></div> <h2 tabindex=\"-1\" dir=\"auto\">mruby homepage</h2> <p dir=\"auto\">The URL of the mruby homepage is: <a href=\"https://mruby.org/\" rel=\"nofollow\">https://mruby.org</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">Mailing list</h2> <p dir=\"auto\">We don't have a mailing list, but you can use <a href=\"https://github.com/mruby/mruby/issues\">GitHub issues</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to compile, test, and install (mruby and gems)</h2> <p dir=\"auto\">For the simplest case, type</p> <p dir=\"auto\">See the <a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/compile.md\">compile.md</a> file for the detail.</p> <h2 tabindex=\"-1\" dir=\"auto\">Building documentation</h2> <p dir=\"auto\">There are two sets of documentation in mruby: the mruby API (generated by YARD) and C API (Doxygen and Graphviz)</p> <p dir=\"auto\">To build both of them, simply go</p> <p dir=\"auto\">You can also view them in your browser</p> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"rake view_api rake view_capi\"><pre><span>rake view_api</span> <span>rake view_capi</span></pre></div> <h2 tabindex=\"-1\" dir=\"auto\">How to customize mruby (mrbgems)</h2> <p dir=\"auto\">mruby contains a package manager called \"mrbgems\" that you can use to create extensions in C and/or Ruby. For a guide on how to use mrbgems, consult the <a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbgems.md\">mrbgems.md</a> file, and for example code, refer to the <a href=\"https://github.com/mruby/mruby/blob/master/examples/mrbgems\">examples/mrbgems/</a> folder.</p> <h2 tabindex=\"-1\" dir=\"auto\">Index of Document</h2> <ul dir=\"auto\"> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/limitations.md\">About the Limitations of mruby</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/compile.md\">About the Compile</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/debugger.md\">About the Debugger with the <code>mrdb</code> Command</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/gc-arena-howto.md\">About GC Arena</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/hier.md\">About the mruby directory structure</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/link.md\">About Linking with <code>libmruby</code></a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/memory.md\">About Memory Allocator Customization</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbconf.md\">About Build-time Configurations</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbgems.md\">About the Build-time Library Manager</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/symbol.md\">About the Symbols</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/internal/boxing.md\">Internal Implementation / About Value Boxing</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/internal/opcode.md\">Internal Implementation / About mruby Virtual Machine Instructions</a></li> </ul> <h2 tabindex=\"-1\" dir=\"auto\">License</h2> <p dir=\"auto\">mruby is released under the <a href=\"https://github.com/mruby/mruby/blob/master/LICENSE\">MIT License</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">Note for License</h2> <p dir=\"auto\">mruby has chosen a MIT License due to its permissive license allowing developers to target various environments such as embedded systems. However, the license requires the display of the copyright notice and license information in manuals for instance. Doing so for big projects can be complicated or troublesome. This is why mruby has decided to display \"mruby developers\" as the copyright name to make it simple conventionally. In the future, mruby might ask you to distribute your new code (that you will commit,) under the MIT License as a member of \"mruby developers\" but contributors will keep their copyright. (We did not intend for contributors to transfer or waive their copyrights, actual copyright holder name (contributors) will be listed in the <a href=\"https://github.com/mruby/mruby/blob/master/AUTHORS\">AUTHORS</a> file.)</p> <p dir=\"auto\">Please ask us if you want to distribute your code under another license.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to Contribute</h2> <p dir=\"auto\">To contribute to mruby, please refer to the <a href=\"https://github.com/mruby/mruby/blob/master/CONTRIBUTING.md\">contribution guidelines</a> and send a pull request to the <a href=\"https://github.com/mruby/mruby\">mruby GitHub repository</a>. By contributing, you grant non-exclusive rights to your code under the MIT License.</p> <h2 tabindex=\"-1\" dir=\"auto\">Star History</h2> <p dir=\"auto\"><a href=\"https://www.star-history.com/#mruby/mruby&amp;Date\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/07b61adb81bdd4c5be8855a65c3442f275d205fefbe4f2d8d8799d60f1430f87/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6d727562792f6d7275627926747970653d44617465\" alt=\"mruby Star History\" data-canonical-src=\"https://api.star-history.com/svg?repos=mruby/mruby&amp;type=Date\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p> <h2 tabindex=\"-1\" dir=\"auto\">Contributors</h2> <p dir=\"auto\"><a href=\"https://github.com/mruby/mruby/graphs/contributors\"><img src=\"https://camo.githubusercontent.com/80b09660539d28fdbd4eb5a6e82b4c867d51c3871b5df34ca2c2d6355385ede7/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6d727562792f6d7275627926616e6f6e3d31266d61783d353030\" alt=\"mruby Contributors\" data-canonical-src=\"https://contrib.rocks/image?repo=mruby/mruby&amp;anon=1&amp;max=500\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p>"},{"id":"https://intertapes.net/","title":"Intertapes – collection of found cassette tapes from different locations","link":"https://intertapes.net/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46345528","content":"<a href=\"https://news.ycombinator.com/item?id=46345528\">Comments</a>","date":1766330999000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://github.com/DeepMyst/Mysti","title":"Show HN: Mysti – Claude, Codex, and Gemini debate your code, then synthesize","link":"https://github.com/DeepMyst/Mysti","hnCommentsUrl":"https://news.ycombinator.com/item?id=46365105","content":"<a href=\"https://news.ycombinator.com/item?id=46365105\">Comments</a>","date":1766495912000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<h2 tabindex=\"-1\" dir=\"auto\">Mysti - Your AI Coding Team (Claude, Codex and Gemini) working together</h2> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/resources/Mysti-Logo.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/resources/Mysti-Logo.png\" alt=\"Mysti Logo\" width=\"128\" height=\"128\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/51bc9a555d405735fa23d3bcbb85ecb254ef5bfef034dbd2b04e3bff37eee06b/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f762f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d56657273696f6e\" alt=\"Version\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/v/DeepMyst.mysti?style=flat-square&amp;label=Version\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/4515efb079c925d6b40a39d33f18bb9bc85d32af3c3ec44f1d62e3137a706c23/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f692f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d496e7374616c6c73\" alt=\"Installs\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/i/DeepMyst.mysti?style=flat-square&amp;label=Installs\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/47b6437fc7cbe6138ae63013cc55fbc861b4889d6e27fd512148bb9097552155/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f722f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d526174696e67\" alt=\"Rating\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/r/DeepMyst.mysti?style=flat-square&amp;label=Rating\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://github.com/DeepMyst/Mysti/blob/main/LICENSE\"> <img src=\"https://camo.githubusercontent.com/cf54cf4f65e7cfd6fa294ec2149b4f9d78b2c38278169ab91fc7d05cdd986e45/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d42534c253230312e312d626c75653f7374796c653d666c61742d737175617265\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-BSL%201.1-blue?style=flat-square\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> <p dir=\"auto\"> <strong>Your AI Coding team for VSCode</strong><br> <em>Use Claude Code, Codex, or Gemini — or combine any two in Brainstorm Mode and never hit bottlenecks</em><br> <em>Wisdom of the crowd where the collective intelligence of several agents outperforms a single one.</em> </p> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/01fcc3f81de9302c4ac756a5e9210a53c956690903b11138d1a8a1fb1b8b5009/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f496e7374616c6c25323066726f6d2d5653253230436f64652532304d61726b6574706c6163652d3030374143433f7374796c653d666f722d7468652d6261646765266c6f676f3d76697375616c2d73747564696f2d636f6465\" alt=\"Install from VS Code Marketplace\" data-canonical-src=\"https://img.shields.io/badge/Install%20from-VS%20Code%20Marketplace-007ACC?style=for-the-badge&amp;logo=visual-studio-code\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> <p dir=\"auto\"> <a href=\"#choose-your-ai\">Providers</a> • <a href=\"#brainstorm-mode\">Brainstorm</a> • <a href=\"#key-features\">Features</a> • <a href=\"#quick-start\">Quick Start</a> • <a href=\"#configuration\">Config</a> </p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Install in Seconds</h2> <p dir=\"auto\"><strong>From VS Code:</strong> Press <code>Ctrl+P</code> (<code>Cmd+P</code> on Mac), then paste:</p> <div data-snippet-clipboard-copy-content=\"ext install DeepMyst.mysti\"><pre><code>ext install DeepMyst.mysti </code></pre></div> <p dir=\"auto\"><strong>Or</strong> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">install from the VS Code Marketplace</a></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Choose Your AI</h2> <p dir=\"auto\">Mysti works with the AI coding tools you already have. <strong>No extra subscriptions needed.</strong></p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/agent-selection.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/agent-selection.png\" alt=\"Agent Selection\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <markdown-accessiblity-table><table> <thead> <tr> <th>Provider</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>Claude Code</strong></td> <td>Deep reasoning, complex refactoring, thorough analysis</td> </tr> <tr> <td><strong>Codex</strong></td> <td>Quick iterations, familiar OpenAI style</td> </tr> <tr> <td><strong>Gemini</strong></td> <td>Fast responses, Google ecosystem integration</td> </tr> <tr> <td><strong>Brainstorm Mode</strong></td> <td>Any two AIs collaborate and debate solutions</td> </tr> </tbody> </table></markdown-accessiblity-table> <p dir=\"auto\"><strong>Switch providers with one click. No lock-in.</strong></p> <h3 tabindex=\"-1\" dir=\"auto\">Why Mysti?</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>vs Copilot/Cursor</th> <th>Mysti Advantage</th> </tr> </thead> <tbody> <tr> <td>Single AI</td> <td><strong>Multi-agent brainstorming</strong> — two AIs collaborate</td> </tr> <tr> <td>Locked to one provider</td> <td><strong>Use any CLI</strong> — Claude, Codex, or Gemini</td> </tr> <tr> <td>Black box</td> <td><strong>Full permission control</strong> — read-only to full-access</td> </tr> <tr> <td>Generic responses</td> <td><strong>16 personas</strong> — architect, debugger, security expert...</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">See It In Action</h2> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/user-experience.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/user-experience.png\" alt=\"Mysti Chat Interface\" width=\"700\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"><em>Beautiful, modern chat interface with syntax highlighting, markdown support, and mermaid diagrams</em></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Brainstorm Mode</h2> <p dir=\"auto\"><strong>Want a second opinion?</strong> Enable Brainstorm Mode and let two AI agents tackle your problem together. <strong>Choose any 2 of 3 agents</strong> (Claude, Codex, or Gemini) from the settings panel.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/brainstorm-mode.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/brainstorm-mode.png\" alt=\"Brainstorm Mode\" width=\"700\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <h3 tabindex=\"-1\" dir=\"auto\">Why Two AIs Beat One</h3> <p dir=\"auto\"><strong>Claude Code</strong> (Anthropic), <strong>Codex</strong> (OpenAI), and <strong>Gemini</strong> (Google) have different training, different strengths, and different blind spots. When any two work together:</p> <ul dir=\"auto\"> <li>Each AI catches edge cases the other might miss</li> <li>Different perspectives lead to more robust solutions</li> <li><strong>Together</strong> they debate, challenge each other, and synthesize the best solution</li> </ul> <p dir=\"auto\">It's like having a senior dev and a tech lead review your code—except they actually discuss it first.</p> <h3 tabindex=\"-1\" dir=\"auto\">Choose Your Team</h3> <p dir=\"auto\">Configure which two agents collaborate in the <strong>Settings Panel</strong>:</p> <markdown-accessiblity-table><table> <thead> <tr> <th>Combination</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td>Claude + Codex</td> <td>Deep analysis meets rapid iteration</td> </tr> <tr> <td>Claude + Gemini</td> <td>Thorough reasoning with fast validation</td> </tr> <tr> <td>Codex + Gemini</td> <td>Quick iterations with Google ecosystem knowledge</td> </tr> </tbody> </table></markdown-accessiblity-table> <h3 tabindex=\"-1\" dir=\"auto\">How It Works</h3> <div data-snippet-clipboard-copy-content=\"Your Request | v +-----------+-----------+ | Agent 1 | Agent 2 | | analyzes | analyzes | +-----+-----+-----+-----+ | | v v +---------------------------+ | Discussion (Full Mode) | | Agents review each other's| | solutions and debate | +-----------+---------------+ | v +---------------------------+ | Synthesis | | Best ideas combined into | | one refined solution | +---------------------------+\"><pre><code>Your Request | v +-----------+-----------+ | Agent 1 | Agent 2 | | analyzes | analyzes | +-----+-----+-----+-----+ | | v v +---------------------------+ | Discussion (Full Mode) | | Agents review each other's| | solutions and debate | +-----------+---------------+ | v +---------------------------+ | Synthesis | | Best ideas combined into | | one refined solution | +---------------------------+ </code></pre></div> <h3 tabindex=\"-1\" dir=\"auto\">Two Collaboration Modes</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>Quick Mode</th> <th>Full Mode</th> </tr> </thead> <tbody> <tr> <td>Direct synthesis</td> <td>Agents discuss first</td> </tr> <tr> <td>Both agents respond, then merge</td> <td>Each AI critiques the other's solution</td> </tr> <tr> <td>Faster results</td> <td>More thorough analysis</td> </tr> <tr> <td>Good for simple tasks</td> <td>Best for complex architecture decisions</td> </tr> </tbody> </table></markdown-accessiblity-table> <h3 tabindex=\"-1\" dir=\"auto\">Intelligent Plan Detection</h3> <p dir=\"auto\">When the AI presents multiple implementation approaches, Mysti automatically detects them and lets you choose your preferred path.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/plan-suggestions.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/plan-suggestions.png\" alt=\"Plan Suggestions\" width=\"600\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"><em>Requires at least 2 CLI tools installed. See <a href=\"#requirements\">Requirements</a>.</em></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Key Features</h2> <h3 tabindex=\"-1\" dir=\"auto\">16 Developer Personas</h3> <p dir=\"auto\">Shape how your AI thinks. Select from specialized personas that change the AI's approach to your problems.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/persona-skills-panel.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/persona-skills-panel.png\" alt=\"Personas and Skills Panel\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <markdown-accessiblity-table><table> <thead> <tr> <th>Persona</th> <th>Focus</th> </tr> </thead> <tbody> <tr> <td><strong>Architect</strong></td> <td>System design, scalability, clean structure</td> </tr> <tr> <td><strong>Debugger</strong></td> <td>Root cause analysis, bug fixing</td> </tr> <tr> <td><strong>Security-Minded</strong></td> <td>Vulnerabilities, threat modeling</td> </tr> <tr> <td><strong>Performance Tuner</strong></td> <td>Optimization, profiling, latency</td> </tr> <tr> <td><strong>Prototyper</strong></td> <td>Quick iteration, PoCs</td> </tr> <tr> <td><strong>Refactorer</strong></td> <td>Code quality, maintainability</td> </tr> <tr> <td>+ 10 more...</td> <td>Full-Stack, DevOps, Mentor, Designer...</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Quick Persona Selection</h3> <p dir=\"auto\">Select personas directly from the toolbar without opening panels.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/persona-toolbar.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/persona-toolbar.png\" alt=\"Toolbar Persona Selection\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Smart Auto-Suggestions</h3> <p dir=\"auto\">Mysti automatically suggests relevant personas and actions based on your message.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/auto-suggestions.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/auto-suggestions.png\" alt=\"Auto Suggestions\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Conversation History</h3> <p dir=\"auto\">Never lose your work. All conversations are saved and easily accessible.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/conversation-history.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/conversation-history.png\" alt=\"Conversation History\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Quick Actions on Welcome</h3> <p dir=\"auto\">Get started fast with one-click actions for common tasks.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/quick-actions-welcome.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/quick-actions-welcome.png\" alt=\"Quick Actions\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Extensive Settings</h3> <p dir=\"auto\">Fine-tune every aspect of Mysti including token budgets, access levels, and brainstorm mode.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/settings-panel.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/settings-panel.png\" alt=\"Settings Panel\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Requirements</h2> <p dir=\"auto\"><strong>Already paying for Claude, ChatGPT, or Gemini? You're ready to go.</strong></p> <p dir=\"auto\">Mysti works with your existing subscriptions—no additional costs!</p> <markdown-accessiblity-table><table> <thead> <tr> <th>CLI Tool</th> <th>Subscription</th> <th>Install</th> </tr> </thead> <tbody> <tr> <td><strong>Claude Code</strong> (recommended)</td> <td>Anthropic API or Claude Pro/Max</td> <td><code>npm install -g @anthropic-ai/claude-code</code></td> </tr> <tr> <td><strong>Codex CLI</strong></td> <td>OpenAI API</td> <td>Follow OpenAI's installation guide</td> </tr> <tr> <td><strong>Gemini CLI</strong></td> <td>Google AI API or Gemini Advanced</td> <td><code>npm install -g @google/gemini-cli</code></td> </tr> </tbody> </table></markdown-accessiblity-table> <p dir=\"auto\">You only need <strong>one</strong> CLI to get started. Install <strong>any two</strong> to unlock Brainstorm Mode.</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Quick Start</h2> <h3 tabindex=\"-1\" dir=\"auto\">1. Install Mysti</h3> <p dir=\"auto\"><strong>Option A:</strong> Press <code>Ctrl+P</code> (<code>Cmd+P</code> on Mac), paste and run:</p> <div data-snippet-clipboard-copy-content=\"ext install DeepMyst.mysti\"><pre><code>ext install DeepMyst.mysti </code></pre></div> <p dir=\"auto\"><strong>Option B:</strong> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">Install from VS Code Marketplace</a></p> <h3 tabindex=\"-1\" dir=\"auto\">2. Install a CLI Tool</h3> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"# Claude Code (recommended) npm install -g @anthropic-ai/claude-code claude auth login # Or Gemini CLI npm install -g @google/gemini-cli gemini auth login\"><pre><span><span>#</span> Claude Code (recommended)</span> npm install -g @anthropic-ai/claude-code claude auth login <span><span>#</span> Or Gemini CLI</span> npm install -g @google/gemini-cli gemini auth login</pre></div> <p dir=\"auto\">For Brainstorm Mode, install any two CLI tools.</p> <h3 tabindex=\"-1\" dir=\"auto\">3. Open Mysti</h3> <ul dir=\"auto\"> <li>Click the <strong>Mysti icon</strong> in the Activity Bar, or</li> <li>Press <code>Ctrl+Shift+M</code> (<code>Cmd+Shift+M</code> on Mac)</li> </ul> <h3 tabindex=\"-1\" dir=\"auto\">4. Start Coding</h3> <p dir=\"auto\">Type your request and let the AI assist you!</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">12 Toggleable Skills</h2> <p dir=\"auto\">Mix and match behavioral modifiers:</p> <ul dir=\"auto\"> <li><strong>Concise</strong> - Clear, brief communication</li> <li><strong>Test-Driven</strong> - Tests alongside code</li> <li><strong>Auto-Commit</strong> - Incremental commits</li> <li><strong>First Principles</strong> - Fundamental reasoning</li> <li><strong>Scope Discipline</strong> - Stay focused on the task</li> <li>And 7 more...</li> </ul> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Permission Controls</h2> <p dir=\"auto\">Stay in control of what the AI can do:</p> <ul dir=\"auto\"> <li><strong>Read-only</strong> - AI can only read, never modify</li> <li><strong>Ask-permission</strong> - Approve each file change</li> <li><strong>Full-access</strong> - Let the AI work autonomously</li> </ul> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Configuration</h2> <h3 tabindex=\"-1\" dir=\"auto\">Essential Settings</h3> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"{ &quot;mysti.defaultProvider&quot;: &quot;claude-code&quot;, &quot;mysti.brainstorm.agents&quot;: [&quot;claude-code&quot;, &quot;google-gemini&quot;], &quot;mysti.brainstorm.discussionMode&quot;: &quot;full&quot;, &quot;mysti.accessLevel&quot;: &quot;ask-permission&quot; }\"><pre>{ <span>\"mysti.defaultProvider\"</span>: <span><span>\"</span>claude-code<span>\"</span></span>, <span>\"mysti.brainstorm.agents\"</span>: [<span><span>\"</span>claude-code<span>\"</span></span>, <span><span>\"</span>google-gemini<span>\"</span></span>], <span>\"mysti.brainstorm.discussionMode\"</span>: <span><span>\"</span>full<span>\"</span></span>, <span>\"mysti.accessLevel\"</span>: <span><span>\"</span>ask-permission<span>\"</span></span> }</pre></div> <h3 tabindex=\"-1\" dir=\"auto\">All Settings</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>Setting</th> <th>Default</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>mysti.defaultProvider</code></td> <td><code>claude-code</code></td> <td>Primary AI provider (<code>claude-code</code>, <code>openai-codex</code>, <code>google-gemini</code>)</td> </tr> <tr> <td><code>mysti.brainstorm.agents</code></td> <td><code>[\"claude-code\", \"openai-codex\"]</code></td> <td>Which 2 agents to use in brainstorm mode</td> </tr> <tr> <td><code>mysti.brainstorm.discussionMode</code></td> <td><code>quick</code></td> <td><code>quick</code> or <code>full</code></td> </tr> <tr> <td><code>mysti.accessLevel</code></td> <td><code>ask-permission</code></td> <td>File access level</td> </tr> <tr> <td><code>mysti.agents.autoSuggest</code></td> <td><code>true</code></td> <td>Auto-suggest personas</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Keyboard Shortcuts</h2> <markdown-accessiblity-table><table> <thead> <tr> <th>Action</th> <th>Windows/Linux</th> <th>Mac</th> </tr> </thead> <tbody> <tr> <td>Open Mysti</td> <td><code>Ctrl+Shift+M</code></td> <td><code>Cmd+Shift+M</code></td> </tr> <tr> <td>Open in New Tab</td> <td><code>Ctrl+Shift+N</code></td> <td><code>Cmd+Shift+N</code></td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Commands</h2> <markdown-accessiblity-table><table> <thead> <tr> <th>Command</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>Mysti: Open Chat</code></td> <td>Open the chat sidebar</td> </tr> <tr> <td><code>Mysti: New Conversation</code></td> <td>Start fresh</td> </tr> <tr> <td><code>Mysti: Add to Context</code></td> <td>Add file/selection to context</td> </tr> <tr> <td><code>Mysti: Clear Context</code></td> <td>Clear all context</td> </tr> <tr> <td><code>Mysti: Open in New Tab</code></td> <td>Open chat as editor tab</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Telemetry</h2> <p dir=\"auto\">Mysti collects <strong>anonymous</strong> usage data to improve the extension:</p> <ul dir=\"auto\"> <li>Feature usage patterns</li> <li>Error rates</li> <li>Provider preferences</li> </ul> <p dir=\"auto\"><strong>No code, file paths, or personal data is ever collected.</strong></p> <p dir=\"auto\">Respects VSCode's telemetry setting. Disable via: Settings &gt; Telemetry: Telemetry Level &gt; off</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">License</h2> <p dir=\"auto\"><strong>Business Source License 1.1 (BSL 1.1)</strong></p> <ul dir=\"auto\"> <li><strong>Free</strong> for personal, educational, and non-profit use</li> <li><strong>Commercial use</strong> requires a separate license</li> <li>Converts to <strong>MIT License</strong> on December 3, 2030</li> </ul> <p dir=\"auto\">Contact <a href=\"mailto:baha@deepmyst.com\">baha@deepmyst.com</a> for commercial licensing.</p> <hr> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">Install</a> • <a href=\"https://github.com/DeepMyst/Mysti/issues\">Report Issue</a> • <a href=\"https://github.com/DeepMyst/Mysti\">GitHub</a> </p> <p dir=\"auto\"> <strong>Mysti</strong> — Built by <a href=\"https://deepmyst.com/\" rel=\"nofollow\">DeepMyst Inc</a><br> <sub>Made with Mysti/sub&gt; </sub></p>"},{"id":"https://github.com/James-Hanson/junk-theorems-in-lean","title":"Some Junk Theorems in Lean","link":"https://github.com/James-Hanson/junk-theorems-in-lean","hnCommentsUrl":"https://news.ycombinator.com/item?id=46364567","content":"<a href=\"https://news.ycombinator.com/item?id=46364567\">Comments</a>","date":1766490799000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<h2 tabindex=\"-1\" dir=\"auto\">Some Junk Theorems in Lean</h2> <p dir=\"auto\">This is a small collection of formally verified junk theorems provable in Lean 4 + Mathlib that, in my experience, are quite surprising and upsetting to mathematicians who are not familiar with type theory (and in the case of Theorems 13 and 14, also to mathematicians who are familiar with type theory). <a href=\"https://github.com/James-Hanson/junk-theorems-in-lean/blob/main/JunkTheorems.lean\">See the main .lean file here.</a></p> <h3 tabindex=\"-1\" dir=\"auto\">Coding</h3> <blockquote> <p dir=\"auto\"><strong>Theorem 1.</strong> <em>The third coordinate of the rational number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\frac{1}{2}$</math-renderer> is a bijection.</em></p> </blockquote> <blockquote> <p dir=\"auto\"><strong>Theorem 2.</strong> <em>The first coordinate of the polynomial <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$X^2(X^3 + X + 1)$</math-renderer> is equal to the prime factorization of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$30$</math-renderer>.</em></p> </blockquote> <blockquote> <p dir=\"auto\"><strong>Theorem 3.</strong> <em>Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> be the multivariate polynomial <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$(X_0 + X_1 + X_2)^3$</math-renderer>. Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$Q$</math-renderer> be the univariate polynomial <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$X^2 + X + 1$</math-renderer>. The second coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> applied to the first coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$Q$</math-renderer> is equal to the natural number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$6$</math-renderer>.</em></p> </blockquote> <h3 tabindex=\"-1\" dir=\"auto\">Sets and Logic</h3> <blockquote> <p dir=\"auto\"><strong>Theorem 4.</strong> <em>The set <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\{z : \\mathbb{R} | z \\neq 0\\}$</math-renderer> is a continuous, non-monotone surjection.</em></p> </blockquote> <blockquote> <p dir=\"auto\"><strong>Theorem 5.</strong> <em>The Riemann hypothesis is in the topological closure of the set not not.</em></p> </blockquote> <p dir=\"auto\">Note though that showing that the Riemann hypothesis is in the topological closure of not will win you a million dollars.</p> <blockquote> <p dir=\"auto\"><strong>Theorem 6.</strong> <em>The following are equivalent: The binary expansion of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$7$</math-renderer>.</em></p> </blockquote> <blockquote> <p dir=\"auto\"><strong>Theorem 7.</strong> <em>The dot product of not with itself. Moreover, the matrix determinant of or. However, not the determinant of and.</em></p> </blockquote> <blockquote> <p dir=\"auto\"><strong>Theorem 8.</strong> <em>The existential quantifier on the category of groups is a non-measurable set.</em></p> </blockquote> <h3 tabindex=\"-1\" dir=\"auto\">Partiality</h3> <p dir=\"auto\">Famously, Lean, like many proof assistants, defines division so that <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\frac{1}{0} = 0$</math-renderer> and subtraction on the natural numbers so that <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2 - 3 = 0$</math-renderer>. In the first case, this leads to the following theorem (which is already in Mathlib).</p> <blockquote> <p dir=\"auto\"><strong>Theorem 9.</strong> (<a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/NumberTheory/Harmonic/ZetaAsymp.html#riemannZeta_one\" rel=\"nofollow\"><code>riemannZeta_one</code></a>) <em><math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\zeta(1) = \\frac{1}{2}(\\gamma - \\log 4 \\pi)$</math-renderer>, where <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\zeta(s)$</math-renderer> is the Riemann zeta function.</em></p> </blockquote> <p dir=\"auto\">If we try to avoid the junk theorem <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2 - 3 = 0$</math-renderer> with the partial subtraction function <code>psub</code>, we get the following.</p> <blockquote> <p dir=\"auto\"><strong>Theorem 10.</strong> <em>Two minus three, where subtraction is understood to be a partial function on <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathbb{N}$</math-renderer>, is equal to the extended natural number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$+\\infty$</math-renderer>.</em></p> </blockquote> <h3 tabindex=\"-1\" dir=\"auto\">Equality</h3> <p dir=\"auto\">In this next theorem, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathsf{QR}$</math-renderer> stands for quadratic reciprocity and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathsf{BCT}$</math-renderer> stands for the Baire category theorem.</p> <blockquote> <p dir=\"auto\"><strong>Theorem 11.</strong> <em>Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$p$</math-renderer> be the unique proof of quadratic reciprocity, and let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$q$</math-renderer> be the unique proof that the Baire category theorem isn't false. The pair <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\mathsf{QR},p\\rangle$</math-renderer> is equal to the pair <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle\\neg\\neg\\mathsf{BCT},q\\rangle$</math-renderer> (in the sense of pointed types). Moreover, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$q$</math-renderer> is a bijection.</em></p> </blockquote> <p dir=\"auto\">However, one cannot even form the sentence 'The unique proof of quadratic reciprocity is a bijection.' in Lean, because this would be as nonsensical as the sentence 'The natural number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2$</math-renderer> is a bijection.'</p> <p dir=\"auto\">Similarly, we can build an element <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$r$</math-renderer> of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathbb{Q}$</math-renderer> and a polynomial <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> with coefficients in <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathbb{N}$</math-renderer>, and prove the following.</p> <blockquote> <p dir=\"auto\"><strong>Theorem 12.</strong></p> <ul dir=\"auto\"> <li><em><math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$r$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\frac{1}{2}$</math-renderer>.</em></li> <li><em><math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2X^2$</math-renderer>.</em></li> <li><em>Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$A$</math-renderer> be the result of applying the third coordinate of the first coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> to the natural number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2$</math-renderer>. Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B$</math-renderer> be the first coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$A$</math-renderer>. For the unique <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$z$</math-renderer> in the domain of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B$</math-renderer>, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B(z)$</math-renderer> is equal to the third coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$r$</math-renderer>.</em></li> </ul> </blockquote> <p dir=\"auto\">Given the first two bullets of Theorem 12, it is perhaps surprising that we can't just take <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$r$</math-renderer> to literally be <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\frac{1}{2}$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$P$</math-renderer> to literally be <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2X^2$</math-renderer>. If we try to do this, Lean will inform us that the resulting proposition does not typecheck. In particular, the last sentence of the statement</p> <ul dir=\"auto\"> <li>Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$A$</math-renderer> be the result of applying the third coordinate of the first coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2X^2$</math-renderer> to the natural number <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2$</math-renderer>. Let <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B$</math-renderer> be the first coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$A$</math-renderer>. For the unique <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$z$</math-renderer> in the domain of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B$</math-renderer>, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$B(z)$</math-renderer> is equal to the third coordinate of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\frac{1}{2}$</math-renderer>.'</li> </ul> <p dir=\"auto\">is completely meaningless, unlike the last sentence of Theorem 12.</p> <p dir=\"auto\">Finally, using the axiom of choice (in a meaningful way, mind), we can build three terms <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer>, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$b$</math-renderer>, and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer> and prove the following:</p> <blockquote> <p dir=\"auto\"><strong>Theorem 13.</strong> <em><math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$b$</math-renderer>, and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$b$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer>.</em></p> </blockquote> <p dir=\"auto\">This may not seem so strange, but the issue is that if we now consider the obvious corollary <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a = c$</math-renderer>, Lean will tell us that <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer> don't have the same type, so the question of whether <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer> is as absurd as the question of whether the Banach space <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\ell^2$</math-renderer> is equal to the monster group. (And, yes, <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$b$</math-renderer> have the same type and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$b$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer> have the same type; there is no type coercion happening here.)</p> <p dir=\"auto\">It does make sense to ask whether <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer> are 'heterogeneously equal' (i.e., is it the case that <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle A, a \\rangle = \\langle C, c\\rangle$</math-renderer>, where <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$A$</math-renderer> is the type of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$a$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$C$</math-renderer> is the type of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$c$</math-renderer>?), but it also makes sense to ask whether <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\text{Banach spaces}, \\ell^2 \\rangle$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\text{groups}, \\text{monster group}\\rangle$</math-renderer> or to ask whether <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle\\mathsf{Prop},\\text{quadratic reciprocity}\\rangle$</math-renderer> is equal to <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\mathsf{Fin} 2, 0 \\rangle$</math-renderer> (where <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathsf{Prop}$</math-renderer> is the type of propositions and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathsf{Fin} 2$</math-renderer> is the type of natural numbers less than <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2$</math-renderer>). The only formal difference is that, while you can prove <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle A, a \\rangle = \\langle C, c\\rangle$</math-renderer> easily (since equality is transitive, after all), the statements <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\text{Banach spaces}, \\ell^2 \\rangle = \\langle \\text{groups}, \\text{monster group}\\rangle$</math-renderer> and <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\langle \\mathsf{Prop},\\text{quadratic reciprocity}\\rangle = \\langle \\mathsf{Fin} 2, 0 \\rangle$</math-renderer> are independent of Lean.</p> <h3 tabindex=\"-1\" dir=\"auto\">Beyond Mathlib</h3> <p dir=\"auto\">This last theorem requires a proof tactic that is (reasonably) banned in Mathlib (i.e., the infamous <code>native_decide</code>) as well as an explicit extra axiomatic assumption. (Think of this as being like an exotic counterexample in real analysis that requires <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$\\mathsf{CH}$</math-renderer>.)</p> <blockquote> <p dir=\"auto\"><strong>Theorem 14.</strong> <em>If we assume axiomatically that the type of natural numbers less than <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2147483649$</math-renderer> is equal to the type of integers in the interval <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$[0,2147483649)$</math-renderer> and that <a href=\"https://leanprover-community.github.io/mathlib4_docs/Init/Core.html#Lean.trustCompiler\" rel=\"nofollow\">we trust the Lean compiler</a>, then <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$0 = 1$</math-renderer>.</em></p> </blockquote> <p dir=\"auto\">In other words, these axioms are inconsistent. This is notable firstly because it is consistent without the axioms used by <code>native_decide</code> (i.e., <code>Lean.trustCompiler</code> and <code>Lean.ofReduceBool</code>) that the type of natural numbers less than <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$2147483649$</math-renderer> is equal to the type of integers in the interval <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$[0,2147483649)$</math-renderer> (indeed it is consistent to assume that any two types of the same cardinality in the same universe are equal), but also secondly because the analogous axioms regarding numbers smaller than <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$k$</math-renderer> are seemingly consistent with <code>native_decide</code> for any <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$k &amp;lt; 2147483649$</math-renderer> (specifically, the analogous proof of <math-renderer data-run-id=\"f5d208a9b482766643b113586b250ddb\">$0 = 1$</math-renderer> does not work).</p> <hr> <p dir=\"auto\">I should clarify some things. Theorems 1-10 (and to some extent Theorem 12) are artifacts of particular definitions made in Mathlib, although the convention that leads to Theorem 9 seems to be considered best practice (classically) for dealing with the fact that division is a partial function. Theorem 11 is not an artifact of particular definitions, but rather follows very directly from the treatment of propositions in type theory. (It's even provable constructively in type theories with propositional extensionality, such as HoTT.)</p> <p dir=\"auto\">Theorems 13 and 14 are unique to Lean and arise from some of its design decisions. Theorem 13 relies on definitional proof irrelevance and Lean's computational rules for quotient types, which also lead to the failure of subject reduction. In other proof assistants based on dependent type theory (e.g., Rocq and Agda), judgmental/definitional equality is transitive, so nothing like Theorem 13 can happen, even assuming choice. Theorem 14 relies on low-level implementation details of the Lean compiler.</p>"},{"id":"https://exe.dev/","title":"Exe.dev","link":"https://exe.dev/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46397609","content":"<a href=\"https://news.ycombinator.com/item?id=46397609\">Comments</a>","date":1766792566000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://graydon2.dreamwidth.org/193447.html","title":"Always bet on text (2014)","link":"https://graydon2.dreamwidth.org/193447.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46397379","content":"<a href=\"https://news.ycombinator.com/item?id=46397379\">Comments</a>","date":1766790580000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div id=\"content\" role=\"main\"> <p> Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button! </p> </div></div>"},{"id":"https://github.com/Syn-Nine/gar-lang/blob/main/DEVLOG.md","title":"Langjam-Gamejam Devlog: Making a language, compiler, VM and 5 games in 52 hours","link":"https://github.com/Syn-Nine/gar-lang/blob/main/DEVLOG.md","hnCommentsUrl":"https://news.ycombinator.com/item?id=46348251","content":"<a href=\"https://news.ycombinator.com/item?id=46348251\">Comments</a>","date":1766349875000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://purplesyringa.moe/blog/faster-practical-modular-inversion/","title":"Faster Practical Modular Inversion","link":"https://purplesyringa.moe/blog/faster-practical-modular-inversion/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46341904","content":"<a href=\"https://news.ycombinator.com/item?id=46341904\">Comments</a>","date":1766286828000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div><p><time>December 20, 2025</time></p><p>Last year, <a href=\"https://lemire.me/blog/2024/04/13/greatest-common-divisor-the-extended-euclidean-algorithm-and-speed/\">Lemire wrote</a> about an optimized variation of <a href=\"https://en.wikipedia.org/wiki/Euclidean_algorithm\">the Euclidean algorithm</a> for computing <a href=\"https://en.wikipedia.org/wiki/Greatest_common_divisor\">the greatest common divisor</a> of two numbers, called <em>binary Euclidean algorithm</em> or <em>Stein’s algorithm</em>. It’s a best-of-class implementation, though it’s currently only used by libc++.</p><p>The post also briefly mentions <a href=\"https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm\">the extended Euclidean algorithm</a>, a related algorithm most often used to compute the <a href=\"https://en.wikipedia.org/wiki/Modular_multiplicative_inverse\">modular multiplicative inverse</a> (given a remainder <eq><math><mi>a</mi></math></eq> and a modulus <eq><math><mi>m</mi></math></eq>, find <eq><math><mi>x</mi></math></eq> such that <eq><math><mrow><mi>a</mi><mo>⋅</mo></mrow><mrow><mi>x</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><mi>m</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>):</p><blockquote><p>There is also a binary version of the extended Euclidean algorithm[,] although it is quite a bit more involved and it is not clear that it […] can be implemented at high speed, leveraging fast instructions, when working on integers that fit in general-purpose registers. […]</p><p>My implementation of the binary extended Euclidean algorithm is quite a bit slower and not recommended. I expect that it should be possible to optimize it further.</p><p><em>– Lemire</em></p></blockquote><p>That’s a big shame, because the extended Euclidean algorithm can be optimized in a very similar manner, and the underlying ideas were described <a href=\"https://eprint.iacr.org/2020/972.pdf\">in a 2020 paper</a>. It’s probably not well-known because the paper focuses on constant-time evaluation and long arithmetic, so people might have assumed it’s irrelevant.</p><p>I’m hoping to bring justice to the extended Stein’s algorithm with this post. I’ll cover how the algorithm works, its limitations, some optimizations compared to Pornin’s paper, and potential further improvements.</p><p>My implementation is <a href=\"https://github.com/purplesyringa/mod2k/blob/104603af3866ac274073a5b2af28f7a41550add1/src/xgcd.rs\">available on GitHub</a> as part of a Rust modular arithmetic library.</p><p>The textbook algorithm can be used not only to compute inverses, but also to solve <a href=\"https://en.wikipedia.org/wiki/Diophantine_equation\">linear Diophantine equations</a>. I will focus on the former in this post, since that’s where the optimizations shine at. I’ll briefly cover the general case at the end of the post.</p><p>I won’t make claims on exact performance, because something strange is going on with the Lemire’s benchmarking results and I don’t want to add to the mess. I’ve measured that my implementation of the algorithm is <eq><math><mn>1.3</mn></math></eq> – <eq><math><mn>2</mn></math></eq> times faster than the textbook implementation on average, even on M4, but you may see a completely different picture if your compiler produces slightly different codegen.</p><blockquote><p>Lemire’s benchmark seems to be skewed by the choice of the compiler (GCC vs Clang), its version (Clang 18 vs Clang 21), optimization flags (<code>-O2</code> vs <code>-O3</code>), the microarchitecture (Haswell vs Ice Lake vs Zen 2), and minutiae of the benchmarking code. Results don’t make much sense mathematically and look disproportionately affected by microarchitectural conditions.</p><p>If you want to get the fastest implementation, I suggest you inspect the assembly more closely than me, because I have no idea what’s going on.</p></blockquote><p>Nevertheless, here is some raw data for transparency. The benchmark measures the time per inversion (in ns), the cell format is “Stein’s algorithm / Euclidean algorithm”.</p><div><table><thead><tr><th>8 bits</th><th>16 bits</th><th>32 bits</th><th>64 bits</th></tr></thead><tbody><tr><th>Haswell</th><td><span>11.38</span> / <span>19.21</span> (-41%)</td><td><span>17.48</span> / <span>33.96</span> (-49%)</td><td><span>29.76</span> / <span>61.69</span> (-52%)</td><td><span>67.18</span> / <span>152.19</span> (-56%)</td></tr><tr><th>Alder Lake</th><td><span>8.20</span> / <span>10.19</span> (-20%)</td><td><span>13.77</span> / <span>16.87</span> (-18%)</td><td><span>21.47</span> / <span>31.00</span> (-31%)</td><td><span>50.38</span> / <span>69.57</span> (-28%)</td></tr><tr><th>Zen 5</th><td><span>7.77</span> / <span>10.56</span> (-26%)</td><td><span>9.43</span> / <span>14.80</span> (-36%)</td><td><span>13.96</span> / <span>23.98</span> (-42%)</td><td><span>34.58</span> / <span>49.24</span> (-30%)</td></tr><tr><th>M1</th><td><span>14.58</span> / <span>13.05</span> (+12%)</td><td><span>11.48</span> / <span>18.63</span> (-38%)</td><td><span>19.74</span> / <span>35.47</span> (-44%)</td><td><span>43.14</span> / <span>71.14</span> (-39%)</td></tr><tr><th>M2</th><td><span>8.93</span> / <span>10.26</span> (-13%)</td><td><span>11.00</span> / <span>17.90</span> (-39%)</td><td><span>19.38</span> / <span>33.78</span> (-43%)</td><td><span>41.33</span> / <span>68.03</span> (-39%)</td></tr><tr><th>M4</th><td><span>5.28</span> / <span>8.60</span> (-39%)</td><td><span>8.07</span> / <span>14.77</span> (-45%)</td><td><span>13.63</span> / <span>28.05</span> (-51%)</td><td><span>28.68</span> / <span>56.22</span> (-49%)</td></tr><tr><th>Cortex-A72</th><td><span>29.80</span> / <span>33.48</span> (-11%)</td><td><span>38.30</span> / <span>49.36</span> (-22%)</td><td><span>61.28</span> / <span>83.63</span> (-27%)</td><td><span>162.55</span> / <span>151.77</span> (+7%)</td></tr><tr><th>Snapdragon 8 Gen 3</th><td><span>9.72</span> / <span>12.13</span> (-20%)</td><td><span>14.97</span> / <span>21.91</span> (-32%)</td><td><span>28.51</span> / <span>39.89</span> (-29%)</td><td><span>70.11</span> / <span>75.46</span> (-7%)</td></tr><tr><th>Kryo 485</th><td><span>15.08</span> / <span>19.36</span> (-22%)</td><td><span>21.54</span> / <span>30.41</span> (-29%)</td><td><span>33.63</span> / <span>50.96</span> (-34%)</td><td><span>90.32</span> / <span>94.76</span> (-5%)</td></tr></tbody></table></div><p>Let’s start with the algorithm for computing the GCD of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq>. Suppose for now that <eq><math><mi>b</mi></math></eq> is odd. Here’s the core idea:</p><ul><li>If <eq><math><mi>a</mi></math></eq> is divisible by <eq><math><msup><mn>2</mn><mi>k</mi></msup></math></eq>, this factor can be removed: <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msup><mn>2</mn><mi>k</mi></msup><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>. This decreases the bit length of <eq><math><mi>a</mi></math></eq> by at least <eq><math><mn>1</mn></math></eq>, guaranteeing <eq><math><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>a</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> time complexity if we can apply this reduction consistently.</li><li>If both <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> are odd, rewriting <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo>−</mo><mi>b</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> guarantees <eq><math><mrow><msup><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo></mrow><mrow><mi>a</mi><mo>−</mo></mrow><mrow><mi>b</mi></mrow></math></eq> will be even and reducible on the next iteration. To avoid negative integers, swap <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> if <eq><math><mrow><mi>a</mi><mo>&lt;</mo></mrow><mrow><mi>b</mi></mrow></math></eq> beforehand; new <eq><math><mi>b</mi></math></eq> remains odd because <eq><math><mi>a</mi></math></eq> was odd.</li></ul><p>The implementation is very short:</p><pre><code><span>while</span> a != <span>0</span> { a &gt;&gt;= a.<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b, a); } a -= b; } <span>return</span> b; </code></pre><p>If the initial <eq><math><mi>b</mi></math></eq> is not guaranteed to be odd, some adjustments are necessary:</p><pre><code><span>let</span> <span>shift</span> = (a | b).<span>trailing_zeros</span>(); <span>// == min(a.trailing_zeros(), b.trailing_zeros())</span> b &gt;&gt;= b.<span>trailing_zeros</span>(); <span>/* loop from the previous snippet */</span> <span>return</span> b &lt;&lt; shift; </code></pre><p>But for modular inversion, the modulus is usually odd, so I won’t dwell on this.</p><p>This covers the general structure of the algorithm, but some optimizations are crucial for getting good performance.</p><p>The conditional swap should be compiled to branchless code to avoid branch misprediction. Compiler hints like <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#builtin-unpredictable\">__builtin_unpredictable</a> or <a href=\"https://doc.rust-lang.org/stable/core/hint/fn.select_unpredictable.html\">core::hint::select_unpredictable</a> may be useful.</p><p>The loop has a high latency because <code>trailing_zeros</code>, <code>&gt;&gt;=</code>, <code>if</code>, and <code>-=</code> are computed sequentially. But since <code>(-a).trailing_zeros() == a.trailing_zeros()</code>, <code>a.trailing_zeros()</code> can in principle be computed before the swap on the previous iteration:</p><pre><code><span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { a &gt;&gt;= q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); } <span>else</span> { (a, b) = (a - b, b); } } </code></pre><p>This brings the latency down to 3 operations: <code>&gt;&gt;=</code>; <code>a - b</code> and <code>b - a</code> computed in parallel; <code>trailing_zeros</code> and <code>if</code> computed in parallel. It also slightly increases the number of operations (computing <code>b - a</code> and <code>a - b</code> and only using one), but the tradeoff pays off.</p><p>Pay close attention to <code>trailing_zeros</code> if you’re implementing this in C. The algorithm can invoke it with a zero input on the last iteration. This is well-defined in Rust, which maps <eq><math><mn>0</mn></math></eq> to the bit width of the data type, but in C <code>__builtin_clz(0)</code> is UB. Use <code>__builtin_clzg</code> to avoid issues. In C++, <code>std::countr_zero(0)</code> is well-defined.</p><blockquote><p>GCC <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Bit-Operation-Builtins.html\">documents</a> <code>__builtin_clz(0)</code> as having an “undefined result”, so I initially assumed it means an indeterminate value. In reality, <a href=\"https://gcc.gnu.org/bugzilla/show_bug.cgi?id=116989\">GCC maintainers consider it UB</a> and <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#builtin-clzg-and-builtin-ctzg\">LLVM documents it as UB</a>… but the optimizers seem to model it exactly like an indeterminate value? (e.g. LLVM considers <code>@llvm.cttz(0)</code> to produce <code>poison</code>) This is frankly ridiculous, someone do something about it.</p></blockquote><div><p>You might be wondering how this algorithm is related to modular inversion.</p><p>The trick is to express the values of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> at each point as weighted sums of the original <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> (denoted <eq><math><mrow><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>) with some coefficients <eq><math><mrow><msub><mi>k</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mi>i</mi></msub></mrow></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>If <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> is invertible modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, their GCD is <eq><math><mn>1</mn></math></eq>, and so at the end of the algorithm <eq><math><mrow><mi>b</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>. This gives us:</p><section><eqn><math display=\"block\"><mrow><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><mo stretchy=\"false\">⟹</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>That is, <eq><math><msub><mi>k</mi><mn>1</mn></msub></math></eq> is the inverse of <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>. So all we need to do is track the coefficients across iterations. We start with:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mn>0</mn><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>When <eq><math><mi>a</mi></math></eq> is divided by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, the coefficients are divided by the same value:</p><section><eqn><math display=\"block\"><mrow><mi>a</mi><mo>=</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo stretchy=\"false\">⟹</mo><mfrac><mi>a</mi><msup><mn>2</mn><mi>q</mi></msup></mfrac><mo>=</mo><mfrac><msub><mi>k</mi><mn>0</mn></msub><msup><mn>2</mn><mi>q</mi></msup></mfrac><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mfrac><msub><mi>l</mi><mn>0</mn></msub><msup><mn>2</mn><mi>q</mi></msup></mfrac><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eqn></section><p>When <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> are swapped, the pairs <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> and <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> are swapped.</p><p>When <eq><math><mi>b</mi></math></eq> is subtracted from <eq><math><mi>a</mi></math></eq>, the coefficients are subtracted:</p><section><eqn><math display=\"block\"><mrow><mi>a</mi><mo>−</mo><mi>b</mi><mo>=</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo>−</mo><msub><mi>k</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>l</mi><mn>0</mn></msub><mo>−</mo><msub><mi>l</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eqn></section><p>In other words, whatever we do to <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq>, we also do to the coefficient pairs <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>.</p></div><p>Implementation attempts quickly reveal a problem: coefficients are not necessarily divisible by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, so it’s not clear how to represent them. Surely not with floats.</p><p>This is actually a core difference between Stein’s algorithm and the textbook Euclidean algorithm, which is implemented as <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>b</mi><mo separator=\"true\">,</mo><mi>a</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>.</p><p>The Euclidean algorithm uses division (<code>q = a / b</code>), but only to compute constant factors. The values are updated with subtraction and multiplication alone (<code>a -= b * q</code>). Stein’s algorithm divides values (<code>a /= 2^q</code>), causing non-integer coefficients.</p><p>This is likely why the extended Stein’s algorithm is unpopular. We’ll use tricks tailored to modular inverse, but the general-purpose case covered at the end of the post essentially boils down to “compute modular inverse and post-process”. I believe it can still be faster than the textbook implementation, but I haven’t tested it.</p><p>We can track coefficients as fractions to stay in integers. The most efficient approach uses the same denominator <eq><math><msup><mn>2</mn><mi>p</mi></msup></math></eq> for all variables:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mi>p</mi></mrow></msup><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mi>p</mi></mrow></msup><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>We start with <eq><math><mrow><mi>p</mi><mo>=</mo></mrow><mrow><mn>0</mn></mrow></math></eq>. Instead of dividing <eq><math><mrow><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mn>0</mn></msub></mrow></math></eq> by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, we increase <eq><math><mi>p</mi></math></eq> by <eq><math><mi>q</mi></math></eq> and multiply <eq><math><mrow><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mn>1</mn></msub></mrow></math></eq> by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>. Subtraction can ignore <eq><math><mi>p</mi></math></eq> because all coefficients use the same precision.</p><p>This seems pointless at first, since we need to know <eq><math><mrow><msup><mn>2</mn><mrow><mo lspace=\"0em\" rspace=\"0em\">−</mo><mi>p</mi></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, but if the modulus is fixed, we can precompute it. Each iteration reduces the total bit length of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> by at least <eq><math><mi>q</mi></math></eq>, and after the last right-shift <eq><math><mrow><mi>a</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>b</mi><mo>≠</mo></mrow><mrow><mn>0</mn></mrow></math></eq>, so if the input numbers fit in <eq><math><mi>k</mi></math></eq> bits, the sum of <eq><math><mi>q</mi></math></eq> (and thus <eq><math><mi>p</mi></math></eq>) is limited by <eq><math><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq>. This means that we can increase precision to <eq><math><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq> at the end and use a single precomputed value <eq><math><mrow><msup><mn>2</mn><mrow><mo lspace=\"0em\" rspace=\"0em\">−</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mn>2</mn><mi>k</mi><mo>−</mo><mn>2</mn><mo form=\"postfix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">)</mo></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>.</p><p>The multitude of variables is getting confusing, so let’s simplify it. We’re looking for <eq><math><mrow><msub><mi>k</mi><mn>1</mn></msub><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> and don’t care about <eq><math><msub><mi>l</mi><mi>i</mi></msub></math></eq>, so tracking just <eq><math><msub><mi>k</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>k</mi><mn>1</mn></msub></math></eq> suffices. Let’s rename these variables to <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> respectively to get rid of indices. This gives us:</p><pre><code><span>// Example for 32-bit inputs (k = 32).</span> <span>let</span> <span>mut </span><span>u</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v</span> = <span>0</span>; <span>let</span> <span>mut </span><span>p</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { a &gt;&gt;= q; v &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (u, v) = (v, u); } <span>else</span> { (a, b) = (a - b, b); } u -= v; } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); v &lt;&lt;= <span>62</span> - p; <span>return</span> (v * inverse_of_2p62) % b0; </code></pre><p>We don’t apply the latency-reducing trick to <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> because the latency is dominated by other calculations. Computing both <code>u - v</code> and <code>v - u</code> would most likely reduce performance, since we’re already pushing the CPU limit of parallel operations.</p><div><p>It’s easy to prove by induction that at the beginning of each iteration,</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>&lt;</mo><mi>u</mi><mo>&lt;</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>&lt;</mo><mi>v</mi><mo>≤</mo><msup><mn>2</mn><mi>p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></eqn></section></div><p>This means that <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> fit in signed <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq>-bit integers. Since <eq><math><mrow><mi>p</mi><mo>≤</mo></mrow><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq>, that amounts to <eq><math><mrow><mn>2</mn><mi>k</mi></mrow></math></eq>-bit types, i.e. twice as wide as the input. And that’s a problem: while it works just fine for <eq><math><mn>32</mn></math></eq>-bit inputs, <eq><math><mn>64</mn></math></eq>-bit inputs require <code>i128</code> arithmetic, which slows down the algorithm considerably. We’ll discuss what to do about it in a bit.</p><p>Before we do this, though, let’s finish the <eq><math><mn>32</mn></math></eq>-bit case. There’s just one thing left to improve: computing <eq><math><mrow><mi>v</mi><mo>⋅</mo></mrow><mrow><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>62</mn></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>.</p><p>On the face of it, this is one multiplication and one reduction, but <a href=\"https://en.wikipedia.org/wiki/Montgomery_modular_multiplication\">Montgomery multiplication</a> demonstrates that these operations can be performed faster together.</p><p>Assume for a moment that <eq><math><mi>v</mi></math></eq> is non-negative. The idea is to subtract a multiple of <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> from <eq><math><mi>v</mi></math></eq> such that the bottom <eq><math><mn>62</mn></math></eq> bits become zero, so that the remainder remains the same, but division by <eq><math><msup><mn>2</mn><mn>62</mn></msup></math></eq> can be performed with a shift. We’re looking for <eq><math><mi>t</mi></math></eq> such that</p><section><eqn><math display=\"block\"><mrow><mi>v</mi><mo>−</mo><mi>t</mi><mo>⋅</mo><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>This is equivalent to <eq><math><mrow><mi>t</mi><mo>=</mo></mrow><mrow><mi>v</mi><mo>⋅</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>, and by precomputing <eq><math><mrow><mi>j</mi><mo>=</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq>, we obtain <eq><math><mrow><mi>v</mi><mo>−</mo></mrow><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> as the easily divisible value. Since <eq><math><mi>v</mi></math></eq> and <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> have equal bottom <eq><math><mn>62</mn></math></eq> bits,</p><section><eqn><math display=\"block\"><mrow><mfrac><mrow><mi>v</mi><mo>−</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo>=</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mi>v</mi><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo>−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow></mrow></math></eqn></section><p>We’ve just found that <eq><math><mrow><mi>v</mi><mo>≤</mo></mrow><mrow><msup><mn>2</mn><mi>p</mi></msup><mo>≤</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq>, so unless <eq><math><mrow><mi>v</mi><mo>=</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq> exactly, this is just</p><section><eqn><math display=\"block\"><mrow><mo>−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo>=</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mn>4</mn><mi>j</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>64</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>64</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow></mrow></math></eqn></section><p>This number is in range <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><mn>0</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>. We know that <eq><math><mn>0</mn></math></eq> can never be an inverse, so it’s actually <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><mn>1</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, and by adding <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, we obtain the exact remainder. This can be computed with only two multiplications and some glue:</p><pre><code><span>fn</span> <span>redc62</span>(v: <span>i64</span>) <span>-&gt;</span> <span>u32</span> { <span>if</span> v == (<span>1</span> &lt;&lt; <span>62</span>) { <span>1</span> } <span>else</span> { <span>let</span> <span>x</span> = v.<span>unsigned_abs</span>().<span>wrapping_mul</span>(j &lt;&lt; <span>2</span>).<span>widening_mul</span>(b0 <span>as</span> <span>u64</span>).<span>1</span> <span>as</span> <span>u32</span>; <span>if</span> v &gt; <span>0</span> { b0 - x } <span>else</span> { x } } } </code></pre><p>That’s it for <eq><math><mn>32</mn></math></eq>-bit and smaller inputs. Yay! Buy yourself a cupcake.</p><p>For <eq><math><mn>64</mn></math></eq>-bit inputs, coefficients only fit in <code>i128</code>. This makes each operation twice as slow. We can reduce <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> on each iteration so that coefficients fit in <eq><math><mn>64</mn></math></eq> bits, since we only need <eq><math><mrow><mi>v</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, but this tanks performance too.</p><p>Hmm. Notice that at the beginning of the algorithm, <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> fit in <eq><math><mn>1</mn></math></eq> bit and then grow slowly. Only once their length exceeds <eq><math><mn>64</mn></math></eq> bits do we need long integers. What if we could somehow reset the length every few iterations, so that <eq><math><mn>64</mn></math></eq>-bit integers suffice?</p><p>Just like <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> can be represented as weighted sums of <eq><math><mrow><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> can be represented as weighted sums of their earlier versions <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>u</mi><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><msub><mi>g</mi><mn>0</mn></msub><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>v</mi><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><msub><mi>g</mi><mn>1</mn></msub><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>The trick is to save <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> and update short coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> instead of long values <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> in the loop. We start with <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo>=</mo></mrow><mrow><mn>1</mn><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub><mo>=</mo></mrow><mrow><mn>0</mn></mrow></math></eq> and trivial coefficients:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>u</mi><mo>=</mo><msub><mi>u</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><mn>0</mn><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>v</mi><mo>=</mo><msub><mi>v</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>When the coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> grow past <eq><math><mn>64</mn></math></eq> bits, we pause, compute <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> based on these formulas, replace <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> with <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq>, and reset the coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> back to trivial, bringing the length back to <eq><math><mn>1</mn></math></eq>.</p><pre><code><div><p><span>let</span> <span>mut </span><span>u0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v0</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { <span>// The coefficients relating (u, v) to (u0, v0).</span> <span>let</span> <span>mut</span> (f0, g0) = (<span>1</span>, <span>0</span>); <span>let</span> <span>mut</span> (f1, g1) = (<span>0</span>, <span>1</span>); <span>let</span> <span>mut </span><span>p</span> = <span>0</span>; <span>// Run the algorithm until p reaches the limit.</span> <span>while</span> a != <span>0</span> &amp;&amp; p + q &lt;= <span>62</span> { a &gt;&gt;= q; f1 &lt;&lt;= q; g1 &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (f0, f1) = (f1, f0); (g0, g1) = (g1, g0); } <span>else</span> { (a, b) = (a - b, b); } f0 -= f1; g0 -= g1; } <span>// This section means different things depending on the reason the loop stopped:</span> <span>// - If we ran out of precision, this performs as much of the last action as possible and</span> <span>// adjusts `q` so that the operation completes on the next iteration.</span> <span>// - If `a = 0`, this effectively raises the precision of f1/g1 to 62. It doesn't adjust</span> <span>// `f0, g0` correctly, but this doesn't matter because `u` is not read on the exit path.</span> a &gt;&gt;= <span>62</span> - p; f1 &lt;&lt;= <span>62</span> - p; g1 &lt;&lt;= <span>62</span> - p; q -= <span>62</span> - p; <span>// Apply the coefficients.</span> <span>let</span> <span>f0</span> = <span>redc62</span>(f0); <span>let</span> <span>g0</span> = <span>redc62</span>(g0); <span>let</span> <span>f1</span> = <span>redc62</span>(f1); <span>let</span> <span>g1</span> = <span>redc62</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % b0, (f1 * u0 + g1 * v0) % b0); } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); <span>return</span> v0; </p><p><label for=\"expansible1\">Expand</label></p></div></code></pre><p>The astute among you might realize this doesn’t improve much, since we went from updating two <eq><math><mn>128</mn></math></eq>-bit numbers in a loop to updating four <eq><math><mn>64</mn></math></eq>-bit numbers in a loop. But since we apply the exact same operations to <eq><math><msub><mi>f</mi><mi>i</mi></msub></math></eq> and <eq><math><msub><mi>g</mi><mi>i</mi></msub></math></eq>, we can vectorize them.</p><div><p>We can’t use SIMD because x86 doesn’t have <code>cmov</code> for vector registers, but we can decrease the coefficient length to <eq><math><mn>32</mn></math></eq> bits and pack two coefficients into one integer:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><msub><mi>c</mi><mn>0</mn></msub><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><mo>+</mo><msup><mn>2</mn><mn>32</mn></msup><msub><mi>g</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><mo>+</mo><msup><mn>2</mn><mn>32</mn></msup><msub><mi>g</mi><mn>1</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section></div><p>This simplifies the inner loop to:</p><pre><code><span>while</span> a != <span>0</span> &amp;&amp; p + q &lt;= <span>30</span> { a &gt;&gt;= q; c1 &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (c0, c1) = (c1, c0); } <span>else</span> { (a, b) = (a - b, b); } c0 -= c1; } </code></pre><p>Just like <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq>, <eq><math><msub><mi>c</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>c</mi><mn>1</mn></msub></math></eq> take <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq> bits, so we limit <eq><math><mi>p</mi></math></eq> by <eq><math><mrow><mn>32</mn><mo>−</mo></mrow><mrow><mn>2</mn><mo>=</mo></mrow><mrow><mn>30</mn></mrow></math></eq>. But with care, we can squeeze out one more bit. Recall the inequalities:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>&lt;</mo><mi>u</mi><mo>&lt;</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>&lt;</mo><mi>v</mi><mo>≤</mo><msup><mn>2</mn><mi>p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>Only <eq><math><mi>u</mi></math></eq> takes <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq> bits. <eq><math><mi>v</mi></math></eq> fits in <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>1</mn></mrow></math></eq>, if barely: signed integer types represent the range <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msup><mn>2</mn><mi>p</mi></msup><mo separator=\"true\">;</mo><msup><mn>2</mn><mi>p</mi></msup><mo>−</mo><mn>1</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, while this is <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><msup><mn>2</mn><mi>p</mi></msup><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, but the number of distinct values is the same. So even if we run out of the <eq><math><mn>30</mn></math></eq>-bit limit, we can shift <eq><math><mi>v</mi></math></eq> once more. This affects the code after the inner loop:</p><pre><code><span>// 31 would be 30 without this optimization</span> a &gt;&gt;= <span>31</span> - p; c1 &lt;&lt;= <span>31</span> - p; q -= <span>31</span> - p; <span>let</span> (f0, g0) = <span>parse_coefficients</span>(c0); <span>let</span> (f1, g1) = <span>parse_coefficients</span>(c1); <span>let</span> <span>f0</span> = <span>redc31</span>(f0); <span>let</span> <span>g0</span> = <span>redc31</span>(g0); <span>let</span> <span>f1</span> = <span>redc31</span>(f1); <span>let</span> <span>g1</span> = <span>redc31</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % b0, (f1 * u0 + g1 * v0) % b0); </code></pre><p>Note that the inner loop is still limited by <eq><math><mn>30</mn></math></eq>, since it not only shifts <eq><math><mi>v</mi></math></eq>, but also subtracts from <eq><math><mi>u</mi></math></eq>, which could cause an overflow with a limit of <eq><math><mn>31</mn></math></eq>.</p><div><p>Parsing coefficients from <eq><math><msub><mi>c</mi><mi>i</mi></msub></math></eq> is slightly tricky due to the unusual signed integer format, but not impossibly so:</p><section><eqn><math display=\"block\"><mrow><mrow><mi>int</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>x</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mi>x</mi></mtd><mtd><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>≤</mo><msup><mn>2</mn><mn>31</mn></msup></mrow></mtd></mtr><mtr><mtd><mrow><mi>x</mi><mo>−</mo><msup><mn>2</mn><mn>32</mn></msup></mrow></mtd><mtd><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>&gt;</mo><msup><mn>2</mn><mn>31</mn></msup></mrow></mtd></mtr></mtable></mrow></mrow></math></eqn></section><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>int</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>32</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>int</mi></mrow><mrow><mo fence=\"true\" form=\"prefix\">(</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mfrac><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>+</mo><msup><mn>2</mn><mn>31</mn></msup><mo>−</mo><mn>1</mn></mrow><msup><mn>2</mn><mn>32</mn></msup></mfrac></mstyle><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo fence=\"true\" form=\"postfix\">)</mo></mrow></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>This assumes that <eq><math><msub><mi>c</mi><mi>i</mi></msub></math></eq> is stored in an unsigned type.</p></div><p>With packed coefficients, the inner loop is similar to the unoptimized version, differing only in <eq><math><mrow><msub><mi>c</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow></math></eq> vs <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq>. This allows us to cheaply combine two approaches: track the true values <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> for the first <eq><math><mn>62</mn></math></eq> iterations and then switch to coefficients. It’s faster than relying on coefficients alone because it recalculates <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> less often.</p><p>The final implementation looks something like this:</p><pre><code><div><p><span>let</span> <span>mut </span><span>u0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v0</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>let</span> <span>mut </span><span>is_first_iteration</span> = <span>true</span>; <span>while</span> a != <span>0</span> { <span>// Either coefficients in SWAR format, or the values u/v, depending on the iteration.</span> <span>let</span> <span>mut </span><span>c0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>c1</span> = <span>if</span> is_first_iteration { <span>0</span> } <span>else</span> { <span>1</span> &lt;&lt; <span>32</span> }; <span>let</span> <span>mut </span><span>p_left</span> = <span>if</span> is_first_iteration { <span>63</span> } <span>else</span> { <span>31</span> }; <span>while</span> a != <span>0</span> &amp;&amp; q &lt; p_left { <span>// &lt; instead of &lt;= is load-bearing</span> a &gt;&gt;= q; c1 &lt;&lt;= q; p_left -= q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (c0, c1) = (c1, c0); } <span>else</span> { (a, b) = (a - b, b); } c0 -= c1; } a &gt;&gt;= p_left; c1 &lt;&lt;= p_left; q -= p_left; <span>if</span> is_first_iteration { u0 = <span>redc63</span>(c0); v0 = <span>redc63</span>(c1); } <span>else</span> { <span>let</span> (f0, g0) = <span>parse_coefficient</span>(c0); <span>let</span> (f1, g1) = <span>parse_coefficient</span>(c1); <span>let</span> <span>f0</span> = <span>redc31</span>(f0); <span>let</span> <span>g0</span> = <span>redc31</span>(g0); <span>let</span> <span>f1</span> = <span>redc31</span>(f1); <span>let</span> <span>g1</span> = <span>redc31</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % m, (f1 * u0 + g1 * v0) % m); } is_first_iteration = <span>false</span>; } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); <span>return</span> v0; </p><p><label for=\"expansible2\">Expand</label></p></div></code></pre><p>We store <code>p_left</code> instead of <code>p</code> so that <code>p_left -= q</code> and <code>q &lt; p_left</code> can be computed with a single instruction.</p><p>The <eq><math><mn>32</mn></math></eq>-bit and <eq><math><mn>64</mn></math></eq>-bit cases can use the same implementation, as replacing <code>q &lt; p_left</code> with <code>true</code> makes it identical to the <eq><math><mn>32</mn></math></eq>-bit algorithm, and compilers recognize this.</p><p><code>redc31(x)</code> can be implemented as <code>redc63(x &lt;&lt; 32)</code>.</p><p>And that’s it! You now know a cool way to compute <eq><math><mn>64</mn></math></eq>-bit modular inverses.</p><p>To support variable <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, we can compute <eq><math><mrow><mi>j</mi><mo>=</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msup><mn>2</mn><mn>64</mn></msup></mrow></math></eq> in runtime. This can be done very quickly with <a href=\"https://arxiv.org/pdf/2204.04342\">an algorithm by Jeffrey Hurchalla</a>.</p><p><eq><math><mi>j</mi></math></eq> only exists if <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> is odd. If it’s even, swap <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>. If both are even, divide them by their common power of two and choose whichever becomes odd as <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>.</p><p>To replace the extended Euclidean algorithm, we need to find <em>integers</em> <eq><math><mrow><mi>x</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>y</mi></mrow></math></eq> such that:</p><section><eqn><math display=\"block\"><mrow><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>0</mn></msub><mi>y</mi><mo>=</mo><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>Luckily, our <eq><math><mi>v</mi></math></eq> is no longer a fraction, but rather a remainder modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, so we can substitute <eq><math><mrow><mi>x</mi><mo>=</mo></mrow><mrow><mi>v</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>. <eq><math><mi>y</mi></math></eq> can then be computed from the equation:</p><section><eqn><math display=\"block\"><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi></mrow><msub><mi>b</mi><mn>0</mn></msub></mfrac><mo>=</mo><mfrac><mrow><mi>b</mi><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi></mrow><msub><mi>b</mi><mn>0</mn></msub></mfrac></mrow></math></eqn></section><p>Since this division is exact, it can be calculated with multiplication by <eq><math><mi>j</mi></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mi>y</mi><mo>=</mo><mi>j</mi><mo>⋅</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>b</mi><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>64</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>Despite this complexity, I believe this method can be faster than the extended Euclidean algorithm, since the auxiliary logic takes constant time, except for computing <eq><math><mi>j</mi></math></eq> in <eq><math><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>k</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>a</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>, which is still pretty good.</p><p>As a reminder, you can find my code <a href=\"https://github.com/purplesyringa/mod2k/blob/104603af3866ac274073a5b2af28f7a41550add1/src/xgcd.rs\">on GitHub</a>. The source of latency-optimized GCD is <a href=\"https://lemire.me/blog/2024/04/13/greatest-common-divisor-the-extended-euclidean-algorithm-and-speed/\">this post</a>. Using coefficients to reset bit lengths of <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> comes from <a href=\"https://eprint.iacr.org/2020/972.pdf\">this paper</a>, which also covers the case when values don’t fit in general-purpose registers.</p><p>Thanks to many friends of mine for contributing to the benchmarking results, to Ian Qvist for the motivation to complete this post and editorial comments, and to Yuki for saving me from going insane over unexplainable performance phenomena.</p></div></div>"},{"id":"https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html","title":"The best things and stuff of 2025","link":"https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46365726","content":"<a href=\"https://news.ycombinator.com/item?id=46365726\">Comments</a>","date":1766501493000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"> <p>Great things and people that I discovered, learned, read, met, etc. in 2025. No particular ordering is implied. Not everything is new.</p> <p><em>also: see the lists from <a href=\"https://blog.fogus.me/2024/12/23/the-best-things-and-stuff-of-2024.html\">2024</a>, <a href=\"https://blog.fogus.me/2023/12/18/the-best-things-and-stuff-of-2023/\">2023</a>, <a href=\"http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/\">2022</a>, <a href=\"https://blog.fogus.me/2021/12/27/the-best-things-and-stuff-of-2021/\">2021</a>, <a href=\"http://blog.fogus.me/2020/12/31/the-best-things-and-stuff-of-2020/\">2020</a>, <a href=\"http://blog.fogus.me/2019/12/30/the-best-things-and-stuff-of-2019/\">2019</a>, <a href=\"http://blog.fogus.me/2019/01/02/the-best-things-and-stuff-of-2018/\">2018</a>, <a href=\"http://blog.fogus.me/2018/01/02/the-best-things-and-stuff-of-2017/\">2017</a>, <a href=\"http://blog.fogus.me/2016/12/29/the-best-things-and-stuff-of-2016/\">2016</a>, <a href=\"http://blog.fogus.me/2015/12/29/the-best-things-and-stuff-of-2015/\">2015</a>, <a href=\"http://blog.fogus.me/2014/12/29/the-best-things-and-stuff-of-2014/\">2014</a>, <a href=\"http://blog.fogus.me/2013/12/27/the-best-things-and-stuff-of-2013/\">2013</a>, <a href=\"http://blog.fogus.me/2012/12/26/the-best-things-and-stuff-of-2012/\">2012</a>, <a href=\"http://blog.fogus.me/2011/12/31/the-best-things-and-stuff-of-2011/\">2011</a> and <a href=\"http://blog.fogus.me/2010/12/30/the-best-things-in-2010/\">2010</a></em></p> <h2 id=\"great-posts-articles-vids-readwatched\">Great posts | articles | vids read/watched</h2> <ul> <li><em><a href=\"https://chadnauseam.com/coding/random/calculator-app\">A calculator app? Anyone could make that</a></em> by Chad Nauseam, esquire - <em>I love the story about how Hans Boehm and friends developed a mind-blowing approach called recursive real arithmetic for numbers like pi and (sqrt 2). The post details various symptom -&gt; problem definition -&gt; alternative solutions -&gt; solution cycles that the team met along the way and should be required reading for programmers.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=JVyz17kwIv4\">Lost in Manboo</a></em> - <em>マンガ喫茶マンボ (manga cafe manboo) shows life for some folks who live in 24-hour game cafes in Japan. The video is dystopic in a way that matches our modern world perfectly.</em><a href=\"#fn1\" id=\"fnref1\" role=\"doc-noteref\"><sup>1</sup></a></li> <li><em><a href=\"https://www.youtube.com/watch?v=0z7_A_8il_g\">The Making of Deeper in You on the OP-1</a></em> - <em>Shows an artist’s approach to song creation/composition using the OP-1 synthesizer. This is hypnotic to watch for someone with zero musical talent like myself.</em></li> <li><em><a href=\"https://thecreativeindependent.com/people/multi-disciplinary-artist-jack-rusher-on-the-need-to-sustain-your-creative-drive-in-the-face-of-technological-change/\">An interview with Jack Rusher</a></em> by The Creative Independent - <em>A lovely interview with online friend Jack Rusher discussing the thoughtful application of tech in art, flow, and the state of research in the modern computing industry.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=MWteJW-wYas\">Uncredited: Searching for Lost Board Game Designers</a></em> by Amabel Holland - <em>Amabel describes her trials and tribulations while trying to find the designers of the long-forgotten board game <a href=\"https://boardgamegeek.com/boardgame/4791/duplicate-ad-lib-crossword-cubes\">Duplicate Ad-Lib Crossword Cubes</a>.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=TldMsMtHvW8\">Brian Weissman on his Magic the Gathering history</a></em> - <em>For anyone who came of age during the earliest years of Magic, the name Brian Weissman is legendary. In this interview he gives countless anecdotes about his experiences in those early days.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/08/before-arcturus-david-lindsays-lost.html\">Before Arcturus: David Lindsay’s Lost Novels</a></em> by Mark Valentine - <em>Mark’s research into David Lindsay revealed evidence that he submitted at least two earlier novels, Aletheus and The Confessions of an Egoist, to the publisher Chatto &amp; Windus in 1902 and 1908. These submissions predated his first published masterpiece, <a href=\"https://bookshop.org/p/books/a-voyage-to-arcturus-an-illuminated-edition-david-lindsay/76f8dc45a1376ddf?aid=98208&amp;ean=9781948886307&amp;listref=best-things-2025&amp;next=t\">A Voyage to Arcturus</a>.</em></li> <li><em><a href=\"https://what-dan-read.com/\">What Dan Read</a></em> by Dan - <em>An amazing account of a lifetime of reading.</em></li> <li><em><a href=\"https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/\">Two Years After Cormac McCarthy’s Death, Rare Access to His Personal Library Reveals the Man Behind the Myth</a></em> by Richard Grant - <em>A glimpse into Cormac McCarthy’s massive, chaotically organized personal library reveals the reclusive author as a polymath with an insatiable curiosity. Scholars are currently cataloging the estimated 20,000 volumes, many of which contain the author’s annotations.</em></li> </ul> <h2 id=\"most-viewed-postsvideos-withby-me\">Most viewed posts/videos with/by me</h2> <p>While I’ve posted a few technical post on my personal blog, I’ve taken a lot of time to guest-post on the <a href=\"https://wormwoodiana.blogspot.com/search/label/Fogus\">Wormwoodania blog</a> about weird, macabre, and sardonic fiction and other related, non-technical topics. I hope to continue this trend into next year. Also, my most assiduous readers will have noticed that I’ve written more about games. I’ve decided to keep those posts on this blog since my intent for the site has always been about systems and systems-thinking and games are a great way to study and model systems.</p> <ul> <li><em><a href=\"https://blog.fogus.me/langdev/long-season.html\">The long season of langdev</a></em> - <em>Whereby I speculate if programming language development is in a lull.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/08/on-baron-corvo-greatest-asshole-who.html\">On ‘Baron Corvo: The Greatest Asshole Who Ever Lived’</a></em> - <em>My review of Johan Kugelberg’s pamphlet on why Baron Corvo still intrigues people.</em><a href=\"#fn2\" id=\"fnref2\" role=\"doc-noteref\"><sup>2</sup></a></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/09/derek-raymond-and-black-novel-guest.html\">Derek Raymond and ‘The Black Novel’</a></em> - <em>Discusses the author Derek Raymond’s criteria for what he calls ‘black novels’.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/06/corvos-icicle-guest-post-by-fogus.html\">Corvo’s Icicle</a></em> - <em>Did Baron Corvo invent the mystery trope of the melting weapon?</em></li> <li><em><a href=\"https://blog.fogus.me/clojure/arities-as-proto.html\">Arities as Pseudo-Protocol</a></em> - <em>Whereby I describe a little-used Clojure technique leveraging function arities as a lightweight interface/protocol.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=_g69GKN6lAM\">My appearance on the Apropos Podcast</a></em> - <em>Sat down with the Apropos crew and had a great time talking Clojure.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/03/meeting-corvo-and-weeks-in-georgetown.html\">Meeting Corvo and Weeks in Georgetown</a></em> - <em>A brief description of some of my hobby research.</em></li> <li><em><a href=\"https://blog.fogus.me/games/18XX/intro.html\">18XX: A System of Systems</a></em> - <em>A description of 18XX board games as a system of systems.</em></li> <li><em><a href=\"https://blog.fogus.me/games/bird-poker.html\">The Bird-Poker Deck</a></em> - <em>A truncated pack of playing cards that displays some interesting game-play characteristics.</em></li> <li><em><a href=\"https://blog.fogus.me/games/checkers-arcade.html\">Checkers Arcade</a></em> - <em>Using an American Checkers set to play many deep games of abstract strategy.</em></li> </ul> <h2 id=\"favorite-technical-books-discovered-and-read\">Favorite technical books discovered (and read)</h2> <ul> <li><strong><a href=\"http://mouse.davidgsimpson.com/\">Mouse, a Language for Microcomputers</a></strong> by Peter Grogono - <em>Mouse is basically an esolang with barely any abstraction facilities, but the book was well-written and the language compelling enough to explore further.</em></li> <li><strong><a href=\"https://explodingthephone.com/hoppdocs/nodd1956.pdf\">Notes on Distance Dialing</a></strong> (pdf) by AT&amp;T - <em>Described the telephone systems of the USA and Canada in the mid-1950s. The reading is a dry as it gets, but it was a fascinating dive into a vastly complex system solving extremely hard problems. This is a must-read for folks interested in systems-thinking. That said, I am actively looking for recommendations for books about the process of designing and building the unbelievably complex telephony system over the rudiments of the earlier systems. Recommendations welcomed!</em></li> </ul> <h2 id=\"favorite-non-technical-books-read\">Favorite non-technical books read</h2> <p>The vast majority of my reading this year was fiction, and I discovered some real gems.<a href=\"#fn3\" id=\"fnref3\" role=\"doc-noteref\"><sup>3</sup></a></p> <ul> <li><strong><a href=\"https://www.gutenberg.org/ebooks/24201\">The Eye of Osiris</a></strong> by R. Austin Freeman - <em>This is the first book that I’ve read from Freeman and I suspect that I will read many more in the future. The story follows the disappearance of John Bellingham, Egyptologist and the subsequent investigation. As the investigation stalls, the eminent Dr.&nbsp;Thorndyke digs into the case. The story sets up the mystery nicely and indeed provides enough information to the reader to infer how the disappearance occurred and who or what facilitated it. The book is one of the best whodunits that I’ve ever read.</em></li> <li><strong><a href=\"https://www.gutenberg.org/ebooks/564\">The Mystery of Edwin Drood</a></strong> by Charles Dickens - <em>His final work remains unfinished as he passed away before he could complete it. Further complicating the meta-story is that he also didn’t outline the ending nor even put to paper the “villain” of the story. The meta-mystery of the ending has motivated a mountain of speculation around the ending including dozens of continuations of the story from other authors, all deriving their pet endings from textual hints, accounts from Dickens’ friends, illustration notes, and even in some cases seances supposedly accompanied by the spirit of Dickens himself. What was written by Dickens is spectacular and a compelling mystery and although it would be great to know the resolution, in some ways the “Droodiana” that has cropped up over the past 150+ years is reason enough for it to remain a mystery. The whole lore around Edwin Drood is a worthwhile hobby in itself and well-worth exploring. The <a href=\"https://www.amazon.com/dp/B0000CHQCS/?tag=fogus-20\">Chiltern Library edition</a> of the book contains the story and a good bit of the lore around the writing and the meta-works available at the time of its publication.<a href=\"#fn4\" id=\"fnref4\" role=\"doc-noteref\"><sup>4</sup></a></em></li> <li><strong><a href=\"https://www.amazon.com/shadow-people-Margaret-St-Clair/dp/B00005XVNT/?tag=fogus-20\">The Shadow People</a></strong> by Margaret St.&nbsp;Clair - <em>Sadly out of print and difficult to find, but I’ve had it on my shelves for decades and finally got around to reading it. The book came onto my radar in the 1980s when I learned about it in the <a href=\"https://en.wikipedia.org/wiki/Appendix_N\">appendix-n</a> of the 1st edition Advanced D&amp;D Dungeon Masters Guide. I enjoyed many of the books at the time and have slowly swung around to re-reading them over the past few years. Sadly, most on the list do not stand the test of time for me, but St.&nbsp;Clair’s mixture of 60s counter-cultural leanings in a fantasy/sf world still works. The cultural touch-points in the book feel quite dated, but despite the occasional awkwardness, the story is unique even today.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/lolly-willowes-warbler-classics-annotated-edition-sylvia-townsend-warner/793f95da3bb968a0?aid=98208&amp;ean=9781959891635&amp;listref=best-things-2025&amp;next=t\">Lolly Willowes</a></strong> by Sylvia Townsend Warner - <em>The book started as a passable novel of manners focused on a turn of the century British middle-class family. The titular character was mostly background decoration for the first third of the novel and AFAIR was talked about only in the third-person. It’s only when she made the choice to move out on her own to the country<a href=\"#fn5\" id=\"fnref5\" role=\"doc-noteref\"><sup>5</sup></a> in her middle age does she gain a central role in the narrative and her inner thoughts revealed. This is where things really pick up because I was shocked to learn that this unassuming woman’s inner thoughts had a delicious darkness to them. I don’t want to give away too much, but I’ll just say that you will not expect how the story ends.</em></li> <li><strong><a href=\"https://www.fantagraphics.com/collections/daniel-clowes/products/patience\">Patience</a></strong> by Daniel Clowes - <em>A profound graphic novel using time-travel to explore the idea of enduring love with a story that proceed through time, following Jack as he tries to alter the past and save the woman he loves. This well-known science fiction motif is elevated by Clowes’ signature psychological complexity.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/narcissus-and-goldmund-hermann-hesse/2249287049aa22fb?aid=98208&amp;ean=9780553275865&amp;listref=best-things-2025&amp;next=t\">Narcissus and Goldmund</a></strong> by Herman Hesse - <em>I’ve read most of the books by Hermann Hesse but this one escaped my attention until this year. The story follows the parallel lives of a monk Narcissus and his passionate friend Goldmund as they respectively search for meaning in life through spiritual means and through pleasures of the flesh.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/we-who-are-about-to-joanna-russ/a7176b6dc2109f04?aid=98208&amp;ean=9780819567598&amp;listref=best-things-2025&amp;next=t\">We Who Are About To…</a></strong> by Joanna Russ - <em>A small group of astronauts crash land on a hostile alien world and quickly realize that rescue is unlikely to come. Many SF stories have started this way and so the expectation is that this is a colonization story… but Russ thrives on subverting reader expectations.</em></li> <li><strong><a href=\"https://tartaruspress.com/russell-fifty-forgotten-records.html\">Fifty Forgotten Records</a></strong> by R.B. Russell - <em>Another lovely entry in Russell’s series (one can hope) of autobiographical explorations of art, so far covering literature and now music. This book describes 50 records of varying popularity and Russell’s personal connections to each. While I certainly enjoyed finding a dozen or so new albums to explore, the true triumph of the book lies in the vulnerable, reflective memoir threaded throughout.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/the-way-of-all-flesh-samuel-butler/b5c2be53f34c9706?aid=98208&amp;ean=9780375752490&amp;listref=best-things-2025&amp;next=t\">The Way of All Flesh</a></strong> by Samuel Butler *A novel that follows 4-generations of the Ponitifex family, with a particular bildungsromanesque thread around Ernest, a young man who’s naivete leads to his downfall and how his life unfolds thereafter.<a href=\"#fn6\" id=\"fnref6\" role=\"doc-noteref\"><sup>6</sup></a></li> </ul> <h2 id=\"number-of-books-written-or-published\">Number of books written or published</h2> <p>As I mentioned, I have taken to writing more on non-technical topics, but I’ve even taken to dabble in fiction this year. I wrote a lot of fiction when I was (much) younger but all that I wrote from those days resides at the bottom of a landfill in Baltimore… which is probably for the best. I doubt that this avenue will result in any publications or even anything worth reading at all, but I’m having a great time regardless.</p> <h2 id=\"number-of-programming-languages-designed\">Number of programming languages designed</h2> <p>I’ve tinkered with a concatenative functional programming language named Juxt for years, but it’s not something that anyone should ever use. My thoughts are almost entirely focused exclusively on moving Clojure into the future, but I take a moment to think in stacks from time to time.<a href=\"#fn7\" id=\"fnref7\" role=\"doc-noteref\"><sup>7</sup></a></p> <h2 id=\"favorite-musicians-albums-discovered\">Favorite musicians / albums discovered</h2> <ul> <li><em><a href=\"https://lovesliescrushing.bandcamp.com/\">lovesliescrushing</a></em> - <em>It’s been quite a while since I’ve discovered any good ambient. This duo’s catalog has accompanied many of my 2025 coding activities.</em></li> <li><em><a href=\"https://deathandvanillamusic.bandcamp.com/album/whistle-and-ill-come-to-you\">Whistle And I’ll Come to You</a></em> by Death and Vanilla - <em>An album that conjures the atmosphere of folk horror films despite its electronic and psychedelic tones. It has a vaguely similar ethereal beauty that drew me to Dead Can Dance 100 years ago.</em></li> <li><em><a href=\"https://mariachiaramusic.bandcamp.com/album/closer\">Closer</a></em> by Maria Chiara Argirò - <em>Her jazz-infused electronic ambient music drilled its way into my ear and nested in my brain for months.</em></li> </ul> <p>The artist that I listened to the most in 2025 was <a href=\"https://cocteautwins.com/\">Cocteau Twins</a> – which probably mirrors a couple of years around when I was 15 or 16.<a href=\"#fn8\" id=\"fnref8\" role=\"doc-noteref\"><sup>8</sup></a></p> <h2 id=\"favorite-show-about-a-misanthrope-tasked-with-saving-a-humanity-that-might-not-be-worth-saving-at-all\">Favorite show about a misanthrope tasked with saving a humanity that might not be worth saving at all</h2> <p><a href=\"https://www.imdb.com/title/tt22202452/\">Pluribus</a></p> <h2 id=\"favorite-films-discovered\">Favorite films discovered</h2> <ul> <li><strong><a href=\"https://www.imdb.com/title/tt26581740/\">Weapons</a></strong> by Zach Cregger - <em>This one was probably my pick for the best new horror film released in 2025. Like Cregger’s other horror film <a href=\"https://www.imdb.com/title/tt15791034/\">Barbarian</a>,<a href=\"#fn9\" id=\"fnref9\" role=\"doc-noteref\"><sup>9</sup></a> Weapons mixed in black humor without being ham-handed about it. The highlight of the film was the performance by Amy Madigan, who stole every scene that she was in.</em></li> <li><strong><a href=\"https://www.imdb.com/title/tt7322224/\">Triangle of Sadness</a></strong> by Ruben Östlund - <em>Östlund is truly the master of the cringey moment, but his work is not “cringe comedy” as we commonly encounter. The cringe tension in his films instead comes from the mismatched expectations of the characters and a dogged insistence on magnifying the cringe that arises by stretching scenes to their breaking point.</em></li> </ul> <h2 id=\"favorite-podcasts\">Favorite podcasts</h2> <ul> <li><strong><a href=\"https://quietlittlehorrors.com/\">Quiet Little Horrors</a></strong> by <a href=\"https://jenmyers.net/about/\">Jen Meyers</a> and <a href=\"https://jessichartier.com/\">Jessi Chartier</a> - <em>By far my favorite horror-related podcast going right now. The cinematic analysis from the hosts is surpassed only by the texture of their personal experiences informing their analysis of films. I consider myself extremely lucky to have had the chance to sit down with the hosts and talk about Roman Polanski’s film, and Roland Topor’s book on which it’s based, <a href=\"https://bookshop.org/p/books/the-tenant-valancourt-international-roland-topor/b99ff27c8d84505f?aid=98208&amp;ean=9781948405775&amp;listref=best-things-2025&amp;next=t\">The Tenant</a> for their <a href=\"https://quietlittlehorrors.com/episode-06-14-the-tenant/\">penultimate 2025 episode</a>.</em></li> <li><strong><a href=\"https://open.spotify.com/show/0mYti5kalrRraItbZubwvk\">Beyond Yacht Rock 2000</a></strong> - <em>A podcast with a brilliant premise – devise a fictional genre of music and then try to find musicians, albums, and songs that adhere to that genre.</em></li> <li><strong><a href=\"http://www.youtube.com/channel/UCXat06LvIYIyE2SpV_IuVjA\">Malcom Guite</a></strong> - <em>Tolkien, Arthurian epic poetry, pipe-smoking… I wish this guy was my dad.</em></li> <li><strong><a href=\"https://www.youtube.com/@QuinnsIdeas\">Quinn’s Ideas</a></strong> - <em>I enjoy his long-form science fiction analysis, which is a YT genre that I typically skip. I’m pleased that the channel has so far avoided devolving into the inevitable booktube haul morass.</em></li> </ul> <h2 id=\"favorite-games-discovered\">Favorite games discovered</h2> <p>Usually tabletop games, but occasionally video games.</p> <ul> <li><strong>Jacoby</strong> - <em>While reading Montague Rhodes James’ memoir I came across the mention of a card game called Jacoby. After searching high and low for months, I finally found the rules in a book from 1890 titled The young folk’s cyclopædia of games and sports.<a href=\"#fn10\" id=\"fnref10\" role=\"doc-noteref\"><sup>10</sup></a> This long-lost game is a 3-player trick-taking game with some very nice tension.</em><a href=\"#fn11\" id=\"fnref11\" role=\"doc-noteref\"><sup>11</sup></a></li> <li><strong><a href=\"https://boardgamegeek.com/boardgame/354132/east-india-companies\">East India Companies</a></strong> designed by Pascal Ribrault - <em>The best tabletop game that I’ve found in 2-3 years. The game is a distilled <a href=\"https://blog.fogus.me/games/18XX/intro.html\">18XX</a> game with a dash of luck thrown in for good measure. It’s a purely stock holding and market manipulation game where a little bit of information compounds to large advantages if you can leverage it at the right time. I would play this 50 more times if I could.</em></li> <li><strong><a href=\"https://boardgamegeek.com/boardgame/262939/far-away\">Far Away</a></strong> designed by Alexander Jerabek - <em>A science fiction cooperative sandbox game for 2-players but that I’ve only ever played solo. While I think that the game as designed would be a better 2p affair, as a solo game it’s still an interesting world-builder. I enjoy the meta-nature of the game that allows the player(s) to not only build the world as they explore it, but they are tasked with defining the “mechanics” of the world along the way.</em></li> </ul> <ul> <li><em><a href=\"https://hypercubed.github.io/joy/joy.html\">Joy</a></em> - <em>Joy is a mindfrak of a programming language in the concatenative functional language family. The core of Joy is beautiful and among the foundational programming languages in my opinion.</em></li> </ul> <ul> <li><a href=\"http://www.clojure.org/\">Clojure</a> - <em>2025 marks the 16th year<a href=\"#fn12\" id=\"fnref12\" role=\"doc-noteref\"><sup>12</sup></a> as a full-time Clojure programmer.</em></li> <li><a href=\"https://mail.openjdk.org/pipermail/amber-spec-experts/2023-December/003959.html\">Java</a> - <em>Working deep in the Clojure compiler means that a portion of my 2025 work was in Java.</em></li> </ul> <ul> <li><em><a href=\"https://clojerl.org/\">Clojerl</a></em> - <em>There was once a dialect of Clojure targeting Erlang/BEAM so I would like to catch up on it to see where it stands.</em></li> <li><em><a href=\"https://github.com/babashka/scittle\">Scittle</a></em> - <em>A very lightweight, Clojure-like, skin on top of JavaScript that it super simple to include in HTML pages. I would like to produce something that uses Scittle to get a feel for its “Clojure-ness.”</em></li> </ul> <h2 id=\"favorite-papers-discovered-and-read\">Favorite papers discovered (and read)</h2> <p>none of particular note.</p> <h2 id=\"still-havent-read\">Still haven’t read…</h2> <p>I Ching, A Fire upon the Deep, Don Quixote, and <strong><a href=\"http://blog.fogus.me/2012/09/21/the-amazing-colossal-science-fiction-ketchup/\">a boat-load of sci-fi</a></strong></p> <h2 id=\"favorite-technical-conferences-attended\">Favorite technical conferences attended</h2> <ul> <li><em><a href=\"https://www.2025.clojure-conj.org/\">Clojure/conj 2025</a></em> - <em>The 2025 edition of the Conj was the first organized entirely by <a href=\"https://www.nubank.com/\">Nubank</a>’s amazing Clojure community-focused team: Magdalena Useglio, Christoph Neumann, and Jordan Miller. Unsurprisingly, I think that this was one of the best Clojure/conj events ever, and I’ve seen my fair share. I’m perpetually humbled to be part of a community of amazingly thoughtful Clojure friends.</em></li> <li><em><a href=\"https://sites.google.com/nubank.com.br/clojure-south\">Clojure South 2025</a></em> - <em>Before that I was fortunate to be in Brazil when Clojure South happened. I had such a great time and was impressed by how well the conference was run. I met many new Clojure programmers and dozens of brilliant Brazilian programmers for the first time. I would love to attend the next one if at all possible.</em></li> </ul> <h2 id=\"favorite-code-read\">Favorite code read</h2> <ul> <li><em><a href=\"https://www.redblobgames.com/grids/hexagons/implementation.html\">Implementation of Hex Grids</a></em> - <em>Useful functions for game developers/designers.</em></li> <li><em><a href=\"https://small-js.org/Home/Home.html\">SmallJS</a></em> - <em>A little Smalltalk-80 that compiles to JavaScript.</em></li> <li><em><a href=\"https://github.com/historicalsource/zork1\">Zork I</a></em> - <em>The original Zork source code. I’ve only started digging into the <a href=\"https://setsideb.com/learning-zork-implementation-language-by-steve-meretzky/\">ZIL</a> definitions, but I plan to keep digging for months to come.</em></li> <li><em><a href=\"https://computerhistory.org/blog/xerox-alto-source-code/\">Xerox Alto</a></em> - <em>So far I’ve only scratched the surface of the mountains of system code in the archive. The wisdom contained in here is likely to take a lifetime to explore.</em><a href=\"#fn13\" id=\"fnref13\" role=\"doc-noteref\"><sup>13</sup></a></li> </ul> <h2 id=\"life-changing-technology-discovered\">Life-changing technology “discovered”</h2> <ul> <li><em>LLMs</em> <em>are here to stay, so it behooves me to learn to navigate this new world. That said…</em></li> <li><em><a href=\"https://en.wikipedia.org/wiki/Zettelkasten\">Zettelkasten</a></em> <em>… has had a much larger impact on my life in 2025. I’ve only just started collecting my notes using the system, but I’ve managed to leverage the system to put together a handful of non-technical posts (see the section on my posts above) this year and found the system very helpful in composing ideas. This is a long-term WiP, but I’ve very pleased so far.</em><a href=\"#fn14\" id=\"fnref14\" role=\"doc-noteref\"><sup>14</sup></a></li> </ul> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-zettelkasten-ca.jpg\" alt=\"Some Zettelkasten notes used for Checkers Arcade post\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <h2 id=\"state-of-plans-from-2025\">State of plans from 2025</h2> <p>2025 was a particularly productive year for meeting my plans for the year. Starting early in the year I knew that I needed a better way to track my tasks. So to start the year I visited a couple of Japanese stationary stores<a href=\"#fn15\" id=\"fnref15\" role=\"doc-noteref\"><sup>15</sup></a> to get some ideas. In 2024 I had used the Hobonichi Techo<a href=\"#fn16\" id=\"fnref16\" role=\"doc-noteref\"><sup>16</sup></a> and while I found it to be a lovely system, it didn’t quite work for me. First, it wasn’t clear how or if I was making progress on my tasks without spelunking into the past pages of the schedule. Second, I take a lot of notes longhand in cheap composition notebooks and so I found myself jumping back and forth between those and the Hobonichi. I tried using an insert into my Techo case for note-taking but I didn’t like the form-factor. I take big sprawling notes and filled the pages too quickly. So after the new year I took a minimalist approach with a Japanese calendar stamp:</p> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-stamp-cal.jpg\" alt=\"Rubber stamp calendar\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <p>The image above shows an example, but the problem with it should be apparent… there’s just not enough room for fidelity. OK, sure it didn’t work as a real task tracker, but I still use it to keep track of small bits of detail associated with days of the week like: energy level, mood, sleep, exercise, etc. It became apparent that I needed something that solved three problems: 1) track any number of tasks, 2) give me an idea of my progress at a glance, and 3) be on hand already. My first pass at this was to draw a 4-week grid on my notebook and scribble tasks in pencil into the cells. I would then color the grid as I progressed through tasks. This worked great for about 5 weeks until I went on a week-long trip without my notebook, killing my solution to #3. Even before that however I had found that I wanted to make frequent changes and move things around, defer items, and change the colors, so it became apparent that I had another problem to solve; 4) allow for easy change. While I was on my week-long trip I decided to find a solution that account for all four of my problems, and it turned out that my solution was the solution to so many other problems… spreadsheets!</p> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-tasks-sheet.jpg\" alt=\"My ongoing tasks sheet\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <p>Above you’ll see a representational image that gives the basics of the task tracking. The rows correspond to tasks and the columns to the months. The white section on the left are the tasks details like category, name, description, and success criteria. The colored segments represent the state of the tasks regarding progress. The left-most colored column is the current month. Each cell is filled in before the month starts with high-level goals which are amended and modified as I make progress (or not). The meaning of the colors are:</p> <ul> <li>Light green: Task completed and success criteria met</li> <li>Dark green: Task completed, but its success criteria changed during the process</li> <li>Light orange: Not started</li> <li>Dark orange: In progress (not shown above)</li> <li>Red: Incomplete and/or unsuccessful</li> <li>Gray: Not applicable. This is for new tasks that are added to the tracker, or removed and brought back. All months are back-filled in gray.</li> </ul> <p>And that’s the whole system. It’s easy to change and rearrange. It’s on-hand.<a href=\"#fn17\" id=\"fnref17\" role=\"doc-noteref\"><sup>17</sup></a> I can see how I’m doing at a glance. Can track any number of simultaneous tasks. Perfect.</p> <p>Enough of this meta-discussion… how did my plans for 2025 go?</p> <ul> <li><em><a href=\"https://www.clojure.org/\">Clojure 1.13</a></em> - <em>While a 1.13 release didn’t happen, we did release numerous updates to 1.12 and made plans for how to fill out the next version.</em></li> <li><em><a href=\"https://github.com/clojure/core.async\">core.async next</a></em> - <em>We made some interesting changes to core.async to leverage JDK 21+ virtual threads, but before that we made changes to smooth the path for allowing opt-in use of vthreads. At the moment there are some challenges around the way that the JVM tracks vthreads, but I feel pretty good that if we can address those then the implementation is solid.</em></li> <li><em><a href=\"https://blog.fogus.me/\">Simplify my blog</a></em> - <em>I completely moved away from Wordpress onto a hacked-together Markdown/org-mode + pandoc + bash to static pipeline. It’s a piece of junk, but so much more lightweight that what I had running for years.</em></li> <li><em><a href=\"https://gist.github.com/fogus/224d658be2a1afaaffe4ac1f25d1fa61\">Juxt</a></em> - <em>Juxt is my exploration in functional concatenative language design built on the JVM. It’s not yet clear to me if or when I would ever release this into the wild, but the explorations have been great fun and I’ve used Juxt as a vehicle for finding relevant books and papers.<a href=\"#fn18\" id=\"fnref18\" role=\"doc-noteref\"><sup>18</sup></a> That said, most of my programming time is spent maintaining and evolving Clojure, but there are rare moments of time that I can spend on Juxt, and I plan to continue to do so in 2025. You’ll see some interesting progress in the gist link.</em></li> </ul> <h2 id=\"plans-for-2026\">Plans for 2026</h2> <ul> <li><em>More non-technical writing in 2026.</em> - <em>I would like to continue explorations of fiction and games. That’s not to say that there aren’t a few technical posts in me still, but they will not be my priority.</em></li> <li><em>Publish the rules for a card game of my own design.</em> - <em>I have a couple in the pipeline, and feel like one of them could be a keeper.</em></li> <li><em><a href=\"https://www.clojure.org/\">Clojure 1.13</a></em> - <em>Thinking around the 1.13 release is ongoing and we’d like to get it out sooner rather than later. Stay tuned.</em></li> <li><em>Create something with my hands</em> - <em>I have no idea what this might be, but I’ve been putting off artifact creation for waaaaay too long.</em></li> <li><em>Read more non-fiction</em> - <em>I’m particularly interested in biographies and books-on-books.</em><a href=\"#fn19\" id=\"fnref19\" role=\"doc-noteref\"><sup>19</sup></a></li> <li><em>Read an untranslated book</em> - <em>Inspired by the <a href=\"https://theuntranslated.wordpress.com/\">Untranslated Blog</a>… my best chance for success is something written in French. Topic TBD.</em></li> </ul> <h2 id=\"tech-radar\">2026 Tech Radar</h2> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-zettelkasten.jpg\" alt=\"My Zettelkasten stack\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <ul> <li>try: <a href=\"https://www.goodnotes.com/\">Goodnotes</a> - <em>I’ve bounced off of numerous note-taking apps in my time, but my older son swears by it for annotating PDFs.</em></li> <li>adopt: <a href=\"https://www.amazon.com/Antinet-Zettelkasten-Knowledge-Prolific-Researcher/dp/B0BPVTBYG7/?tag=fogus-20\">Antinet Zettelkasten</a> - <em>I used my growing card file to great effect while writing a few essays this year.</em></li> <li>assess: LLMs - <em>I’m into the 3rd AI hype-cycle in my life (at least) and this is not much different than they other two, save for the potential market and job disruptions in play. I tried in earnest to make AI work for me, with varying degrees of un-success. I’ve had zero success leveraging it in my work maintaining and evolving Clojure. For problem formation in the face of novelty, LLMs have been more frustrating than helpful and the little gains that I’ve found were in the very early phases of problem solving requiring a bare minimum of experimental code. But even these examples operate wholly in the known rather than in the unknown where I’d like to operate instead. Even in these early stages the “hand-holding” involved was more frustrating than helpful. In my work, the bottleneck is absolutely not the code. While I think that the kind of up-front work that I do could inform prompt-engineering to some degree, by the time that I get to that point the code is often perfunctory. Most of the work that I do is devising and investigating new problem framing rather than in interpolation of the known (i.e.&nbsp;analogy play). While the latter is important for sure, what’s known often acts as a source of tension to help motivate and tease out potentially new solutions. And this is a huge problem in the very nature of LLMs. That is, they are trained on the products of problem solving processes rather then also in the very processes themselves. Further, as a Socratic partner, LLMs are incredibly frustrating in their inability to move a “discussion” forward. A good Socratic partner creates pressure to move toward truth, but LLMs are too sycophantic, lack an awareness of useful tension,<a href=\"#fn20\" id=\"fnref20\" role=\"doc-noteref\"><sup>20</sup></a> cannot often identify contradiction, and lack any ability to adhere to the trajectory of a conversation. So far I’m left wanting, but because LLMs are likely to never go away then I’ll see if these downsides get better in the future.</em><a href=\"#fn21\" id=\"fnref21\" role=\"doc-noteref\"><sup>21</sup></a></li> <li>hold: <a href=\"https://www.amazon.com/BOOX-Tablet-Go-10-3-ePaper/dp/B0D4DFT3W3/?tag=fogus-20\">Boox Go 10.3 tablet</a> - <em>I just couldn’t pull the trigger on this and suspect that I will not ever.</em><a href=\"#fn22\" id=\"fnref22\" role=\"doc-noteref\"><sup>22</sup></a></li> <li>stop: <a href=\"https://www.typescriptlang.org/\">TypeScript</a> - <em>I just don’t do enough in this space to justify continuing down this road.</em></li> </ul> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-c64ai.jpg\" alt=\"Have you heard of an AI?\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <h2 id=\"people-who-inspired-me-in-2025-in-no-particular-order\">People who inspired me in 2025 (in no particular order)</h2> <p>Yuki, Keita, Shota, Craig Andera, Carin Meier, Justin Gehtland, Rich Hickey, Nick Bentley, Paula Gearon, Zeeshan Lakhani, Brian Goetz, David Nolen, Jeb Beich, Paul Greenhill, Kristin Looney, Andy Looney, Kurt Christensen, Samm Deighan, David Chelimsky, Chas Emerick, Stacey Abrams, Paul deGrandis, Nada Amin, Michiel Borkent, Alvaro Videla, Slava Pestov, Yoko Harada, Mike Fikes, Dan De Aguiar, Christian Romney, Russ Olsen, Alex Miller, Adam Friedman, Tracie Harris, Alan Kay, Wayne Applewhite, Naoko Higashide, Zach Tellman, Nate Prawdzik, Bobbi Towers, JF Martel, Phil Ford, Nate Hayden, Sean Ross, Tim Good, Chris Redinger, Steve Jensen, Christian Freeling, Jordan Miller, Mia, Christoph Neumann, Tim Ewald, Stu Halloway, Jack Rusher, Jenn Meyers, Michael Berstein, Benoît Fleury, Rafael Ferreira, Robert Randolph, Joe Lane, Renee Lee, Pedro Matiello, Jarrod Taylor, Magdalena Useglio, Jaret Binford, Ailan Batista, Matheus Machado, Quentin S. Crisp, John Cooper, Conrad Barski, Amabel Holland, Ben Kamphaus, Barry Malzberg (RIP), Kory Heath (RIP).</p> <p>Onward to 2026!</p> <p>:F</p> <section id=\"footnotes\" role=\"doc-endnotes\"> <hr> <ol> <li id=\"fn1\"><p>The video has similar vibes to Haruki Murakami’s excellent book After Dark.<a href=\"#fnref1\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn2\"><p>I’d love to try and write something about Corvo’s obsession with the Catholic hierarchy and the tenuous idea that it was a kind of occult architecture. This may be a bridge too far for my ability and knowledge.<a href=\"#fnref2\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn3\"><p>I have some of these books listed at <a href=\"https://bookshop.org/lists/best-things-2025\">bookshop.org</a> if you’re interested in grabbing copies.<a href=\"#fnref3\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn4\"><p>A lot more Droodiana has been written since 1950 of course.<a href=\"#fnref4\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn5\"><p>The “move to the country” theme present in a significant number of pre-WWII fiction representing a reclamation of feminine power. I would love to find/create a list of books exploring this theme.<a href=\"#fnref5\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn6\"><p>Interestingly, this was a recommendation from friend <a href=\"https://www.linkedin.com/in/david-nolen-37b42813/\">David Nolen</a>, who also mentioned another book that just barely missed this list, <a href=\"https://bookshop.org/p/books/melville-s-short-novels-authoritative-texts-contexts-criticism-herman-melville/f3008086921a816b?aid=98208&amp;ean=9780393976410&amp;listref=best-things-2025&amp;next=t\">Benito Cereno</a> which I think needs another read in the future.*<a href=\"#fnref6\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn7\"><p>If you’re interested in exploring an interesting new programming language that mixes interesting ideas, then I recommend <a href=\"https://www.uiua.org/\">Uiua</a> that bills itself as a point-free, APL-style, array-oriented modern language.<a href=\"#fnref7\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn8\"><p>I was in a “junk shop” a couple of weeks ago and found both Black Sabbath’s <em>Master of Reality</em> and the <em>Complete Vatican Recordings</em> of the works of Alessandro Moreschi… two albums that couldn’t be more different. I suspect that one of both of these albums will get a lot of play in 2026.<a href=\"#fnref8\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn9\"><p>I could have also added Cregger’s <em>Barbarian</em> to the year’s best filmatic discoveries, but I would like another watch to really focus in on the depths.<a href=\"#fnref9\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn10\"><p>I also found a POD copy of the Nichureki, a 13th-century Japanese book containing the earliest written record of Heian Shogi… a topic for another day perhaps.<a href=\"#fnref10\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn11\"><p>I wrote an essay about Jacoby and its connection to the author M.R. James that is due to be published next year in the journal <em>Ghosts and Scholars</em> #50.<a href=\"#fnref11\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn12\"><p>This is strictly my work-life time. My total use of Clojure has been longer.<a href=\"#fnref12\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn13\"><p>While the Alto source code is certainly interesting, it’s unclear how the repository credits Douglas Engelbart’s NLS vision and Intellect Augmentation, if at all.<a href=\"#fnref13\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn14\"><p>My ultimate dream is to build a giant card-file and then build a Jack Kirby-esque relentless idea-collage universe along the lines of his “Fourth World” mythos tying together all of the concepts in said file… I may need another lifetime for this.<a href=\"#fnref14\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn15\"><p>Japanese stationary stores and thrift-shops are two of my guilty pleasures. Has anyone else noticed that in the States, there are more young people shopping in thrift shops than ever before. I would love to understand why. Is it a growing prevalence of Tik-Tok thrift-haul videos, an appreciation for retro, an economic indicator, all, some, or none?<a href=\"#fnref15\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn16\"><p>I put my best effort into the Techo, but I could never fully buy into the very Japanese view of the planner as a life-book.<a href=\"#fnref16\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn17\"><p>I’m already in Google Sheets all the time anyway, and can access it on my phone if needed. Really though, I’d love to see a device in the spirit of the TRS-80 model 100 to do this kind of work on the go… but I would still probably not get one. ¯_(ツ)_/¯<a href=\"#fnref17\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn18\"><p>You can see the <em>current</em> <a href=\"https://gist.github.com/fogus/6d716276678b0698c96dd13e040c71eb\">Juxt bibtex</a> on GitHub.<a href=\"#fnref18\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn19\"><p>I would also love to read the complete work of the comic book creator Jack Kirby. There are some lovely omnibus editions of his work, but I don’t quite know how I feel about the fact that the comics industry is embracing this format. Certainly singles are a joke, but omnibuses have turned comics enjoyment from reading into weightlifting.<a href=\"#fnref19\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn20\"><p>The tension problem is also why I’ve found LLMs to be terrible at aiding tabletop game design. A prime characteristic of the kinds of games that I enjoy is emergent complexity, but if LLMs identify complexity at all, they have so far been terrible at deciding which complexity is useful. That is, LLMs have no notion of “delicious tension” nor how to devise it.<a href=\"#fnref20\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn21\"><p>A huge problem with LLMs are that they are by their very nature dependent on digitized information. While a larger proportion of scientific and computing information is available in digitized form, there are still whole fields of knowledge left on paper, so to speak. First, a large problem with this fact is that only a small fraction of total knowledge is available to training LLMs, leaving large gaps in the knowledge base exacerbating the problem of decoupled confidence and reality. Second, this is problematic because training these models on digital-data leads to an amplification of the biases inherent in the digitized records. This can be mitigated by the search-augmented and human-in-the-loop systems, but these are also incomplete sources of validation and even the validation itself has bias (e.g.&nbsp;SEO, status quo, liability constraints, etc.) and often reduce the traceability of an answer. A second informational downside of LLMs is that they take training data at face-value rather than inherent value. However, in my programming career I’ve learned a lot more from bad code than good code. Likewise, code input to training is heavily biased to work at all and the ingestion itself it geared strictly to work to build a plausible-continuation model. Good code works as exemplars of clarity, layering abstractions, maintainability, and sad-path security, but so does bad code. Heavily curated or contrasting training data could mitigate this to some degree, but at the moment, a lot of the code generated by LLMs is often lacking these fundamental code characteristics. This matches my actual observation of code generation, but I would imagine that the inability of the ingestion to distinguish valid examples from cautionary examples is more general problem. These are all technical points and do not take into account the societal problems that LLMs present… which are bountiful! These are evolving critiques that I’ll refine through more exposure.<a href=\"#fnref21\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn22\"><p>The Boox is a truly lovely device, but I’ve developed a diametric motivation to de-device myself. This was born from my perennial obsession with Cyberdecks and “minimalist” writing devices. Every so often I’m hit with a driving urge to build such things, but then I get turned off by the supporting communities around them, especially its gross fetishization of an “aesthetic of productivity” where the act of building (and buying of course) these tools supersedes and stands-in for their actual use.<a href=\"#fnref22\" role=\"doc-backlink\">↩︎</a></p></li> </ol> </section> </div>"},{"id":"https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/","title":"QNX Self-Hosted Developer Desktop","link":"https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46398201","content":"<a href=\"https://news.ycombinator.com/item?id=46398201\">Comments</a>","date":1766798213000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<section> <p>The team and I are beyond excited to share what we've been cooking up over the last little while: <strong>a full desktop environment running on QNX 8.0, with support for self-hosted compilation</strong>! This environment both makes it easier for newly-minted QNX developers to get started with building for QNX, but it also vastly simplifies the process of porting Linux applications and libraries to QNX 8.0.</p><p>This self-hosted target environment is pre-loaded with many of the ports you'll find on <a href=\"https://oss.qnx.com/?ref=devblog.qnx.com\" rel=\"noreferrer\">the QNX Open-source Dashboard</a>. (The portal currently includes over 1,400 ports across various targets, QNX versions, and architectures, of which more than 600 are unique ports!)</p><p>In this initial release, you can grab a copy of the QEMU image and give it a try for yourself. There's still so much more to add, but it's in a great place today for this first release. The team is really passionate about this one, and we're eagerly looking forward to your feedback!</p><h2 id=\"whats-included\">What's Included</h2><p>For the initial release of Desktop, we tried to cover all the basics: windowing, terminal, IDEs, browser, file management, and samples. To that end, here's what makes up the QNX Developer Desktop:</p><ul><li>A customizable XFCE desktop environment running on Wayland</li><li>The tools you need to compile and/or run your code (<code>clang</code>, gcc, <code>clang++</code>, Python, <code>make</code>, <code>cmake</code>, <code>git</code>, etc)</li><li>A web browser (can you join <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">the QNX Discord</a> from the QNX Desktop? 🏅👀)</li><li>Ports of popular IDEs/editors, like Geany, Emacs, Neovim, and vim</li><li>Thunar, for file management</li><li>Preloaded samples, like Hello World in C, C++, and Python, and GTK demos OpenGL ES demos</li><li>... and of course, a terminal.</li></ul><h2 id=\"system-requirements\">System Requirements</h2><p>This environment runs as a virtual machine, using QEMU on Ubuntu. To try the image, you'll need:</p><ul><li>Ubuntu 22.04 or 24.04</li></ul><h2 id=\"try-it-yourself\">Try It Yourself</h2><p>(Keep in mind this is the first release, so it takes a minute to get started and it's a bit rough around the edges.)</p><p>With <a href=\"https://qnx.com/getqnx?ref=devblog.qnx.com\" rel=\"noreferrer\">a free QNX license</a>, you can find this release in QNX Software Center. On the <strong>Available</strong> tab of the <strong>Manage Installation</strong> pane, search for \"quick start\" and install the \"QNX SDP 8.0 Quick Start Target Image for QEMU\".</p><p>You'll find the image in your QNX installation directory, usually <code>~/qnx800/images</code> by default. Follow the <code>README.md</code> file in the <code>qemu</code> directory to extract &amp; combine the multiple QNX packages downloaded under the hood.</p><p>Next, follow the PDF instructions found in the new <code>./qemu_qsti/docs/</code> directory to install the required dependencies and boot up.</p><div><p>💡</p><p>If you experience any trouble starting the environment, check the PDF's <b><strong>Troubleshooting</strong></b> chapter, or come <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">ask us on Discord</a>.</p></div><h2 id=\"whats-next\">What's Next</h2><p>This is just the very first release! Over the next few months and beyond, we'll drop more updates of Desktop. You can look forward to:</p><ul><li>QEMU images for Windows &amp; macOS, and native images for x86</li><li>A native Desktop image on Raspberry Pi</li><li>Enhanced documentation</li><li>Features to help use this self-hosted environment in CI jobs</li><li>More samples &amp; stability</li><li>... and more! Have suggestions? Let us know.</li></ul><p>Lastly, if you want some help with your QNX journey, you can find the QNX team and community:</p><ul><li>in Discord here: <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">discord.gg/Jj4EkkrFTT</a></li><li>on Reddit at: <a href=\"https://reddit.com/r/qnx?ref=devblog.qnx.com\" rel=\"noreferrer\">reddit.com/r/qnx</a></li></ul> </section>"},{"id":"https://www.eff.org/deeplinks/2025/12/ai-police-reports-year-review","title":"AI Police Reports: Year in Review","link":"https://www.eff.org/deeplinks/2025/12/ai-police-reports-year-review","hnCommentsUrl":"https://news.ycombinator.com/item?id=46367195","content":"<a href=\"https://news.ycombinator.com/item?id=46367195\">Comments</a>","date":1766511015000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div><p><span>In 2024, EFF wrote our initial blog about </span><a href=\"https://www.eff.org/deeplinks/2024/05/what-can-go-wrong-when-police-use-ai-write-reports\"><span>what could go wrong when police let AI write police reports</span></a><span>. Since then, the technology has proliferated at a disturbing rate. Why? The most popular generative AI tool for writing police reports is Axon’s Draft One, and Axon also happens to be the largest provider of body-worn cameras to police departments in the United States. As we’ve written, companies are increasingly </span><a href=\"https://www.eff.org/deeplinks/2025/04/beware-bundle-companies-are-banking-becoming-your-police-departments-favorite\"><span>bundling their products</span></a><span> to make it easier for police to buy more technology than they may need or that the public feels comfortable with.&nbsp;</span></p> <p><span>We have good news and bad news.&nbsp;</span></p> <p><b>Here’s the bad news:</b><span> AI written police reports are still unproven, untransparent, and downright irresponsible–especially when the criminal justice system, informed by police reports, is deciding people’s freedom. The King County prosecuting attorney’s office in Washington state </span><a href=\"https://www.eff.org/deeplinks/2024/10/prosecutors-washington-state-warn-police-dont-use-gen-ai-write-reports\"><span>barred police from using AI to write police reports</span></a><span>. As their </span><a href=\"https://komonews.com/amp/news/local/king-county-prosecutor-tells-police-not-to-use-ai-artificial-intelligence-for-official-reports-for-now-errors-concerns-law-enforcement-perjury-criminal-justice\"><span>memo</span></a><span> read, “We do not fear advances in technology – but we do have legitimate concerns about some of the products on the market now... AI continues to develop and we are hopeful that we will reach a point in the near future where these reports can be relied on. For now, our office has made the decision not to accept any police narratives that were produced with the assistance of AI.”&nbsp;</span></p> <p><span>In July of this year, EFF published a </span><a href=\"https://www.eff.org/deeplinks/2025/07/axons-draft-one-designed-defy-transparency\"><span>two-part </span></a><span>report on how Axon designed Draft One to defy transparency. Police upload their body-worn camera’s audio into the system, the system generates a report that the officer is expected to edit, and then the officer exports the report. But when they do that, Draft One erases the initial draft, and with it any evidence of what portions of the report were written by AI and what portions were written by an officer. That means that if an officer is caught lying on the stand – as shown by a contradiction between their courtroom testimony and their earlier police report – they could point to the contradictory parts of their report and say, “the AI wrote that.” Draft One is designed to make it hard to disprove that.&nbsp;</span></p> <p><span>In this video of a</span><a href=\"https://vimeo.com/941650612\"> <span>roundtable discussion about Draft One</span></a><span>, Axon’s senior principal product manager for generative AI is asked (at the 49:47 mark) whether or not it’s possible to see after-the-fact which parts of the report were suggested by the AI and which were edited by the officer. His response (bold and definition of RMS added):&nbsp;</span></p> <p><span>“</span><b>So we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices</b><span>—so basically the officer generates that draft, they make their edits, if they submit it into our Axon records system then that’s the only place we store it, if they copy and paste it into their third-party RMS [records management system] system as soon as they’re done with that and close their browser tab, it’s gone. It’s actually never stored in the cloud at all so you don’t have to worry about extra copies floating around.”</span></p> <p><span>Yikes!&nbsp;</span></p> <p><span>All of this obfuscation also makes it incredibly hard for people outside police departments to figure out if their city’s officers are using AI to write reports–and even harder to use public records requests to audit just those reports. That’s why this year EFF also put out a </span><a href=\"https://www.eff.org/deeplinks/2025/07/effs-guide-getting-records-about-axons-ai-generated-police-reports\"><span>comprehensive guide</span></a><span> to help the public make their records requests as tailored as possible to learn about AI-generated reports.&nbsp;</span></p> <p><b>Ok, now here’s the good news:&nbsp;</b><span>People who believe AI-written police reports are irresponsible and potentially harmful to the public are fighting back.&nbsp;</span></p> <p><span>This year, two states have passed bills that are an important first step in reigning in AI police reports. Utah’s </span><a href=\"https://le.utah.gov/~2025/bills/static/SB0180.html\"><span>SB 180</span></a><span> mandates that police reports created in whole or in part by generative AI have a disclaimer that the report contains content generated by AI. It also requires officers to certify that they checked the report for accuracy. </span><a href=\"https://www.eff.org/deeplinks/2025/10/victory-california-requires-transparency-ai-police-reports\"><span>California’s SB 524</span></a><span> went even further. It requires police to disclose, on the report, if it was used to fully or in part author a police report. Further, it bans vendors from selling or sharing the information a police agency provided to the AI. The bill also requires departments to retain the first draft of the report so that judges, defense attorneys, or auditors could readily see which portions of the final report were written by the officer and which portions were written by the computer.</span></p> <p><span>In the coming year, anticipate many more states joining California and Utah in regulating, or perhaps even banning, police from using AI to write their reports.&nbsp;</span></p> <p><span><span><i>This article is part of our Year in Review series. <a href=\"https://www.eff.org/tags/2025-review\">Read other articles</a> about the fight for digital rights in 2025.</i></span></span></p> </div>"},{"id":"https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html","title":"Package managers keep using Git as a database, it never works out","link":"https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46391514","content":"<a href=\"https://news.ycombinator.com/item?id=46391514\">Comments</a>","date":1766753196000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div itemprop=\"articleBody\"> <p>Using git as a database is a seductive idea. You get version history for free. Pull requests give you a review workflow. It’s distributed by design. GitHub will host it for free. Everyone already knows how to use it.</p> <p>Package managers keep falling for this. And it keeps not working out.</p> <h2 id=\"cargo\">Cargo</h2> <p>The crates.io index started as a git repository. Every Cargo client cloned it. This worked fine when the registry was small, but the index kept growing. Users would see progress bars like “Resolving deltas: 74.01%, (64415/95919)” hanging for ages, the visible symptom of Cargo’s libgit2 library grinding through <a href=\"https://github.com/rust-lang/cargo/issues/9069\">delta resolution</a> on a repository with thousands of historic commits.</p> <p>The problem was worst in CI. Stateless environments would download the full index, use a tiny fraction of it, and throw it away. Every build, every time.</p> <p><a href=\"https://rust-lang.github.io/rfcs/2789-sparse-index.html\">RFC 2789</a> introduced a sparse HTTP protocol. Instead of cloning the whole index, Cargo now fetches files directly over HTTPS, downloading only the metadata for dependencies your project actually uses. (This is the “<a href=\"https://nesbitt.io/2025/12/05/package-manager-tradeoffs.html\">full index replication vs on-demand queries</a>” tradeoff in action.) By April 2025, 99% of crates.io requests came from Cargo versions where sparse is the default. The git index still exists, still growing by thousands of commits per day, but most users never touch it.</p> <h2 id=\"homebrew\">Homebrew</h2> <p><a href=\"https://github.com/Homebrew/brew/pull/9383\">GitHub explicitly asked Homebrew to stop using shallow clones.</a> Updating them was <a href=\"https://brew.sh/2023/02/16/homebrew-4.0.0/\">“an extremely expensive operation”</a> due to the tree layout and traffic of homebrew-core and homebrew-cask.</p> <p>Users were downloading 331MB just to unshallow homebrew-core. The .git folder approached 1GB on some machines. Every <code>brew update</code> meant waiting for git to grind through delta resolution.</p> <p>Homebrew 4.0.0 in February 2023 switched to JSON downloads for tap updates. The reasoning was blunt: “they are expensive to git fetch and git clone and GitHub would rather we didn’t do that… they are slow to git fetch and git clone and this provides a bad experience to end users.”</p> <p>Auto-updates now run every 24 hours instead of every 5 minutes, and they’re much faster because there’s no git fetch involved.</p> <h2 id=\"cocoapods\">CocoaPods</h2> <p>CocoaPods is the package manager for iOS and macOS development. It hit the limits hard. The Specs repo grew to hundreds of thousands of podspecs across a deeply nested directory structure. Cloning took minutes. Updating took minutes. CI time vanished into git operations.</p> <p>GitHub imposed CPU rate limits. The culprit was shallow clones, which force GitHub’s servers to compute which objects the client already has. The team tried various band-aids: stopping auto-fetch on <code>pod install</code>, converting shallow clones to full clones, <a href=\"https://blog.cocoapods.org/Sharding/\">sharding the repository</a>.</p> <p>The CocoaPods blog captured it well: <a href=\"https://blog.cocoapods.org/Master-Spec-Repo-Rate-Limiting-Post-Mortem/\">“Git was invented at a time when ‘slow network’ and ‘no backups’ were legitimate design concerns. Running endless builds as part of continuous integration wasn’t commonplace.”</a></p> <p>CocoaPods 1.8 <a href=\"https://blog.cocoapods.org/CocoaPods-1.8.0-beta/\">gave up on git entirely</a> for most users. A CDN became the default, serving podspec files directly over HTTP. The migration saved users about a gigabyte of disk space and made <code>pod install</code> nearly instant for new setups.</p> <h2 id=\"nixpkgs\">Nixpkgs</h2> <p>Nix already solved the client-side problem. The package manager fetches expressions as <a href=\"https://releases.nixos.org/nix/nix-2.13.6/manual/package-management/channels.html\">tarballs via channels</a>, served from S3 and CDN, not git clones. Binary caches serve built packages over HTTP. End users never touch the git repository.</p> <p>But the repository itself is stress-testing GitHub’s infrastructure. In November 2025, GitHub contacted the NixOS team about <a href=\"https://discourse.nixos.org/t/nixpkgs-core-team-update-2025-11-30-github-scaling-issues/72709\">periodic maintenance jobs failing</a> and causing “issues achieving consensus between replicas.” If unresolved, the repository could have become read-only.</p> <p>The repository totals 83GB with half a million tree objects and 20,000 forks. A local clone is only 2.5GB. The rest is GitHub’s fork network storing every pull request branch and merge commit. The CI queries mergeability daily, creating new merge commits each time.</p> <h2 id=\"vcpkg\">vcpkg</h2> <p>vcpkg is Microsoft’s C++ package manager. It uses git tree hashes to version its ports, with the curated registry at <a href=\"https://github.com/Microsoft/vcpkg\">github.com/Microsoft/vcpkg</a> containing over 2,000 libraries.</p> <p>The problem is that vcpkg needs to retrieve specific versions of ports by their git tree hash. When you specify a <code>builtin-baseline</code> in your vcpkg.json (functioning like a lockfile for reproducible builds), vcpkg looks up historical commits to find the exact port versions you need. This only works if you have the full commit history.</p> <p>Shallow clones break everything. GitHub Actions uses shallow clones by default. DevContainers <a href=\"https://github.com/devcontainers/images/issues/398\">shallow-clone vcpkg</a> to save space. CI systems optimize for fast checkouts. All of these result in the same error: “vcpkg was cloned as a shallow repository… Try again with a full vcpkg clone.”</p> <p>The workarounds are ugly. One <a href=\"https://github.com/devcontainers/images/issues/398\">proposed solution</a> involves parsing vcpkg.json to extract the baseline hash, deriving the commit date, then fetching with <code>--shallow-since=&lt;date&gt;</code>. Another suggests including twelve months of history, hoping projects upgrade before their baseline falls off the cliff. For GitHub Actions, you need <code>fetch-depth: 0</code> in your checkout step, <a href=\"https://github.com/microsoft/vcpkg/issues/25349\">downloading the entire repository history</a> just to resolve dependencies.</p> <p>A vcpkg team member <a href=\"https://github.com/microsoft/vcpkg/issues/25349\">explained the fundamental constraint</a>: “Port versions don’t use commit hashes, we use the git tree hash of the port directory. As far as I know, there is no way to deduce the commit that added a specific tree hash.” An in-product fix is infeasible. The architecture baked in git deeply enough that there’s no escape hatch.</p> <p>Unlike Cargo, Homebrew, and CocoaPods, vcpkg hasn’t announced plans to move away from git registries. Custom registries must still be git repositories. The documentation describes filesystem registries as an alternative, but these require local or mounted paths rather than HTTP access. There’s no CDN, no sparse protocol, no HTTP-based solution on the horizon.</p> <h2 id=\"go-modules\">Go modules</h2> <p><a href=\"https://engineering.grab.com/go-module-proxy\">Grab’s engineering team</a> went from 18 minutes for <code>go get</code> to 12 seconds after deploying a module proxy. That’s not a typo. Eighteen minutes down to twelve seconds.</p> <p>The problem was that <code>go get</code> needed to fetch each dependency’s source code just to read its go.mod file and resolve transitive dependencies. Cloning entire repositories to get a single file.</p> <p>Go had security concerns too. The original design wanted to remove version control tools entirely because <a href=\"https://arslan.io/2019/08/02/why-you-should-use-a-go-module-proxy/\">“these fragment the ecosystem: packages developed using Bazaar or Fossil, for example, are effectively unavailable to users who cannot or choose not to install these tools.”</a> Beyond fragmentation, the Go team worried about security bugs in version control systems becoming security bugs in <code>go get</code>. You’re not just importing code; you’re importing the attack surface of every VCS tool on the developer’s machine.</p> <p>GOPROXY became the default in Go 1.13. The proxy serves source archives and go.mod files independently over HTTP. Go also introduced a <a href=\"https://nesbitt.io/2025/12/21/federated-package-management.html#gos-experiment-with-dns\">checksum database (sumdb)</a> that records cryptographic hashes of module contents. This protects against force pushes silently changing tagged releases, and ensures modules remain available even if the original repository is deleted.</p> <h2 id=\"beyond-package-managers\">Beyond package managers</h2> <p>The same pattern shows up wherever developers try to use git as a database.</p> <p>Git-based wikis like Gollum (used by GitHub and GitLab) become <a href=\"https://github.com/gollum/gollum/issues/1940\">“somewhat too slow to be usable”</a> at scale. Browsing directory structure takes seconds per click. Loading pages takes longer. <a href=\"https://docs.gitlab.com/ee/development/wikis.html\">GitLab plans to move away from Gollum entirely.</a></p> <p>Git-based CMS platforms like Decap hit GitHub’s API rate limits. A Decap project on GitHub <a href=\"https://decapcms.org/blog/git-based-cms-definition-features-best-practices/\">scales to about 10,000 entries</a> if you have a lot of collection relations. A new user with an empty cache makes a request per entry to populate it, burning through the 5,000 request limit quickly. If your site has lots of content or updates frequently, use a database instead.</p> <p>Even GitOps tools that embrace git as a source of truth have to work around its limitations. ArgoCD’s repo server <a href=\"https://argo-cd.readthedocs.io/en/stable/operator-manual/high_availability/\">can run out of disk space</a> cloning repositories. A single commit invalidates the cache for all applications in that repo. Large monorepos need special scaling considerations.</p> <h2 id=\"the-pattern\">The pattern</h2> <p>The hosting problems are symptoms. The underlying issue is that git inherits filesystem limitations, and filesystems make terrible databases.</p> <p><strong>Directory limits.</strong> Directories with too many files become slow. CocoaPods had <a href=\"https://blog.cocoapods.org/Sharding/\">16,000 pod directories</a> in a single Specs folder, requiring huge tree objects and expensive computation. Their fix was hash-based sharding: split directories by the first few characters of a hashed name, so no single directory has too many entries. Git itself does this internally with its objects folder, splitting into 256 subdirectories. You’re reinventing B-trees, badly.</p> <p><strong>Case sensitivity.</strong> Git is case-sensitive, but macOS and Windows filesystems typically aren’t. <a href=\"https://learn.microsoft.com/en-us/azure/devops/repos/git/os-compatibility\">Check out a repo containing both <code>File.txt</code> and <code>file.txt</code> on Windows</a>, and the second overwrites the first. <a href=\"https://learn.microsoft.com/en-us/azure/devops/repos/git/case-sensitivity\">Azure DevOps</a> had to add server-side enforcement to block pushes with case-conflicting paths.</p> <p><strong>Path length limits.</strong> Windows restricts paths to <a href=\"https://learn.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation\">260 characters</a>, a constraint dating back to DOS. Git supports longer paths, but Git for Windows inherits the OS limitation. This is painful with deeply nested node_modules directories, where <code>git status</code> fails with “Filename too long” errors.</p> <p><strong>Missing database features.</strong> Databases have CHECK constraints and UNIQUE constraints; git has nothing, so every package manager builds its own validation layer. Databases have locking; git doesn’t. Databases have indexes for queries like “all packages depending on X”; with git you either traverse every file or build your own index. Databases have migrations for schema changes; git has “rewrite history and force everyone to re-clone.”</p> <p>The progression is predictable. Start with a flat directory of files. Hit filesystem limits. Implement sharding. Hit cross-platform issues. Build server-side enforcement. Build custom indexes. Eventually give up and use HTTP or an actual database. You’ve built a worse version of what databases already provide, spread across git hooks, CI pipelines, and bespoke tooling.</p> <p>None of this means git is bad. Git excels at what it was designed for: distributed collaboration on source code, with branching, merging, and offline work. The problem is using it for something else entirely. Package registries need fast point queries for metadata. Git gives you a full-document sync protocol when you need a key-value lookup.</p> <p>If you’re building a package manager and git-as-index seems appealing, look at Cargo, Homebrew, CocoaPods, vcpkg, Go. They all had to build workarounds as they grew, causing pain for users and maintainers. The pull request workflow is nice. The version history is nice. You will hit the same walls they did.</p> </div>"},{"id":"https://github.com/readme/guides/publishing-your-work","title":"Publishing your work increases your luck","link":"https://github.com/readme/guides/publishing-your-work","hnCommentsUrl":"https://news.ycombinator.com/item?id=46397991","content":"<a href=\"https://news.ycombinator.com/item?id=46397991\">Comments</a>","date":1766796184000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div data-hpc=\"\"> <p>No matter how hard you work, it still takes a little bit of luck for something to hit. That can be discouraging, since luck feels like a force outside our control. But the good news is that we can increase our chances of encountering good luck. That may sound like magic, but it’s not supernatural. The trick is to increase the number of opportunities we have for good fortune to find us. The simple act of publishing your work is one of the best ways to invite a little more luck into your life.</p> <p>Before we get into the “how,” it’s important to get on the same page about the “what.” What are we talking about when we say “luck?” There are a lot of definitions that could apply, but let’s stick with a simple one: Luck is when something unexpected and good happens to you. Unexpected and good. Who doesn’t want to increase the odds of something unexpected and good?</p> <p>In our world, luck can include:</p> <ul><li><p>Having your OSS library take off</p></li><li><p>Being invited to speak at a conference</p></li><li><p>Landing a new job</p></li><li><p>Getting a new consulting client</p></li><li><p>Being invited onto a podcast</p></li><li><p>Making new friends in your community</p></li></ul> <p>None of these things are totally in your control, which can at times feel frustrating.&nbsp;</p> <p>How can we increase the odds of finding luck? By being a person who works in public. By doing work and being public about it, you build a reputation for yourself. You build a track record. You build a public body of work that speaks on your behalf better than any resume ever could.</p> <p>The goal is not to become famous, the goal is to increase the chances of luck finding us. For me, one of the most helpful ways to think about this has always been the concept of the “Luck Surface Area,” described in an <a href=\"https://www.codusoperandi.com/posts/increasing-your-luck-surface-area\"><u>old post by Jason Roberts</u></a>. He wrote (and note, the emphasis is mine):&nbsp;</p> <p><i>\"The amount of serendipity that will occur in your life, your Luck Surface Area, is directly proportional to the degree to which you </i><i><b>do something</b></i><i> you’re passionate about combined with the total number of people to whom this is </i><i><b>effectively communicated</b></i><i>.\"</i></p> <p>Going further, he codifies it into a formula where:</p> <div tabindex=\"0\"> <pre><span><span>Luck</span> <span>=</span> <span>[</span><span>Doing</span> <span>Things</span><span>]</span> <span>*</span> <span>[</span><span>Telling</span> <span>People</span><span>]</span></span></pre> </div> <p>The more things you do multiplied by the more people you tell, the larger your Luck Surface Area becomes. The larger your Luck Surface Area, the more likely you are to catch luck as it flows by.</p> <picture> <source srcset=\"https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=468&amp;fm=avif 468w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=374&amp;fm=avif 374w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=280&amp;fm=avif 280w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=234&amp;fm=avif 234w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=187&amp;fm=avif 187w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=93&amp;fm=avif 93w\" sizes=\"(max-width: 930px) 90vw, 840px\" type=\"image/avif\"> <source srcset=\"https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=468&amp;fm=webp 468w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=374&amp;fm=webp 374w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=280&amp;fm=webp 280w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=234&amp;fm=webp 234w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=187&amp;fm=webp 187w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=93&amp;fm=webp 93w\" sizes=\"(max-width: 930px) 90vw, 840px\" type=\"image/webp\"> <source srcset=\"https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=468&amp;fm=jpg 468w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=374&amp;fm=jpg 374w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=280&amp;fm=jpg 280w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=234&amp;fm=jpg 234w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=187&amp;fm=jpg 187w,https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=93&amp;fm=jpg 93w\" sizes=\"(max-width: 930px) 90vw, 840px\" type=\"image/jpeg\"> <img width=\"468\" height=\"342\" loading=\"lazy\" decoding=\"async\" alt=\"A graph with &quot;Doing&quot; on the Y axis, and &quot;Telling&quot; on the X axis. The more you do and tell, the better.\" src=\"https://images.ctfassets.net/s5uo95nf6njh/1mf4WuCw33UGsrQTdkErFe/1b5c74f7b54deb664b6bb39aa6303d35/AF_inline.jpg?w=468&amp;fm=jpg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </picture> <h3>Source:<a href=\"https://www.codusoperandi.com/posts/increasing-your-luck-surface-area\"><u> Jason Roberts</u></a></h3> <hr> <h2>Doing the work</h2> <p>Before you can publish your work, you have to actually <i>do</i> the work. The good news for you is that by even reading this Guide on The ReadME Project, you’ve probably already self-selected into a group of people for whom “doing things” comes somewhat naturally. You’re a developer, a designer, a creator, an author, or something else entirely.&nbsp; Whatever moniker you want to give yourself, you’re built to <i>do</i> things, and that’s the important part.&nbsp;</p> <p>If that doesn’t ring true for you, you may fall into one of two groups:</p> <ol><li><p>You actually <i>are</i> doing things, you’ve just trained yourself to think that anything you do isn’t worth sharing.</p></li><li><p>You <i>want</i> to be doing things, but you can’t bring yourself to get started.</p></li></ol> <p>If you’re in the first group, you may need to step back and reframe the work you’re already doing. This is a common blind spot for people who are executing at a high level! They’ve forgotten just how much they know. They think that they’re not doing anything interesting because they assume that everyone knows as much as they do. This effect is only exacerbated when everyone in your immediate vicinity is at a similar—or higher—skill level. As you become more of an expert, your quality bar gets higher and higher and you forget that everything you know is not known by everyone.</p> <p>If you’re in this group I want to give you a challenge: Watch the communities where you hang out and see what people are sharing and what gets noticed. Is it something you could have done? Is it something you’ve <i>already</i> done? At its worst this could lead you in the direction of becoming bitter, critical, and thinking that you’re smarter than everyone. To that I say “resist!” There is no life there. My encouragement to you is to view that as objective evidence that people want to know all of the things that you already know! There is a huge opportunity for you, should you decide to start sharing your work.&nbsp;</p> <p>If you’re in the second group, you just need to start. Start anywhere, start on anything, start something. You’ll never come up with the perfect idea for an OSS library, a business, a podcast, or an article by just thinking about it. Start on something, today. It won’t be the perfect version of the thing you have in your head, but you’ll be in motion. Motion begets motion, progress begets progress. Pick the smallest thing you can do and get started.</p> <p>Doing the work is the most important part. It’s the nucleus around which everything else revolves. What that “work” looks like, though, is entirely up to you! That’s the fun part. It can take any form and be in any domain. Wherever your curiosity or expertise draw you, dive into that.&nbsp;</p> <p>Projects outside of work are a good place to dive into your curiosity.&nbsp;</p> <ul><li><p>If you want to make<a href=\"https://twitter.com/aschmelyun/status/1506960015063625733\"><u> a thermal receipt printer that prints GitHub issues</u></a>, you should.&nbsp;</p></li><li><p>If you want to<a href=\"https://twitter.com/aarondfrancis/status/1333866090573811723\"><u> turn a prefabricated shed into an office</u></a>, go for it.&nbsp;</p></li><li><p>If you want to go all in on an<a href=\"https://twitter.com/steveruizok/status/1419048412431933441\"><u> SVG drawing tool</u></a>, do it.&nbsp;</p></li><li><p>If you want to write tens of thousands of words about <a href=\"https://bam.kalzumeus.com/archive/\"><u>the infrastructure of modern money</u></a>, that’s a newsletter.&nbsp;</p></li></ul> <p>Your curiosity will naturally pull you in certain directions, so don’t be afraid to go super deep into a topic that you’re interested in. When a person is truly interested in the thing they’re writing or talking about, their excitement is contagious. Whatever you’re excited about, be excited about it publicly. Whatever you’re curious about, be curious about it publicly. People will want to follow along and you’ll inspire people along the way.</p> <p>Projects at work can be a good place to dive into your expertise.&nbsp;</p> <p>It's likely you're constantly solving problems and learning interesting things at your job. This is a great opportunity to take what you’re already doing and repurpose it for the benefit of others. You can turn those learnings into blog posts, conference talks, meetups, podcasts, or open source projects.&nbsp;</p> <p>Of course not everything you do at work is shareable. If the specifics aren’t shareable, the concepts, lessons, and takeaways likely are. While you’re working, keep a scratch pad open and jot down any problems you come across, interesting patterns you see, or things you found confusing. Do this for a month and you’ll have more things to share than you know what to do with!</p> <p>You’ve done the work, now it's time to tell people.</p> <h2>Hitting the publish button</h2> <p>This part of the formula can be harder for most of us. Most of us really enjoy the building aspect but start to get a little shy when it comes to telling people about the stuff we’ve built. That could be for any number of reasons: fear, embarrassment, self-preservation, or an aversion to being perceived as hawking your wares.</p> <p>It’s a valuable exercise to investigate whether or not you resonate with any of those reasons. Are you afraid people are going to make fun of what you built? Are you embarrassed that it isn’t up to your own (admittedly high) standards? Are you waiting for some elusive perfect moment? Do you have an aversion to “marketing” and don’t want to become the thing you hate? Whatever it is for you, I encourage you to really dig into it and see if that fear is worth keeping around.</p> <p>Sharing things you’re learning or making is not prideful. People are drawn to other people in motion. People <i>want</i> to follow along, people <i>want</i> to learn things, people <i>want</i> to be a part of your journey. It’s not bragging to say, “I’ve made a thing and I think it’s cool!” Bringing people along is a good thing for everyone. By publishing your work you’re helping people learn. You’re inspiring others to create.</p> <p>You can “publish” anywhere. For me that’s mostly Twitter because that’s where most of my peers hang out. It doesn’t have to be Twitter for you. It could be GitHub, a newsletter, a podcast, forums, your blog, YouTube, or something completely different that’s not even on my radar. Anywhere that’s not your hard drive counts!&nbsp;</p> <p>Publishing is a skill, it’s something you can learn. You’ll need to build your publishing skill just like you built every other skill you have.&nbsp;</p> <p>Don’t be afraid to publish along the way. You don’t have to wait until you’re done to drop a perfect, finished artifact from the sky (in fact, you may use that as an excuse to <i>never</i> publish). People like stories, so use that to your benefit. Share the wins, the losses, and the thought processes. Bring us along! If you haven’t been in the habit of sharing your work, it’s going to feel weird when you start. That’s normal! Keep going, you get used to it.&nbsp;</p> <p>You’ve done the work. You’ve hit the publish button. You’ve done your part!&nbsp;</p> <h2>Capturing the luck</h2> <p>You’ve <i>increased the odds</i> that good, unexpected things will come your way. The exact form is hard to predict, but here are a few potential outcomes:&nbsp;</p> <ul><li><p>People start to know you as the person that talks about X, Y, and Z.&nbsp;</p></li><li><p>You start to get emails from people saying that they read your stuff and liked it.&nbsp;</p></li><li><p>You get a DM about a job you might be interested in.</p></li><li><p>People ask you if you’re taking on new clients.</p></li><li><p>Someone you’ve never met or interacted with will mention you as being an expert in your area.&nbsp;</p></li><li><p>A meetup asks you to come talk about the things you’ve been sharing.</p></li><li><p>You become friends with other people in your industry.</p></li><li><p>Your OSS library starts gaining mindshare.</p></li></ul> <p>This is not a random list of made-up examples, it’s a list of things that have literally happened to me once I got over my fears and started sharing my work. I had been doing the work all along, but was too afraid to publish. Once I overcame that fear, my Luck Surface Area expanded and good, unexpected things started happening.&nbsp;</p> <p>The formula is simple.</p> <p>Do the work. Don’t be afraid to dive deep into your curiosity and your expertise. We need more people that are intensely curious. We need more people with deep expertise.</p> <p>Tell people. Press publish, bring us along, share the journey. Tell us what you’ve learned, what you’ve built, or what you’re excited about.</p> <p>The formula may be simple, but I’ll admit it’s not always easy. It’s scary to put yourself out there. It’s hard to open yourself up to criticism. People online can be mean. But for every snarky comment, there are ten times as many people quietly following along and admiring not only your work, but your bravery to put it out publicly. And at some point, one of those people quietly following along will reach out with a life-changing opportunity and you’ll think, “Wow, that was lucky.”</p> </div></div>"},{"id":"https://nhmu.utah.edu/articles/experts-explore-new-mushroom-which-causes-fairytale-hallucinations","title":"Experts explore new mushroom which causes fairytale-like hallucinations","link":"https://nhmu.utah.edu/articles/experts-explore-new-mushroom-which-causes-fairytale-hallucinations","hnCommentsUrl":"https://news.ycombinator.com/item?id=46393936","content":"<a href=\"https://news.ycombinator.com/item?id=46393936\">Comments</a>","date":1766768873000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://george.mand.is/2025/09/more-dynamic-cronjobs/","title":"More dynamic cronjobs","link":"https://george.mand.is/2025/09/more-dynamic-cronjobs/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46399576","content":"<a href=\"https://news.ycombinator.com/item?id=46399576\">Comments</a>","date":1766815842000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<section><p>I remember learning about cronjobs in the early 2000s. I could tell the computer to go <em>do</em> something, on a recurring basis, forever, even when I wasn't there. They felt like magic!</p><p>We didn't have <a href=\"https://crontab.guru/\">Crontab.guru</a> or AI to ask for figuring out some of the more complex specifications. Just the <a href=\"https://man.openbsd.org/crontab.5\">man pages</a> and good old-fashioned trial and error—mostly error in my case.</p><p>But while you could do fun, complex specifications of recurring intervals, you couldn't quite specify something quite as dynamic as \"run this script every Tuesday at 7am <em>unless it's the last Tuesday</em> of the month...\"</p><p>Or at least, you couldn't strictly through the crontab specification syntax. But I had a recent, mildly embarrassing epiphany that it's not hard at all to add arbitrary checks to your crontab to account for more complex and dynamic scenarios.</p><p>Want to run a script every Tuesday of the month at 7am <em>except</em> for the last Tuesday? That's easy—set up your crontab to run every Tuesday at 7am, but add a little check to make sure the <em>next</em> week is still part of the same month:</p><pre><code>0 7 * * Tue [ \"$(date -v+7d '+%m')\" = \"$(date '+%m')\" ] &amp;&amp; /path/to/your_command </code></pre><p>If it's not part of the same month, that means we're on the <em>last</em> Tuesday for the month and the script won't run.</p><p><strong>Note:</strong> <em>The <code>-v</code> flag is for the macOS/BSD flavors of <code>date</code>. On Linux you'd want to use <code>-d +7 days</code> instead.</em></p><p>This really has nothing to do with cronjobs at all and everything to do with the <a href=\"https://www.unix.com/man_page/posix/1p/test/\">POSIX \"test\" command</a> which is the thing we're using with those square brackets. I'm used to seeing and utilizing them in shell scripts, but for whatever reason I never thought to reach for that tool here in the crontab.</p><p>You could just as easily rewrite it like this, skipping the bracket shorthand, which is probably easier to read:</p><pre><code>0 7 * * Tue test \"$(date -v+7d '+%m')\" = \"$(date '+%m')\" &amp;&amp; /path/to/your_command </code></pre><p>It never crossed my mind until recently to add slightly more complex checks at the crontab level.</p><h3>Other clever cronjob things you can do:</h3><h4>Holiday-only cronjobs</h4><p>Maybe fetch a list of all the US Holidays for a given year and store them in a handy <code>HOLIDAYS.txt</code> file somewhere:</p><pre><code>curl -s https://date.nager.at/api/v3/PublicHolidays/2025/US | jq -r '.[].date' &gt; HOLIDAYS.txt </code></pre><p>Now you can update your cronjob to run every Tuesday at 7am <em>except</em> on Holidays:</p><pre><code>0 7 * * Tue ! grep -qx \"$(date +%F)\" HOLIDAYS.txt &amp;&amp; /path/to/your_command </code></pre><p>Or inversely, maybe run a holiday-only script that checks once a day</p><pre><code>@daily grep -qx \"$(date +%F)\" HOLIDAYS.txt &amp;&amp; /path/to/your_special_holiday_command </code></pre><h4>Only run on sunny days</h4><p>The <a href=\"https://weather.gov/\">National Weather Service</a> makes all kinds of fun data available (if you can find it...). How about a script that runs every hour, but only when the weather is clear?</p><pre><code>@hourly curl -s \"https://api.weather.gov/gridpoints/TOP/32,81/forecast/hourly\" | jq -r '.properties.periods[0].shortForecast' | grep -qi clear &amp;&amp; /path/to/your_command </code></pre><p>Or maybe when the weather is cloudy?</p><pre><code>@hourly curl -s \"https://api.weather.gov/gridpoints/TOP/32,81/forecast/hourly\" | jq -r '.properties.periods[0].shortForecast' | grep -qi cloudy &amp;&amp; /path/to/your_command </code></pre><h4>Only run when there's something newsworthy</h4><p>Or maybe we get in line with every-other-startup I'm aware of and throw AI at the problem, only running our script when the LLM gods have decided there is something newsworthy:</p><pre><code>@hourly curl -s \"https://news.google.com/rss?hl=en-US&amp;gl=US&amp;ceid=US:en\" | llm --system \"Reply strictly 'yes' or 'no'. Does anything in the news today suggest it is a good reason to run a script that I only want to send when the world is on fire and crazy and terrible things are happening?\" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]' | grep -qx yes &amp;&amp; /path/to/oh_no </code></pre>--<p><em>Published on Sunday, September 21st 2025. Read this post as <a href=\"https://george.mand.is/2025/09/more-dynamic-cronjobs.md\" rel=\"alternate\" type=\"text/markdown\">Markdown</a> or <a href=\"https://george.mand.is/2025/09/more-dynamic-cronjobs.txt\" rel=\"alternate\" type=\"text/plain\">plain-text</a>.</em></p><p><em>If you enjoyed reading this consider <a href=\"https://buttondown.com/georgemandis\">signing-up for my newsletter</a>, <a href=\"https://news.ycombinator.com/submitlink?u=https://george.mand.is/2025/09/more-dynamic-cronjobs/&amp;t=More%20dynamic%20cronjobs\">sharing it on Hacker News</a> or <a href=\"https://george.mand.is/hire\">hiring me</a>.</em></p></section>"},{"id":"https://nry.me/posts/2025-10-09/small-web-screenshots/","title":"One million (small web) screenshots","link":"https://nry.me/posts/2025-10-09/small-web-screenshots/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46354492","content":"<a href=\"https://news.ycombinator.com/item?id=46354492\">Comments</a>","date":1766414660000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div><h2 id=\"background\">Background</h2><p>Last month I came across <a href=\"https://onemillionscreenshots.com/\">onemillionscreenshots.com</a> and was pleasantly surprised at how well it worked as a tool for discovery. We all know the adage about judging book covers, but here, …it just kinda works. Skip over the sites with bright flashy colors begging for attention and instead, seek out the negative space in between.</p><p>The one nitpick I have though is in how they sourced the websites. They used the most popular websites from <a href=\"https://en.wikipedia.org/wiki/Common_Crawl\">Common Crawl</a> which is fine, but not really what I’m interested in…</p><p><img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/venn_whole.svg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></p><p>There are of course exceptions, but the relationship between popularity and quality is loose. McDonald’s isn’t popular because it serves the best cheeseburger, it’s popular because it serves a cheeseburger that meets the minimum level of satisfaction for the maximum number of people. It’s a profit maximizing local minima on the cheeseburger landscape.</p><p><img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/venn_close.svg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></p><p>This isn’t limited to just food either, the NYT Best Sellers list, Spotify Top 50, and Amazon review volume are other good examples. For me, what’s “popular” has become a filter for what to avoid. Lucky for us though, there’s a corner of the internet where substance still outweighs click-through rates. A place that’s largely immune to the corrosive influence of monetization. It’s called the small web and it’s a beautiful place.</p><p><img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/popularity.svg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></p><h2 id=\"a-small-web-variant\">A small web variant</h2><p>The timing of this couldn’t have been better. I’m currently working on a couple of tools specifically focused on small web discovery/recommendation and happen to already have most of the data required to pull this off. I just needed to take some screenshots, sooo… you’re welcome <a href=\"https://news.ycombinator.com/item?id=44860696\">armchairhacker</a>!</p><br><center>[full screen version: <a href=\"https://screenshots.nry.me/\">screenshots.nry.me</a>]</center><h2 id=\"technical-details\">Technical details</h2><p>Because I plan on discussing how I gathered the domains in the near future, I’ll skip it for now (it’s pretty interesting). Suffice it to say though, once the domains are available, <a href=\"https://github.com/microsoft/playwright\">capturing the screenshots</a> is trivial. And once those are ready, we have a fairly <a href=\"https://nry.me/posts/2019-03-24/movie-poster-tsne/\">well worn path</a> to follow:</p><ol><li>generate visual embeddings</li><li>dimensionality reduction</li><li>assignment</li></ol><p>I find the last two steps particularly repetitive so I decided to combine them this time via <a href=\"https://en.wikipedia.org/wiki/Self-organizing_map\">self-organizing maps</a> (SOMs). I tried using SOMs a few years ago to help solve a TSP problem (well, <a href=\"https://nry.me/posts/2021-10-09/long-tiny-loop-attempt-2/\">actually the exact opposite…</a>) but ended up going in a different direction. Anyway, despite their trivial implementation they can be extremely useful. A bare bones SOM clocks in at about 10 lines with torch.</p><div><pre tabindex=\"0\"><code data-lang=\"python\"><span><span><span>@torch.no_grad</span>() </span></span><span><span><span>def</span> <span>som_step</span>(alpha, sigma): </span></span><span><span> <span># pick random training sample</span> </span></span><span><span> sample_index <span>=</span> np<span>.</span>random<span>.</span>randint(<span>0</span>, x<span>.</span>shape[<span>0</span>]) </span></span><span><span> D_t <span>=</span> torch<span>.</span>from_numpy(x[sample_index])<span>.</span>to(DEVICE) </span></span><span><span> <span># find the bmu using cosine similarity</span> </span></span><span><span> bmu_flat_idx <span>=</span> torch<span>.</span>argmax(torch<span>.</span>nn<span>.</span>CosineSimilarity(dim<span>=</span><span>2</span>)(D_t, W)<span>.</span>flatten()) </span></span><span><span> <span># convert flat index to 2d coordinates (i, j)</span> </span></span><span><span> u_i <span>=</span> bmu_flat_idx <span>//</span> W<span>.</span>shape[<span>1</span>] </span></span><span><span> u_j <span>=</span> bmu_flat_idx <span>%</span> W<span>.</span>shape[<span>1</span>] </span></span><span><span> <span># compute the l2 distance between the bmu and all other neurons</span> </span></span><span><span> dists_u <span>=</span> torch<span>.</span>sqrt((W_i <span>-</span> u_i)<span>**</span><span>2</span> <span>+</span> (W_j <span>-</span> u_j)<span>**</span><span>2</span>) </span></span><span><span> <span># apply neighborhood smoothing (theta)</span> </span></span><span><span> theta <span>=</span> torch<span>.</span>exp(<span>-</span>(dists_u <span>/</span> sigma)<span>**</span><span>2</span>) </span></span><span><span> <span># update the weights in-place</span> </span></span><span><span> W<span>.</span>add_((theta <span>*</span> alpha)<span>.</span>unsqueeze(<span>2</span>) <span>*</span> (D_t <span>-</span> W)) </span></span></code></pre></div><p>At their core, most SOMs have two elements: a monotonically decreasing learning rate and a neighborhood function with an influence (radius) that is also monotonically decreasing. During training, each step consists of the following:</p><div><ol><li>Randomly select a training sample.</li><li>Compare this training sample against all nodes in the SOM. The node with the smallest (quantization) error becomes the BMU (best matching unit).</li><li>Update the SOM node weights proportional to how far away from the BMU they are. Nodes closer to the BMU become more like the training sample.</li></ol></div><p>There are numerous modifications that can be made, but that’s basically it! If I’ve piqued your interest, I highly recommend the book <i><a href=\"https://www.goodreads.com/book/show/838949.Self_Organizing_Maps\">Self-Organizing Maps</a></i> by Teuvo Kohonen, it’s a fairly quick read and covers the core aspects of SOMs.</p><p>With dimensionality reduction and assignment resolved, we just need the visual embeddings now. I started with the brand new <a href=\"https://arxiv.org/abs/2508.10104\">DinoV3</a> model, but was left rather disappointed. The progression of Meta’s self-supervised vision transformers has been truly incredible, but the latent space captures waaay more information than what I actually need. I just want to encode the high level aesthetic details of webpage screenshots. Because of this, I fell back on an old friend: the <a href=\"https://en.wikipedia.org/wiki/Triplet_loss\">triplet loss</a> on top of a small encoder. The resulting output dimension of 64 afforded ample room for describing the visual range while maintaining a considerably smaller footprint.</p><p>This got me 90% of the way there, but it was still lacking the visual layout I had envisioned. I wanted a stronger correlation with color at the expense of visual similarity. To achieve this, I had to manually enforce this bias by training two SOMs in parallel. One SOM operated on the encoder output (visual), the second SOM on the color distribution and were linked using the following:</p><p><img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/mapping.svg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></p><p>When the quantization error is low, the BMU pulling force is dominated by the visual similarity. As quantization error increases, the pulling force due to visual similarity wanes and is slowly overpowered by the pulling force from the color distribution. In essence, the color distribution controls the macro placement while the visual similarity controls the micro placement. The only controllable hyperparameter with this approach is selecting a threshold for where the crossover point occurs.</p><p>I didn’t spend much time trying to find the optimal point, it’s currently peak fall and well, I’d much rather be outside. A quick look at the overall quantization error (below left) and the <a href=\"https://en.wikipedia.org/wiki/U-matrix\">U-matrix</a> (below right) was sufficient.</p><p><img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/qe_error.png\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> <img src=\"https://nry.me/posts/2025-10-09/small-web-screenshots/imgs/u_matrix.png\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></p><p>There’s still a lot of cruft that slipped in (substack, medium.com, linkedin, etc…) but overall, I’d say it’s not too bad for a first pass. In the time since generating this initial map I’ve already crawled an additional ~250k new domains so I suppose this means I’ll be doing an update. What I do know for certain though is that self-organizing maps have earned a coveted spot in my heart for things that are simple to the point of being elegant and yet, deceptively powerful (the others of course being <a href=\"https://en.wikipedia.org/wiki/Aerodynamic_potential-flow_code\">panel methods</a>, <a href=\"https://nry.me/posts/2024-12-19/ptpx-2024/\">LBM</a>, <a href=\"https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\">Metropolis-Hastings</a>, and the bicycle).</p></div></div>"}]}