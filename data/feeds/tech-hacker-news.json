{"title":"Hacker News","items":[{"id":"https://github.com/apple/ml-sharp","title":"Apple releases open-source model that instantly turns 2D photos into 3D views","link":"https://github.com/apple/ml-sharp","hnCommentsUrl":"https://news.ycombinator.com/item?id=46401539","content":"<a href=\"https://news.ycombinator.com/item?id=46401539\">Comments</a>","date":1766840292000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<h2 tabindex=\"-1\" dir=\"auto\">Sharp Monocular View Synthesis in Less Than a Second</h2> <p dir=\"auto\"><a href=\"https://apple.github.io/ml-sharp/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/cafdcb5612b1ab28528d47af9245604f8f7b0792562c7c5151fff90340a3d6cc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50726f6a6563742d506167652d677265656e\" alt=\"Project Page\" data-canonical-src=\"https://img.shields.io/badge/Project-Page-green\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> <a href=\"https://arxiv.org/abs/2512.10685\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/dba21084a03f7471ad5ab1cbe4b2eeb9c6c4333dde6dae06cd437bc9b9163cf7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323531322e31303638352d6233316231622e737667\" alt=\"arXiv\" data-canonical-src=\"https://img.shields.io/badge/arXiv-2512.10685-b31b1b.svg\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p> <p dir=\"auto\">This software project accompanies the research paper: <em>Sharp Monocular View Synthesis in Less Than a Second</em> by <em>Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen, Amaël Delaunoy, Tian Fang, Yanghai Tsin, Stephan Richter and Vladlen Koltun</em>.</p> <p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/apple/ml-sharp/blob/main/data/teaser.jpg\"><img src=\"https://github.com/apple/ml-sharp/raw/main/data/teaser.jpg\" alt=\"\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p> <p dir=\"auto\">We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25–34% and DISTS by 21–43% versus the best prior model, while lowering the synthesis time by three orders of magnitude.</p> <h2 tabindex=\"-1\" dir=\"auto\">Getting started</h2> <p dir=\"auto\">We recommend to first create a python environment:</p> <div data-snippet-clipboard-copy-content=\"conda create -n sharp python=3.13\"><pre><code>conda create -n sharp python=3.13 </code></pre></div> <p dir=\"auto\">Afterwards, you can install the project using</p> <div data-snippet-clipboard-copy-content=\"pip install -r requirements.txt\"><pre><code>pip install -r requirements.txt </code></pre></div> <p dir=\"auto\">To test the installation, run</p> <h2 tabindex=\"-1\" dir=\"auto\">Using the CLI</h2> <p dir=\"auto\">To run prediction:</p> <div data-snippet-clipboard-copy-content=\"sharp predict -i /path/to/input/images -o /path/to/output/gaussians\"><pre><code>sharp predict -i /path/to/input/images -o /path/to/output/gaussians </code></pre></div> <p dir=\"auto\">The model checkpoint will be downloaded automatically on first run and cached locally at <code>~/.cache/torch/hub/checkpoints/</code>.</p> <p dir=\"auto\">Alternatively, you can download the model directly:</p> <div data-snippet-clipboard-copy-content=\"wget https://ml-site.cdn-apple.com/models/sharp/sharp_2572gikvuh.pt\"><pre><code>wget https://ml-site.cdn-apple.com/models/sharp/sharp_2572gikvuh.pt </code></pre></div> <p dir=\"auto\">To use a manually downloaded checkpoint, specify it with the <code>-c</code> flag:</p> <div data-snippet-clipboard-copy-content=\"sharp predict -i /path/to/input/images -o /path/to/output/gaussians -c sharp_2572gikvuh.pt\"><pre><code>sharp predict -i /path/to/input/images -o /path/to/output/gaussians -c sharp_2572gikvuh.pt </code></pre></div> <p dir=\"auto\">The results will be 3D gaussian splats (3DGS) in the output folder. The 3DGS <code>.ply</code> files are compatible to various public 3DGS renderers. We follow the OpenCV coordinate convention (x right, y down, z forward). The 3DGS scene center is roughly at (0, 0, +z). When dealing with 3rdparty renderers, please scale and rotate to re-center the scene accordingly.</p> <h3 tabindex=\"-1\" dir=\"auto\">Rendering trajectories (CUDA GPU only)</h3> <p dir=\"auto\">Additionally you can render videos with a camera trajectory. While the gaussians prediction works for all CPU, CUDA, and MPS, rendering videos via the <code>--render</code> option currently requires a CUDA GPU. The gsplat renderer takes a while to initialize at the first launch.</p> <div data-snippet-clipboard-copy-content=\"sharp predict -i /path/to/input/images -o /path/to/output/gaussians --render # Or from the intermediate gaussians: sharp render -i /path/to/output/gaussians -o /path/to/output/renderings\"><pre><code>sharp predict -i /path/to/input/images -o /path/to/output/gaussians --render # Or from the intermediate gaussians: sharp render -i /path/to/output/gaussians -o /path/to/output/renderings </code></pre></div> <h2 tabindex=\"-1\" dir=\"auto\">Evaluation</h2> <p dir=\"auto\">Please refer to the paper for both quantitative and qualitative evaluations. Additionally, please check out this <a href=\"https://apple.github.io/ml-sharp/\" rel=\"nofollow\">qualitative examples page</a> containing several video comparisons against related work.</p> <h2 tabindex=\"-1\" dir=\"auto\">Citation</h2> <p dir=\"auto\">If you find our work useful, please cite the following paper:</p> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"@inproceedings{Sharp2025:arxiv, title = {Sharp Monocular View Synthesis in Less Than a Second}, author = {Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\\&quot;{e}l Delaunoy and Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun}, journal = {arXiv preprint arXiv:2512.10685}, year = {2025}, url = {https://arxiv.org/abs/2512.10685}, }\"><pre><span>@inproceedings</span>{<span>Sharp2025:arxiv</span>, <span>title</span> = <span><span>{</span>Sharp Monocular View Synthesis in Less Than a Second<span>}</span></span>, <span>author</span> = <span><span>{</span>Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\\\"{e}l Delaunoy and Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun<span>}</span></span>, <span>journal</span> = <span><span>{</span>arXiv preprint arXiv:2512.10685<span>}</span></span>, <span>year</span> = <span><span>{</span>2025<span>}</span></span>, <span>url</span> = <span><span>{</span>https://arxiv.org/abs/2512.10685<span>}</span></span>, }</pre></div> <h2 tabindex=\"-1\" dir=\"auto\">Acknowledgements</h2> <p dir=\"auto\">Our codebase is built using multiple opensource contributions, please see <a href=\"https://github.com/apple/ml-sharp/blob/main/ACKNOWLEDGEMENTS\">ACKNOWLEDGEMENTS</a> for more details.</p> <h2 tabindex=\"-1\" dir=\"auto\">License</h2> <p dir=\"auto\">Please check out the repository <a href=\"https://github.com/apple/ml-sharp/blob/main/LICENSE\">LICENSE</a> before using the provided code and <a href=\"https://github.com/apple/ml-sharp/blob/main/LICENSE_MODEL\">LICENSE_MODEL</a> for the released models.</p>"},{"id":"http://npmjs.com/package/ezff","title":"Show HN: Ez FFmpeg – Video editing in plain English","link":"http://npmjs.com/package/ezff","hnCommentsUrl":"https://news.ycombinator.com/item?id=46400251","content":"<a href=\"https://news.ycombinator.com/item?id=46400251\">Comments</a>","date":1766825146000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://floor796.com/","title":"Floor796","link":"https://floor796.com/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46401612","content":"<a href=\"https://news.ycombinator.com/item?id=46401612\">Comments</a>","date":1766841180000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://react-networks-lib.rackout.net/fibre","title":"Splice a Fibre","link":"https://react-networks-lib.rackout.net/fibre","hnCommentsUrl":"https://news.ycombinator.com/item?id=46401190","content":"<a href=\"https://news.ycombinator.com/item?id=46401190\">Comments</a>","date":1766836637000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html","title":"How uv got so fast","link":"https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46393992","content":"<a href=\"https://news.ycombinator.com/item?id=46393992\">Comments</a>","date":1766769187000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div itemprop=\"articleBody\"> <p>uv installs packages faster than pip by an order of magnitude. The usual explanation is “it’s written in Rust.” That’s true, but it doesn’t explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.</p> <p>Charlie Marsh’s <a href=\"https://www.janestreet.com/tech-talks/uv-an-extremely-fast-python-package-manager/\">Jane Street talk</a> and a <a href=\"https://xebia.com/blog/uv-the-engineering-secrets-behind-pythons-speed-king/\">Xebia engineering deep-dive</a> cover the technical details well. The interesting parts are the design decisions: standards that enable fast paths, things uv drops that pip supports, and optimizations that don’t require Rust at all.</p> <h2 id=\"the-standards-that-made-uv-possible\">The standards that made uv possible</h2> <p>pip’s slowness isn’t a failure of implementation. For years, Python packaging required executing code to find out what a package needed.</p> <p>The problem was <a href=\"https://setuptools.pypa.io/\">setup.py</a>. You couldn’t know a package’s dependencies without running its setup script. But you couldn’t run its setup script without installing its build dependencies. <a href=\"https://peps.python.org/pep-0518/\">PEP 518</a> in 2016 called this out explicitly: “You can’t execute a setup.py file without knowing its dependencies, but currently there is no standard way to know what those dependencies are in an automated fashion without executing the setup.py file.”</p> <p>This chicken-and-egg problem forced pip to download packages, execute untrusted code, fail, install missing build tools, and try again. Every install was potentially a cascade of subprocess spawns and arbitrary code execution. Installing a source distribution was essentially <code>curl | bash</code> with extra steps.</p> <p>The fix came in stages:</p> <ul> <li><a href=\"https://peps.python.org/pep-0518/\">PEP 518</a> (2016) created pyproject.toml, giving packages a place to declare build dependencies without code execution. The TOML format was borrowed from Rust’s Cargo, which makes a Rust tool returning to fix Python packaging feel less like coincidence.</li> <li><a href=\"https://peps.python.org/pep-0517/\">PEP 517</a> (2017) separated build frontends from backends, so pip didn’t need to understand setuptools internals.</li> <li><a href=\"https://peps.python.org/pep-0621/\">PEP 621</a> (2020) standardized the <code>[project]</code> table, so dependencies could be read by parsing TOML rather than running Python.</li> <li><a href=\"https://peps.python.org/pep-0658/\">PEP 658</a> (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.</li> </ul> <p>PEP 658 went live on PyPI in May 2023. uv launched in February 2024. uv could be fast because the ecosystem finally had the infrastructure to support it. A tool like uv couldn’t have shipped in 2020. The standards weren’t there yet.</p> <p>Other ecosystems figured this out earlier. Cargo has had static metadata from the start. npm’s package.json is declarative. Python’s packaging standards finally bring it to parity.</p> <h2 id=\"what-uv-drops\">What uv drops</h2> <p>Speed comes from elimination. Every code path you don’t have is a code path you don’t wait for.</p> <p>uv’s <a href=\"https://docs.astral.sh/uv/pip/compatibility/\">compatibility documentation</a> is a list of things it doesn’t do:</p> <p><strong>No .egg support.</strong> Eggs were the pre-wheel binary format. pip still handles them; uv doesn’t even try. The format has been obsolete for over a decade.</p> <p><strong>No pip.conf.</strong> uv ignores pip’s configuration files entirely. No parsing, no environment variable lookups, no inheritance from system-wide and per-user locations.</p> <p><strong>No bytecode compilation by default.</strong> pip compiles .py files to .pyc during installation. uv skips this step, shaving time off every install. You can opt in if you want it.</p> <p><strong>Virtual environments required.</strong> pip lets you install into system Python by default. uv inverts this, refusing to touch system Python without explicit flags. This removes a whole category of permission checks and safety code.</p> <p><strong>Stricter spec enforcement.</strong> pip accepts malformed packages that technically violate packaging specs. uv rejects them. Less tolerance means less fallback logic.</p> <p><strong>Ignoring requires-python upper bounds.</strong> When a package says it requires <code>python&lt;4.0</code>, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare <code>python&lt;4.0</code> because they haven’t tested on Python 4, not because they’ll actually break. The constraint is defensive, not predictive.</p> <p><strong>First-index wins by default.</strong> When multiple package indexes are configured, pip checks all of them. uv picks from the first index that has the package, stopping there. This prevents dependency confusion attacks and avoids extra network requests.</p> <p>Each of these is a code path pip has to execute and uv doesn’t.</p> <h2 id=\"optimizations-that-dont-need-rust\">Optimizations that don’t need Rust</h2> <p>Some of uv’s speed comes from Rust. But not as much as you’d think. Several key optimizations could be implemented in pip today:</p> <p><strong>HTTP range requests for metadata.</strong> <a href=\"https://packaging.python.org/en/latest/specifications/binary-distribution-format/\">Wheel files</a> are zip archives, and zip archives put their file listing at the end. uv tries PEP 658 metadata first, falls back to HTTP range requests for the zip central directory, then full wheel download, then building from source. Each step is slower and riskier. The design makes the fast path cover 99% of cases. None of this requires Rust.</p> <p><strong>Parallel downloads.</strong> pip downloads packages one at a time. uv downloads many at once. Any language can do this.</p> <p><strong>Global cache with hardlinks.</strong> pip copies packages into each virtual environment. uv keeps one copy globally and uses <a href=\"https://en.wikipedia.org/wiki/Hard_link\">hardlinks</a> (or copy-on-write on filesystems that support it). Installing the same package into ten venvs takes the same disk space as one. Any language with filesystem access can do this.</p> <p><strong>Python-free resolution.</strong> pip needs Python running to do anything, and invokes build backends as subprocesses to get metadata from legacy packages. uv parses TOML and wheel metadata natively, only spawning Python when it hits a setup.py-only package that has no other option.</p> <p><strong>PubGrub resolver.</strong> uv uses the <a href=\"https://github.com/dart-lang/pub/blob/master/doc/solver.md\">PubGrub algorithm</a>, originally from Dart’s pub package manager. Both pip and PubGrub use backtracking, but PubGrub applies conflict-driven clause learning from SAT solvers: when it hits a dead end, it analyzes why and skips similar dead ends later. This makes it faster on complex dependency graphs and better at explaining failures. pip could adopt PubGrub without rewriting in Rust.</p> <h2 id=\"where-rust-actually-matters\">Where Rust actually matters</h2> <p>Some optimizations do require Rust:</p> <p><strong>Zero-copy deserialization.</strong> uv uses <a href=\"https://rkyv.org/\">rkyv</a> to deserialize cached data without copying it. The data format is the in-memory format. Libraries like FlatBuffers achieve this in other languages, but rkyv integrates tightly with Rust’s type system.<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\" role=\"doc-noteref\">1</a></sup></p> <p><strong>Thread-level parallelism.</strong> Python’s GIL forces parallel work into separate processes, with IPC overhead and data copying. Rust can parallelize across threads natively, sharing memory without serialization boundaries. This matters most for resolution, where the solver explores many version combinations.<sup id=\"fnref:1:1\"><a href=\"#fn:1\" rel=\"footnote\" role=\"doc-noteref\">1</a></sup></p> <p><strong>No interpreter startup.</strong> Every time pip spawns a subprocess, it pays Python’s startup cost. uv is a single static binary with no runtime to initialize.</p> <p><strong>Compact version representation.</strong> uv packs versions into u64 integers where possible, making comparison and hashing fast. Over 90% of versions fit in one u64. This is micro-optimization that compounds across millions of comparisons.</p> <p>These are real advantages. But they’re smaller than the architectural wins from dropping legacy support and exploiting modern standards.</p> <h2 id=\"design-over-language\">Design over language</h2> <p>uv is fast because of what it doesn’t do, not because of what language it’s written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.</p> <p>pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesn’t, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.</p> <p>Other package managers could learn from this: static metadata, no code execution to discover dependencies, and the ability to resolve everything upfront before downloading. Cargo and npm have operated this way for years. If your ecosystem requires running arbitrary code to find out what a package needs, you’ve already lost.</p> </div>"},{"id":"https://github.com/DeepMyst/Mysti","title":"Show HN: Mysti – Claude, Codex, and Gemini debate your code, then synthesize","link":"https://github.com/DeepMyst/Mysti","hnCommentsUrl":"https://news.ycombinator.com/item?id=46365105","content":"<a href=\"https://news.ycombinator.com/item?id=46365105\">Comments</a>","date":1766495912000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<h2 tabindex=\"-1\" dir=\"auto\">Mysti - Your AI Coding Team (Claude, Codex and Gemini) working together</h2> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/resources/Mysti-Logo.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/resources/Mysti-Logo.png\" alt=\"Mysti Logo\" width=\"128\" height=\"128\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/51bc9a555d405735fa23d3bcbb85ecb254ef5bfef034dbd2b04e3bff37eee06b/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f762f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d56657273696f6e\" alt=\"Version\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/v/DeepMyst.mysti?style=flat-square&amp;label=Version\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/4515efb079c925d6b40a39d33f18bb9bc85d32af3c3ec44f1d62e3137a706c23/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f692f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d496e7374616c6c73\" alt=\"Installs\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/i/DeepMyst.mysti?style=flat-square&amp;label=Installs\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/47b6437fc7cbe6138ae63013cc55fbc861b4889d6e27fd512148bb9097552155/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f722f446565704d7973742e6d797374693f7374796c653d666c61742d737175617265266c6162656c3d526174696e67\" alt=\"Rating\" data-canonical-src=\"https://img.shields.io/visual-studio-marketplace/r/DeepMyst.mysti?style=flat-square&amp;label=Rating\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <a href=\"https://github.com/DeepMyst/Mysti/blob/main/LICENSE\"> <img src=\"https://camo.githubusercontent.com/cf54cf4f65e7cfd6fa294ec2149b4f9d78b2c38278169ab91fc7d05cdd986e45/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d42534c253230312e312d626c75653f7374796c653d666c61742d737175617265\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-BSL%201.1-blue?style=flat-square\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> <p dir=\"auto\"> <strong>Your AI Coding team for VSCode</strong><br> <em>Use Claude Code, Codex, or Gemini — or combine any two in Brainstorm Mode and never hit bottlenecks</em><br> <em>Wisdom of the crowd where the collective intelligence of several agents outperforms a single one.</em> </p> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\"> <img src=\"https://camo.githubusercontent.com/01fcc3f81de9302c4ac756a5e9210a53c956690903b11138d1a8a1fb1b8b5009/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f496e7374616c6c25323066726f6d2d5653253230436f64652532304d61726b6574706c6163652d3030374143433f7374796c653d666f722d7468652d6261646765266c6f676f3d76697375616c2d73747564696f2d636f6465\" alt=\"Install from VS Code Marketplace\" data-canonical-src=\"https://img.shields.io/badge/Install%20from-VS%20Code%20Marketplace-007ACC?style=for-the-badge&amp;logo=visual-studio-code\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> <p dir=\"auto\"> <a href=\"#choose-your-ai\">Providers</a> • <a href=\"#brainstorm-mode\">Brainstorm</a> • <a href=\"#key-features\">Features</a> • <a href=\"#quick-start\">Quick Start</a> • <a href=\"#configuration\">Config</a> </p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Install in Seconds</h2> <p dir=\"auto\"><strong>From VS Code:</strong> Press <code>Ctrl+P</code> (<code>Cmd+P</code> on Mac), then paste:</p> <div data-snippet-clipboard-copy-content=\"ext install DeepMyst.mysti\"><pre><code>ext install DeepMyst.mysti </code></pre></div> <p dir=\"auto\"><strong>Or</strong> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">install from the VS Code Marketplace</a></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Choose Your AI</h2> <p dir=\"auto\">Mysti works with the AI coding tools you already have. <strong>No extra subscriptions needed.</strong></p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/agent-selection.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/agent-selection.png\" alt=\"Agent Selection\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <markdown-accessiblity-table><table> <thead> <tr> <th>Provider</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>Claude Code</strong></td> <td>Deep reasoning, complex refactoring, thorough analysis</td> </tr> <tr> <td><strong>Codex</strong></td> <td>Quick iterations, familiar OpenAI style</td> </tr> <tr> <td><strong>Gemini</strong></td> <td>Fast responses, Google ecosystem integration</td> </tr> <tr> <td><strong>Brainstorm Mode</strong></td> <td>Any two AIs collaborate and debate solutions</td> </tr> </tbody> </table></markdown-accessiblity-table> <p dir=\"auto\"><strong>Switch providers with one click. No lock-in.</strong></p> <h3 tabindex=\"-1\" dir=\"auto\">Why Mysti?</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>vs Copilot/Cursor</th> <th>Mysti Advantage</th> </tr> </thead> <tbody> <tr> <td>Single AI</td> <td><strong>Multi-agent brainstorming</strong> — two AIs collaborate</td> </tr> <tr> <td>Locked to one provider</td> <td><strong>Use any CLI</strong> — Claude, Codex, or Gemini</td> </tr> <tr> <td>Black box</td> <td><strong>Full permission control</strong> — read-only to full-access</td> </tr> <tr> <td>Generic responses</td> <td><strong>16 personas</strong> — architect, debugger, security expert...</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">See It In Action</h2> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/user-experience.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/user-experience.png\" alt=\"Mysti Chat Interface\" width=\"700\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"><em>Beautiful, modern chat interface with syntax highlighting, markdown support, and mermaid diagrams</em></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Brainstorm Mode</h2> <p dir=\"auto\"><strong>Want a second opinion?</strong> Enable Brainstorm Mode and let two AI agents tackle your problem together. <strong>Choose any 2 of 3 agents</strong> (Claude, Codex, or Gemini) from the settings panel.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/brainstorm-mode.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/brainstorm-mode.png\" alt=\"Brainstorm Mode\" width=\"700\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <h3 tabindex=\"-1\" dir=\"auto\">Why Two AIs Beat One</h3> <p dir=\"auto\"><strong>Claude Code</strong> (Anthropic), <strong>Codex</strong> (OpenAI), and <strong>Gemini</strong> (Google) have different training, different strengths, and different blind spots. When any two work together:</p> <ul dir=\"auto\"> <li>Each AI catches edge cases the other might miss</li> <li>Different perspectives lead to more robust solutions</li> <li><strong>Together</strong> they debate, challenge each other, and synthesize the best solution</li> </ul> <p dir=\"auto\">It's like having a senior dev and a tech lead review your code—except they actually discuss it first.</p> <h3 tabindex=\"-1\" dir=\"auto\">Choose Your Team</h3> <p dir=\"auto\">Configure which two agents collaborate in the <strong>Settings Panel</strong>:</p> <markdown-accessiblity-table><table> <thead> <tr> <th>Combination</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td>Claude + Codex</td> <td>Deep analysis meets rapid iteration</td> </tr> <tr> <td>Claude + Gemini</td> <td>Thorough reasoning with fast validation</td> </tr> <tr> <td>Codex + Gemini</td> <td>Quick iterations with Google ecosystem knowledge</td> </tr> </tbody> </table></markdown-accessiblity-table> <h3 tabindex=\"-1\" dir=\"auto\">How It Works</h3> <div data-snippet-clipboard-copy-content=\"Your Request | v +-----------+-----------+ | Agent 1 | Agent 2 | | analyzes | analyzes | +-----+-----+-----+-----+ | | v v +---------------------------+ | Discussion (Full Mode) | | Agents review each other's| | solutions and debate | +-----------+---------------+ | v +---------------------------+ | Synthesis | | Best ideas combined into | | one refined solution | +---------------------------+\"><pre><code>Your Request | v +-----------+-----------+ | Agent 1 | Agent 2 | | analyzes | analyzes | +-----+-----+-----+-----+ | | v v +---------------------------+ | Discussion (Full Mode) | | Agents review each other's| | solutions and debate | +-----------+---------------+ | v +---------------------------+ | Synthesis | | Best ideas combined into | | one refined solution | +---------------------------+ </code></pre></div> <h3 tabindex=\"-1\" dir=\"auto\">Two Collaboration Modes</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>Quick Mode</th> <th>Full Mode</th> </tr> </thead> <tbody> <tr> <td>Direct synthesis</td> <td>Agents discuss first</td> </tr> <tr> <td>Both agents respond, then merge</td> <td>Each AI critiques the other's solution</td> </tr> <tr> <td>Faster results</td> <td>More thorough analysis</td> </tr> <tr> <td>Good for simple tasks</td> <td>Best for complex architecture decisions</td> </tr> </tbody> </table></markdown-accessiblity-table> <h3 tabindex=\"-1\" dir=\"auto\">Intelligent Plan Detection</h3> <p dir=\"auto\">When the AI presents multiple implementation approaches, Mysti automatically detects them and lets you choose your preferred path.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/plan-suggestions.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/plan-suggestions.png\" alt=\"Plan Suggestions\" width=\"600\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <p dir=\"auto\"><em>Requires at least 2 CLI tools installed. See <a href=\"#requirements\">Requirements</a>.</em></p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Key Features</h2> <h3 tabindex=\"-1\" dir=\"auto\">16 Developer Personas</h3> <p dir=\"auto\">Shape how your AI thinks. Select from specialized personas that change the AI's approach to your problems.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/persona-skills-panel.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/persona-skills-panel.png\" alt=\"Personas and Skills Panel\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <markdown-accessiblity-table><table> <thead> <tr> <th>Persona</th> <th>Focus</th> </tr> </thead> <tbody> <tr> <td><strong>Architect</strong></td> <td>System design, scalability, clean structure</td> </tr> <tr> <td><strong>Debugger</strong></td> <td>Root cause analysis, bug fixing</td> </tr> <tr> <td><strong>Security-Minded</strong></td> <td>Vulnerabilities, threat modeling</td> </tr> <tr> <td><strong>Performance Tuner</strong></td> <td>Optimization, profiling, latency</td> </tr> <tr> <td><strong>Prototyper</strong></td> <td>Quick iteration, PoCs</td> </tr> <tr> <td><strong>Refactorer</strong></td> <td>Code quality, maintainability</td> </tr> <tr> <td>+ 10 more...</td> <td>Full-Stack, DevOps, Mentor, Designer...</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Quick Persona Selection</h3> <p dir=\"auto\">Select personas directly from the toolbar without opening panels.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/persona-toolbar.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/persona-toolbar.png\" alt=\"Toolbar Persona Selection\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Smart Auto-Suggestions</h3> <p dir=\"auto\">Mysti automatically suggests relevant personas and actions based on your message.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/auto-suggestions.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/auto-suggestions.png\" alt=\"Auto Suggestions\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Conversation History</h3> <p dir=\"auto\">Never lose your work. All conversations are saved and easily accessible.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/conversation-history.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/conversation-history.png\" alt=\"Conversation History\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Quick Actions on Welcome</h3> <p dir=\"auto\">Get started fast with one-click actions for common tasks.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/quick-actions-welcome.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/quick-actions-welcome.png\" alt=\"Quick Actions\" width=\"550\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h3 tabindex=\"-1\" dir=\"auto\">Extensive Settings</h3> <p dir=\"auto\">Fine-tune every aspect of Mysti including token budgets, access levels, and brainstorm mode.</p> <p dir=\"auto\"> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/DeepMyst/Mysti/blob/main/docs/screenshots/settings-panel.png\"><img src=\"https://github.com/DeepMyst/Mysti/raw/main/docs/screenshots/settings-panel.png\" alt=\"Settings Panel\" width=\"450\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a> </p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Requirements</h2> <p dir=\"auto\"><strong>Already paying for Claude, ChatGPT, or Gemini? You're ready to go.</strong></p> <p dir=\"auto\">Mysti works with your existing subscriptions—no additional costs!</p> <markdown-accessiblity-table><table> <thead> <tr> <th>CLI Tool</th> <th>Subscription</th> <th>Install</th> </tr> </thead> <tbody> <tr> <td><strong>Claude Code</strong> (recommended)</td> <td>Anthropic API or Claude Pro/Max</td> <td><code>npm install -g @anthropic-ai/claude-code</code></td> </tr> <tr> <td><strong>Codex CLI</strong></td> <td>OpenAI API</td> <td>Follow OpenAI's installation guide</td> </tr> <tr> <td><strong>Gemini CLI</strong></td> <td>Google AI API or Gemini Advanced</td> <td><code>npm install -g @google/gemini-cli</code></td> </tr> </tbody> </table></markdown-accessiblity-table> <p dir=\"auto\">You only need <strong>one</strong> CLI to get started. Install <strong>any two</strong> to unlock Brainstorm Mode.</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Quick Start</h2> <h3 tabindex=\"-1\" dir=\"auto\">1. Install Mysti</h3> <p dir=\"auto\"><strong>Option A:</strong> Press <code>Ctrl+P</code> (<code>Cmd+P</code> on Mac), paste and run:</p> <div data-snippet-clipboard-copy-content=\"ext install DeepMyst.mysti\"><pre><code>ext install DeepMyst.mysti </code></pre></div> <p dir=\"auto\"><strong>Option B:</strong> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">Install from VS Code Marketplace</a></p> <h3 tabindex=\"-1\" dir=\"auto\">2. Install a CLI Tool</h3> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"# Claude Code (recommended) npm install -g @anthropic-ai/claude-code claude auth login # Or Gemini CLI npm install -g @google/gemini-cli gemini auth login\"><pre><span><span>#</span> Claude Code (recommended)</span> npm install -g @anthropic-ai/claude-code claude auth login <span><span>#</span> Or Gemini CLI</span> npm install -g @google/gemini-cli gemini auth login</pre></div> <p dir=\"auto\">For Brainstorm Mode, install any two CLI tools.</p> <h3 tabindex=\"-1\" dir=\"auto\">3. Open Mysti</h3> <ul dir=\"auto\"> <li>Click the <strong>Mysti icon</strong> in the Activity Bar, or</li> <li>Press <code>Ctrl+Shift+M</code> (<code>Cmd+Shift+M</code> on Mac)</li> </ul> <h3 tabindex=\"-1\" dir=\"auto\">4. Start Coding</h3> <p dir=\"auto\">Type your request and let the AI assist you!</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">12 Toggleable Skills</h2> <p dir=\"auto\">Mix and match behavioral modifiers:</p> <ul dir=\"auto\"> <li><strong>Concise</strong> - Clear, brief communication</li> <li><strong>Test-Driven</strong> - Tests alongside code</li> <li><strong>Auto-Commit</strong> - Incremental commits</li> <li><strong>First Principles</strong> - Fundamental reasoning</li> <li><strong>Scope Discipline</strong> - Stay focused on the task</li> <li>And 7 more...</li> </ul> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Permission Controls</h2> <p dir=\"auto\">Stay in control of what the AI can do:</p> <ul dir=\"auto\"> <li><strong>Read-only</strong> - AI can only read, never modify</li> <li><strong>Ask-permission</strong> - Approve each file change</li> <li><strong>Full-access</strong> - Let the AI work autonomously</li> </ul> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Configuration</h2> <h3 tabindex=\"-1\" dir=\"auto\">Essential Settings</h3> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"{ &quot;mysti.defaultProvider&quot;: &quot;claude-code&quot;, &quot;mysti.brainstorm.agents&quot;: [&quot;claude-code&quot;, &quot;google-gemini&quot;], &quot;mysti.brainstorm.discussionMode&quot;: &quot;full&quot;, &quot;mysti.accessLevel&quot;: &quot;ask-permission&quot; }\"><pre>{ <span>\"mysti.defaultProvider\"</span>: <span><span>\"</span>claude-code<span>\"</span></span>, <span>\"mysti.brainstorm.agents\"</span>: [<span><span>\"</span>claude-code<span>\"</span></span>, <span><span>\"</span>google-gemini<span>\"</span></span>], <span>\"mysti.brainstorm.discussionMode\"</span>: <span><span>\"</span>full<span>\"</span></span>, <span>\"mysti.accessLevel\"</span>: <span><span>\"</span>ask-permission<span>\"</span></span> }</pre></div> <h3 tabindex=\"-1\" dir=\"auto\">All Settings</h3> <markdown-accessiblity-table><table> <thead> <tr> <th>Setting</th> <th>Default</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>mysti.defaultProvider</code></td> <td><code>claude-code</code></td> <td>Primary AI provider (<code>claude-code</code>, <code>openai-codex</code>, <code>google-gemini</code>)</td> </tr> <tr> <td><code>mysti.brainstorm.agents</code></td> <td><code>[\"claude-code\", \"openai-codex\"]</code></td> <td>Which 2 agents to use in brainstorm mode</td> </tr> <tr> <td><code>mysti.brainstorm.discussionMode</code></td> <td><code>quick</code></td> <td><code>quick</code> or <code>full</code></td> </tr> <tr> <td><code>mysti.accessLevel</code></td> <td><code>ask-permission</code></td> <td>File access level</td> </tr> <tr> <td><code>mysti.agents.autoSuggest</code></td> <td><code>true</code></td> <td>Auto-suggest personas</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Keyboard Shortcuts</h2> <markdown-accessiblity-table><table> <thead> <tr> <th>Action</th> <th>Windows/Linux</th> <th>Mac</th> </tr> </thead> <tbody> <tr> <td>Open Mysti</td> <td><code>Ctrl+Shift+M</code></td> <td><code>Cmd+Shift+M</code></td> </tr> <tr> <td>Open in New Tab</td> <td><code>Ctrl+Shift+N</code></td> <td><code>Cmd+Shift+N</code></td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Commands</h2> <markdown-accessiblity-table><table> <thead> <tr> <th>Command</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>Mysti: Open Chat</code></td> <td>Open the chat sidebar</td> </tr> <tr> <td><code>Mysti: New Conversation</code></td> <td>Start fresh</td> </tr> <tr> <td><code>Mysti: Add to Context</code></td> <td>Add file/selection to context</td> </tr> <tr> <td><code>Mysti: Clear Context</code></td> <td>Clear all context</td> </tr> <tr> <td><code>Mysti: Open in New Tab</code></td> <td>Open chat as editor tab</td> </tr> </tbody> </table></markdown-accessiblity-table> <hr> <h2 tabindex=\"-1\" dir=\"auto\">Telemetry</h2> <p dir=\"auto\">Mysti collects <strong>anonymous</strong> usage data to improve the extension:</p> <ul dir=\"auto\"> <li>Feature usage patterns</li> <li>Error rates</li> <li>Provider preferences</li> </ul> <p dir=\"auto\"><strong>No code, file paths, or personal data is ever collected.</strong></p> <p dir=\"auto\">Respects VSCode's telemetry setting. Disable via: Settings &gt; Telemetry: Telemetry Level &gt; off</p> <hr> <h2 tabindex=\"-1\" dir=\"auto\">License</h2> <p dir=\"auto\"><strong>Business Source License 1.1 (BSL 1.1)</strong></p> <ul dir=\"auto\"> <li><strong>Free</strong> for personal, educational, and non-profit use</li> <li><strong>Commercial use</strong> requires a separate license</li> <li>Converts to <strong>MIT License</strong> on December 3, 2030</li> </ul> <p dir=\"auto\">Contact <a href=\"mailto:baha@deepmyst.com\">baha@deepmyst.com</a> for commercial licensing.</p> <hr> <p dir=\"auto\"> <a href=\"https://marketplace.visualstudio.com/items?itemName=DeepMyst.mysti\" rel=\"nofollow\">Install</a> • <a href=\"https://github.com/DeepMyst/Mysti/issues\">Report Issue</a> • <a href=\"https://github.com/DeepMyst/Mysti\">GitHub</a> </p> <p dir=\"auto\"> <strong>Mysti</strong> — Built by <a href=\"https://deepmyst.com/\" rel=\"nofollow\">DeepMyst Inc</a><br> <sub>Made with Mysti/sub&gt; </sub></p>"},{"id":"https://intertapes.net/","title":"Intertapes – collection of found cassette tapes from different locations","link":"https://intertapes.net/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46345528","content":"<a href=\"https://news.ycombinator.com/item?id=46345528\">Comments</a>","date":1766330999000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://github.com/mruby/mruby","title":"Mruby: Ruby for Embedded Systems","link":"https://github.com/mruby/mruby","hnCommentsUrl":"https://news.ycombinator.com/item?id=46351457","content":"<a href=\"https://news.ycombinator.com/item?id=46351457\">Comments</a>","date":1766379614000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div dir=\"auto\"> <h2 tabindex=\"-1\" dir=\"auto\">mruby</h2> <p><a href=\"https://github.com/marketplace/actions/super-linter\"> <img src=\"https://github.com/mruby/mruby/actions/workflows/super-linter.yml/badge.svg\" alt=\"GitHub Super-Linter\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p></div> <h3 tabindex=\"-1\" dir=\"auto\">Table of contents</h3> <ul dir=\"auto\"> <li><a href=\"#what-is-mruby\">What is mruby</a></li> <li><a href=\"#how-to-get-mruby\">How to get mruby</a></li> <li><a href=\"#mruby-homepage\">mruby homepage</a></li> <li><a href=\"#mailing-list\">Mailing list</a></li> <li><a href=\"#how-to-compile-test-and-install-mruby-and-gems\">How to compile, test, and install (mruby and gems)</a></li> <li><a href=\"#building-documentation\">Building documentation</a></li> <li><a href=\"#how-to-customize-mruby-mrbgems\">How to customize mruby (mrbgems)</a></li> <li><a href=\"#index-of-document\">Index of Document</a></li> <li><a href=\"#license\">License</a></li> <li><a href=\"#note-for-license\">Note for License</a></li> <li><a href=\"#how-to-contribute\">How to Contribute</a></li> <li><a href=\"#star-history\">Star History</a></li> <li><a href=\"#contributors\">Contributors</a></li> </ul> <h2 tabindex=\"-1\" dir=\"auto\">What is mruby</h2> <p dir=\"auto\">mruby is the lightweight implementation of the Ruby language complying to (part of) the <a href=\"https://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=59579\" rel=\"nofollow\">ISO standard</a> with more recent features provided by Ruby 3.x. Also, its syntax is Ruby 3.x compatible except for pattern matching.</p> <p dir=\"auto\">You can link and embed mruby within your application. The \"mruby\" interpreter program and the interactive \"mirb\" shell are provided as examples. You can also compile Ruby programs into compiled byte code using the \"mrbc\" compiler. All these tools are located in the \"bin\" directory. \"mrbc\" can also generate compiled byte code in a C source file. See the \"mrbtest\" program under the \"test\" directory for an example.</p> <p dir=\"auto\">This achievement was sponsored by the Regional Innovation Creation R&amp;D Programs of the Ministry of Economy, Trade and Industry of Japan.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to get mruby</h2> <p dir=\"auto\">To get mruby, you can download the stable version 3.4.0 from the official mruby GitHub repository or clone the trunk of the mruby source tree with the \"git clone\" command. You can also install and compile mruby using <a href=\"https://github.com/postmodern/ruby-install\">ruby-install</a>, <a href=\"https://github.com/rbenv/ruby-build\">ruby-build</a> or <a href=\"https://github.com/rvm/rvm\">rvm</a>.</p> <p dir=\"auto\">The latest development version of mruby can be downloaded via the following URL: <a href=\"https://github.com/mruby/mruby/zipball/master\">https://github.com/mruby/mruby/zipball/master</a></p> <p dir=\"auto\">The trunk of the mruby source tree can be checked out with the following command:</p> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"$ git clone https://github.com/mruby/mruby.git\"><pre>$ <span>git clone https://github.com/mruby/mruby.git</span></pre></div> <h2 tabindex=\"-1\" dir=\"auto\">mruby homepage</h2> <p dir=\"auto\">The URL of the mruby homepage is: <a href=\"https://mruby.org/\" rel=\"nofollow\">https://mruby.org</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">Mailing list</h2> <p dir=\"auto\">We don't have a mailing list, but you can use <a href=\"https://github.com/mruby/mruby/issues\">GitHub issues</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to compile, test, and install (mruby and gems)</h2> <p dir=\"auto\">For the simplest case, type</p> <p dir=\"auto\">See the <a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/compile.md\">compile.md</a> file for the detail.</p> <h2 tabindex=\"-1\" dir=\"auto\">Building documentation</h2> <p dir=\"auto\">There are two sets of documentation in mruby: the mruby API (generated by YARD) and C API (Doxygen and Graphviz)</p> <p dir=\"auto\">To build both of them, simply go</p> <p dir=\"auto\">You can also view them in your browser</p> <div dir=\"auto\" data-snippet-clipboard-copy-content=\"rake view_api rake view_capi\"><pre><span>rake view_api</span> <span>rake view_capi</span></pre></div> <h2 tabindex=\"-1\" dir=\"auto\">How to customize mruby (mrbgems)</h2> <p dir=\"auto\">mruby contains a package manager called \"mrbgems\" that you can use to create extensions in C and/or Ruby. For a guide on how to use mrbgems, consult the <a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbgems.md\">mrbgems.md</a> file, and for example code, refer to the <a href=\"https://github.com/mruby/mruby/blob/master/examples/mrbgems\">examples/mrbgems/</a> folder.</p> <h2 tabindex=\"-1\" dir=\"auto\">Index of Document</h2> <ul dir=\"auto\"> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/limitations.md\">About the Limitations of mruby</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/compile.md\">About the Compile</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/debugger.md\">About the Debugger with the <code>mrdb</code> Command</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/gc-arena-howto.md\">About GC Arena</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/hier.md\">About the mruby directory structure</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/link.md\">About Linking with <code>libmruby</code></a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/memory.md\">About Memory Allocator Customization</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbconf.md\">About Build-time Configurations</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/mrbgems.md\">About the Build-time Library Manager</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/guides/symbol.md\">About the Symbols</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/internal/boxing.md\">Internal Implementation / About Value Boxing</a></li> <li><a href=\"https://github.com/mruby/mruby/blob/master/doc/internal/opcode.md\">Internal Implementation / About mruby Virtual Machine Instructions</a></li> </ul> <h2 tabindex=\"-1\" dir=\"auto\">License</h2> <p dir=\"auto\">mruby is released under the <a href=\"https://github.com/mruby/mruby/blob/master/LICENSE\">MIT License</a>.</p> <h2 tabindex=\"-1\" dir=\"auto\">Note for License</h2> <p dir=\"auto\">mruby has chosen a MIT License due to its permissive license allowing developers to target various environments such as embedded systems. However, the license requires the display of the copyright notice and license information in manuals for instance. Doing so for big projects can be complicated or troublesome. This is why mruby has decided to display \"mruby developers\" as the copyright name to make it simple conventionally. In the future, mruby might ask you to distribute your new code (that you will commit,) under the MIT License as a member of \"mruby developers\" but contributors will keep their copyright. (We did not intend for contributors to transfer or waive their copyrights, actual copyright holder name (contributors) will be listed in the <a href=\"https://github.com/mruby/mruby/blob/master/AUTHORS\">AUTHORS</a> file.)</p> <p dir=\"auto\">Please ask us if you want to distribute your code under another license.</p> <h2 tabindex=\"-1\" dir=\"auto\">How to Contribute</h2> <p dir=\"auto\">To contribute to mruby, please refer to the <a href=\"https://github.com/mruby/mruby/blob/master/CONTRIBUTING.md\">contribution guidelines</a> and send a pull request to the <a href=\"https://github.com/mruby/mruby\">mruby GitHub repository</a>. By contributing, you grant non-exclusive rights to your code under the MIT License.</p> <h2 tabindex=\"-1\" dir=\"auto\">Star History</h2> <p dir=\"auto\"><a href=\"https://www.star-history.com/#mruby/mruby&amp;Date\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/07b61adb81bdd4c5be8855a65c3442f275d205fefbe4f2d8d8799d60f1430f87/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6d727562792f6d7275627926747970653d44617465\" alt=\"mruby Star History\" data-canonical-src=\"https://api.star-history.com/svg?repos=mruby/mruby&amp;type=Date\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p> <h2 tabindex=\"-1\" dir=\"auto\">Contributors</h2> <p dir=\"auto\"><a href=\"https://github.com/mruby/mruby/graphs/contributors\"><img src=\"https://camo.githubusercontent.com/80b09660539d28fdbd4eb5a6e82b4c867d51c3871b5df34ca2c2d6355385ede7/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6d727562792f6d7275627926616e6f6e3d31266d61783d353030\" alt=\"mruby Contributors\" data-canonical-src=\"https://contrib.rocks/image?repo=mruby/mruby&amp;anon=1&amp;max=500\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></a></p>"},{"id":"https://ndstudio.gov/posts/automating-federal-retirements","title":"We Automated Federal Retirements","link":"https://ndstudio.gov/posts/automating-federal-retirements","hnCommentsUrl":"https://news.ycombinator.com/item?id=46402327","content":"<a href=\"https://news.ycombinator.com/item?id=46402327\">Comments</a>","date":1766847750000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div><p>Imagine retiring after a lifetime of public service — as a veteran, air traffic controller, or first responder — only to wait six months in financial limbo because a decades-old government process can't handle your application.</p><p>That was the reality for thousands of federal retirees every year since the 60's, having to apply for retirement within a paper-based, broken system plagued by delays and inefficiency.</p><p>If you had told us we’d relocate our lives to move to D.C. to fix this, we’d have called it ridiculous.</p><p>Yat had just left a decade-long run at Airbnb, helping to build it from scrappy startup to public company; likewise, Dennis also came from startups in manufacturing and AI. Government work simply wasn’t in the life plan.</p><p>Yet in under a year, our team of two has transformed this outdated paper process into a modern, digital workflow. The new system is on track to handle 100,000 digital applications by the end of the year, many of which will experience significantly reduced processing time.</p><p>We share our experience in this blog post in hopes that what started as a mission to give retirees the transition they deserve can turn into something bigger: a proven playbook for modernizing outdated government systems. The same systematic problems we encountered are not unique to retirement, and our approach to them can hopefully be applied to streamlining other outdated areas where citizens interface with their government — from applying for benefits, to filing taxes.&nbsp;</p><p>We're proud to have cut through some bureaucracy and make an impact here, and we’re excited for what's possible when talented builders turn their skills to public service.</p><h2>What Makes Retirements So Complicated?</h2><figure><img src=\"https://assets.ndstudio.gov/files.png\" alt=\"The retirement files\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>An example of just how much paper can go into a single retirement case</figcaption></figure><p>Before we arrived, when a federal employee retired, they began by preparing a thick stack of forms to submit to their HR department. Processing this case would involve multiple government parties further assembling and verifying information from additional records. Their HR office, their payroll providers, and OPM each needed to individually review every piece of paper for consistency and accuracy.&nbsp;</p><p>This process can take over six months. During this time, retirees receive only partial payments — sometimes enough to get by, but less than their full annuity.</p><p>It evolved this way over time: new retirement laws had to be supported, checks were added to reduce error rates on paper forms, and digital systems were added piecemeal but never integrated.</p><p>The result was significant inefficiency. For OPM, this even meant physically pulling historic records about retirees from an underground mine in Pennsylvania, where millions of paper records are stored in vast rows of file cabinets.</p><figure><img src=\"https://assets.ndstudio.gov/The%20Mine\" alt=\"photo of the mine\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>“The Mine\" - a former limestone mine 230 feet underground in Boyers, Pennsylvania, where 26,000 file cabinets hold over 400 million pieces of paper relating to retirements</figcaption></figure><p>These challenges hadn't gone unnoticed. In fact, OPM had launched no fewer than <a href=\"https://www.opm.gov/news/secrets-of-opm/200-feet-underground/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>three separate modernization initiatives in the 1980s, '90s, and '00s</span></a>, pouring an estimated $130 million of taxpayer money to try to move this process off of paper. Every single initiative failed.</p><p>A 2014 <a href=\"https://www.washingtonpost.com/sf/national/2014/03/22/sinkhole-of-bureaucracy/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Washington Post investigation</span></a> captured the issues in vivid detail, but that article could just as easily have been written in early 2025. Despite over a decade passing, progress remained glacial, and nothing had seemingly changed.</p><p>This was the broken system we walked into earlier this year.&nbsp;</p><p>At the time, we knew only about the crippling inefficiencies of the paper system, not the string of failed efforts that had come before. So perhaps emboldened by sheer naiveté, we set out to do what our predecessors couldn’t: actually modernize federal retirement processing and deliver something that could finally last.</p><h2>Digitization and retire.opm.gov</h2><figure><img src=\"https://assets.ndstudio.gov/we-do-this-not-because-it-is-easy.png\" alt=\"&quot;We do this not because it is easy&quot; poster\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>Naivete, and a healthy dose of stubbornness</figcaption></figure><p>Our first priority was bringing the whole system online, immediately.</p><p>Speed was of the essence in order to stop the bleeding. We issued a public memo <a href=\"https://www.opm.gov/news/opm-launches-historic-fully-online-retirement-application-system-across-federal-government.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"><span>for a government-wide </span></a>cutoff of new paper into The Mine. In order to support this, the digital replacement had to be ready within a month.</p><p>OPM’s last attempt at modernization had kicked off the Online Retirement Application (ORA), which set out to serve as a digital version of paper-based retirement applications. However, despite starting in 2018 and millions of dollars per year in investment, the platform was still not fully functional. It looked and performed like a website from the 1990s, and key features that were needed for real usage were still missing.</p><figure><img src=\"https://assets.ndstudio.gov/online-application-process\" alt=\"A photo of the Online Retirement Application interface\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>The Online Retirement Application interface</figcaption></figure><p>We initially tried to embed ourselves alongside the OPM development team to accelerate its completion. There were certain retirement types that were critical but not yet supported, and there was no ability for applicants to upload supporting documentation PDFs larger than 5MB.</p><p>What should have been simple ended up near impossible: once again, OPM had bet this modernization effort on a flawed technical direction from the outset. They had committed to building all of this on Microsoft PowerApps, a “no-code” tool meant for building simple web apps, not a professional development platform. For all the complexities required to truly move retirements off of paper, this would be like giving a construction crew Lego bricks to build a 100-story skyscraper.&nbsp;</p><p>When we met with the developers in Macon, Georgia, OPM's engineering hub, they told us the PowerApps experience was so unfriendly that even they were afraid to make changes. Unless they’ve been specifically trained with PowerApps, most software developers would find it extremely unintuitive to build with, making it hard to apply classic coding skills or iterate quickly.</p><p>After several more weeks with little progress and only a few weeks left until launch, we called an emergency meeting.</p><p>We could either continue wrestling with the PowerApps approach with no clear path to success, or pull a Hail Mary of rebuilding the whole system in a modern way. It would be a herculean effort, but it was the only option that gave us a real shot at delivering. The resulting payoff would be the speed, flexibility, and modern capabilities that we knew were possible.</p><p>Scrapping a seven year effort in favor of a weeks-long rebuild wasn't a decision we took lightly. With a high-profile, government-wide rollout already announced, intense public scrutiny, and OPM's painful history of failed attempts, the idea must have sounded insane to many. Yet, it was somehow the most reasonable path forward.</p><p>We were up until 3AM that night detailing next steps. We made a plan for what to do, who to talk to, and how to divide the work. By the next morning, we were off to the races.</p><h2>A New Technical Direction</h2><p>The approach we set for OPM was to stand up a digital platform that could connect every source of retirement information, and serve a modern experience to every user in the process. We leveraged industry standard web technologies, while integrating with some of OPM’s existing expertise to prioritize easy adoption and longevity. Beyond just enabling our immediate team to move fast, we needed to set a foundation for years to come beyond our direct involvement. The technologies we chose were broadly adopted by the developer community, well documented, and battle-tested.</p><figure><img src=\"https://assets.ndstudio.gov/tech-stack-1.png\" alt=\"An image of the technical stack we chose\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>The tech stack</figcaption></figure><p>This would usually be the part of a technical blog where we would brag about fancy frameworks or proudly show off a unique architecture design. The reality is we simply stuck to solid fundamentals: understand your query patterns, make sure tables are properly indexed, write efficient joins, and execute things in batch - and when the time calls for it, move long-running processes off the main application and onto asynchronous workers (we used Azure Functions).</p><p>An additionally unique aspect of government was that it can be challenging to get third party vendor tooling. As a result, we often built much of our own tooling from scratch, including our own roles based permissioning system and a feature flagging system.</p><p>All of this was developed in the ensuing weeks towards launch. After a blur of late nights, last minute bug fixes, and constant communication with the OPM team, we finally got it done.&nbsp;</p><p>On June 2, 2025, retire.opm.gov went live. By August 4th, almost every agency in the federal government was using the new Online Retirement Application, ending all paper submissions.</p><figure><img src=\"https://assets.ndstudio.gov/celebration.jpeg\" alt=\"Celebrating the launch of the first app\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></figure><h2>Designing A Better Experience</h2><p>With the system online, there were still many improvements to be made. Like taxes, applying for retirement was still an incredibly confusing process. Working closely with talented designers and the Retirement Services team at OPM, we set out to reinvent the user experience from end-to-end.</p><p>During the day we’d collaborate closely with Retirement Services to synthesize feedback from users all across the government. At night, we’d lock in and address every last issue and complaint.</p><p>Impactful features came out of this: the new Online Retirement Application now incorporates a live annuity estimator so users can see how their choices for benefits and elections impact their annuity in real-time as they fill out their application, instead of finding out months later as they receive their first check.&nbsp;</p><figure><img src=\"https://assets.ndstudio.gov/new-interface.png\" alt=\"The new retirement interface we had built\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>The new retirement interface built using Tailwind, ShadCN, and Next.js</figcaption></figure><h2>The Promise Of “Instant” Retirement</h2><p>Even though retirees and agencies now work on a modern digital foundation, the delays and redundant steps have not yet been fully eliminated. Retirees still wait longer than necessary for their full paycheck.</p><p>Fortunately, we stumbled on a critical clue. While poring over old documentation, we discovered that OPM actually had data warehouses that stored historic information about every federal employee. Apparently, these warehouses were created as part of a modernization effort in 2007, and HR and payroll offices all across government have supposedly been regularly reporting into it.&nbsp;</p><p>For some reason however, this was not well known at OPM, and those that knew about it didn’t know what data it held, nor considered how it could be used to simplify retirement processing. Not many had seen the data, and administrators were initially resistant to sharing access.</p><p>From a software perspective, this was the holy grail: a single source of truth that held all the information that the manual redundant steps were meant to review. Because the information was regularly reported by HR and payroll, by the time an employee retired, OPM should already have everything needed to process the retirement, without anyone re-entering or re-verifying information.</p><p>We needed to see this data for ourselves. After weeks of navigating through a jungle of bureaucratic red-tape, what we finally uncovered was eye-opening: the data was far richer and higher-quality than anyone had anticipated. All along, OPM had actually been sitting on top of a digital version of their underground Mine. It had just been forgotten and buried over time.</p><p>The hypothesis was clear: if we could successfully incorporate this high-quality data into the new digital workflow — and prove its reliability to every stakeholder along the way — we could eliminate the time-consuming manual checks entirely.</p><figure><img src=\"https://assets.ndstudio.gov/celebration-from-the-mine.jpeg\" alt=\"Celebration in the mine\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>Celebration in the mine after getting instant retirement to work</figcaption></figure><p>Operations gave us 500 recently processed applications to test with, and we queried the data out of the databases into the official annuity calculator. Result: Every non-complex case matched down to the penny. <strong>This proved that the buried digital mine was accurate enough to pay retirees their exact amount on day one.</strong></p><p>Around the agency, people were excited, but still tentative: What about missing fields? What about the messy edge cases?</p><p>Our solution was through product design. The “Instant” experience would be a “show but verify” type of experience. Retirees see their application pre-filled from OPM's data, then get the opportunity to make corrections. If the data looks correct and they don't make elections that complicate the case, the application qualifies as \"Instant\".</p><figure><img src=\"https://assets.ndstudio.gov/ui.png\" alt=\"A photo of the retirement UI\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"><figcaption>The application is pre-filled with OPM’s data, and retirees confirm it. If the data looks good, this qualifies for “Instant”</figcaption></figure><p>We launched this offering in the new Online Retirement Application (ORA), where thousands of cases now qualify for “Instant” processing.</p><p>Last month, we returned to the Mine to pilot these with the team using real retirements. Deep underground, next to the old stacks of paper, the team triggered their first ever “instantly adjudicated” application. The experiment’s success proved what we had hoped: OPM’s existing data could reliably process Instant cases without manual work.</p><p>Now, with everyone bought into the vision, we are setting our sights towards making Instant retirement a widespread reality.</p><h2>What’s Next</h2><p>Over the next few months the technical work will only get more sophisticated as we aim to create the first truly automated retirement process end-to-end. Imagine “Full Self-Driving” with no manual interventions or redundant checks, delivering rapid retirements and paychecks for our retiring civil servants.</p><p>We’ll expand the “Instant” program government-wide by partnering with HR and payroll offices to simplify some of their processes as well. It’s not just the OPM portion that will experience faster processing and reduced backlogs, every participant in the process will see improvements.</p><p>Along the way, we’ll also keep building the tools our users need. From simple wins like bulk case management and real-time dashboards, to sophisticated AI that flags potential issues early, these tools will further help to reduce processing time, even for cases where manual work is still necessary.</p><p>Our initial data warehouse discovery unlocked the first Instant cases, but dozens of other systems — payroll, insurance, personnel records — hold valuable data. New integrations are coming which will result in more pre-filled fields, fewer errors, and faster, more accurate outcomes.</p><p>The pattern is consistent - the data to streamline federal services often already exists, it's just sitting in disconnected systems that don't talk to each other. Connect them, and suddenly month-long processes can become instant.</p><p>Outdated systems are everywhere in government, and initiatives like ours are exactly what <a href=\"https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>the President’s Executive Order earlier this year</span></a> called for. We hope this project serves as a blueprint for similar efforts, demonstrating how to successfully drive the technological and operational changes needed to bring government into the modern era.</p><h2>Reflections</h2><p>A year ago, government work wasn't even on our radar. But the reality surprised us.</p><p>Every federal employee who retires from now on can use what we built — for all 2.3 million current employees and everyone who follows. We shipped a government-wide system in six months, built to last. Few places let you create this kind of impact this fast.</p><p>The problems are genuinely interesting — integrating fragmented systems with no single source of truth, encoding decades of retirement law, bridging legacy tech, building trust in automation, and driving the operational shifts to match.</p><p>We built most of this as a small team of two engineers. We're still building, and there’s many more opportunities like this throughout the government. If this sounds like the kind of problem you want to work on, we should talk.</p><p>Thank you to Scott Kupor, Joe Gebbia, the OPM Retirement Services team, and countless others for their partnership in making this project a reality. Additional thanks to Edward Coristine and Zach Terrell for reviewing this blog post.</p></div></div>"},{"id":"https://purplesyringa.moe/blog/faster-practical-modular-inversion/","title":"Faster practical modular inversion","link":"https://purplesyringa.moe/blog/faster-practical-modular-inversion/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46341904","content":"<a href=\"https://news.ycombinator.com/item?id=46341904\">Comments</a>","date":1766286828000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div><p><time>December 20, 2025</time></p><p>Last year, <a href=\"https://lemire.me/blog/2024/04/13/greatest-common-divisor-the-extended-euclidean-algorithm-and-speed/\">Lemire wrote</a> about an optimized variation of <a href=\"https://en.wikipedia.org/wiki/Euclidean_algorithm\">the Euclidean algorithm</a> for computing <a href=\"https://en.wikipedia.org/wiki/Greatest_common_divisor\">the greatest common divisor</a> of two numbers, called <em>binary Euclidean algorithm</em> or <em>Stein’s algorithm</em>. It’s a best-of-class implementation, though it’s currently only used by libc++.</p><p>The post also briefly mentions <a href=\"https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm\">the extended Euclidean algorithm</a>, a related algorithm most often used to compute the <a href=\"https://en.wikipedia.org/wiki/Modular_multiplicative_inverse\">modular multiplicative inverse</a> (given a remainder <eq><math><mi>a</mi></math></eq> and a modulus <eq><math><mi>m</mi></math></eq>, find <eq><math><mi>x</mi></math></eq> such that <eq><math><mrow><mi>a</mi><mo>⋅</mo></mrow><mrow><mi>x</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><mi>m</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>):</p><blockquote><p>There is also a binary version of the extended Euclidean algorithm[,] although it is quite a bit more involved and it is not clear that it […] can be implemented at high speed, leveraging fast instructions, when working on integers that fit in general-purpose registers. […]</p><p>My implementation of the binary extended Euclidean algorithm is quite a bit slower and not recommended. I expect that it should be possible to optimize it further.</p><p><em>– Lemire</em></p></blockquote><p>That’s a big shame, because the extended Euclidean algorithm can be optimized in a very similar manner, and the underlying ideas were described <a href=\"https://eprint.iacr.org/2020/972.pdf\">in a 2020 paper</a>. It’s probably not well-known because the paper focuses on constant-time evaluation and long arithmetic, so people might have assumed it’s irrelevant.</p><p>I’m hoping to bring justice to the extended Stein’s algorithm with this post. I’ll cover how the algorithm works, its limitations, some optimizations compared to Pornin’s paper, and potential further improvements.</p><p>My implementation is <a href=\"https://github.com/purplesyringa/mod2k/blob/104603af3866ac274073a5b2af28f7a41550add1/src/xgcd.rs\">available on GitHub</a> as part of a Rust modular arithmetic library.</p><p>The textbook algorithm can be used not only to compute inverses, but also to solve <a href=\"https://en.wikipedia.org/wiki/Diophantine_equation\">linear Diophantine equations</a>. I will focus on the former in this post, since that’s where the optimizations shine at. I’ll briefly cover the general case at the end of the post.</p><p>I won’t make claims on exact performance, because something strange is going on with the Lemire’s benchmarking results and I don’t want to add to the mess. I’ve measured that my implementation of the algorithm is <eq><math><mn>1.3</mn></math></eq> – <eq><math><mn>2</mn></math></eq> times faster than the textbook implementation on average, even on M4, but you may see a completely different picture if your compiler produces slightly different codegen.</p><blockquote><p>Lemire’s benchmark seems to be skewed by the choice of the compiler (GCC vs Clang), its version (Clang 18 vs Clang 21), optimization flags (<code>-O2</code> vs <code>-O3</code>), the microarchitecture (Haswell vs Ice Lake vs Zen 2), and minutiae of the benchmarking code. Results don’t make much sense mathematically and look disproportionately affected by microarchitectural conditions.</p><p>If you want to get the fastest implementation, I suggest you inspect the assembly more closely than me, because I have no idea what’s going on.</p></blockquote><p>Nevertheless, here is some raw data for transparency. The benchmark measures the time per inversion (in ns), the cell format is “Stein’s algorithm / Euclidean algorithm”.</p><div><table><thead><tr><th>8 bits</th><th>16 bits</th><th>32 bits</th><th>64 bits</th></tr></thead><tbody><tr><th>Haswell</th><td><span>11.38</span> / <span>19.21</span> (-41%)</td><td><span>17.48</span> / <span>33.96</span> (-49%)</td><td><span>29.76</span> / <span>61.69</span> (-52%)</td><td><span>67.18</span> / <span>152.19</span> (-56%)</td></tr><tr><th>Alder Lake</th><td><span>8.20</span> / <span>10.19</span> (-20%)</td><td><span>13.77</span> / <span>16.87</span> (-18%)</td><td><span>21.47</span> / <span>31.00</span> (-31%)</td><td><span>50.38</span> / <span>69.57</span> (-28%)</td></tr><tr><th>Zen 5</th><td><span>7.77</span> / <span>10.56</span> (-26%)</td><td><span>9.43</span> / <span>14.80</span> (-36%)</td><td><span>13.96</span> / <span>23.98</span> (-42%)</td><td><span>34.58</span> / <span>49.24</span> (-30%)</td></tr><tr><th>M1</th><td><span>14.58</span> / <span>13.05</span> (+12%)</td><td><span>11.48</span> / <span>18.63</span> (-38%)</td><td><span>19.74</span> / <span>35.47</span> (-44%)</td><td><span>43.14</span> / <span>71.14</span> (-39%)</td></tr><tr><th>M2</th><td><span>8.93</span> / <span>10.26</span> (-13%)</td><td><span>11.00</span> / <span>17.90</span> (-39%)</td><td><span>19.38</span> / <span>33.78</span> (-43%)</td><td><span>41.33</span> / <span>68.03</span> (-39%)</td></tr><tr><th>M4</th><td><span>5.28</span> / <span>8.60</span> (-39%)</td><td><span>8.07</span> / <span>14.77</span> (-45%)</td><td><span>13.63</span> / <span>28.05</span> (-51%)</td><td><span>28.68</span> / <span>56.22</span> (-49%)</td></tr><tr><th>Cortex-A72</th><td><span>29.80</span> / <span>33.48</span> (-11%)</td><td><span>38.30</span> / <span>49.36</span> (-22%)</td><td><span>61.28</span> / <span>83.63</span> (-27%)</td><td><span>162.55</span> / <span>151.77</span> (+7%)</td></tr><tr><th>Snapdragon 8 Gen 3</th><td><span>9.72</span> / <span>12.13</span> (-20%)</td><td><span>14.97</span> / <span>21.91</span> (-32%)</td><td><span>28.51</span> / <span>39.89</span> (-29%)</td><td><span>70.11</span> / <span>75.46</span> (-7%)</td></tr><tr><th>Kryo 485</th><td><span>15.08</span> / <span>19.36</span> (-22%)</td><td><span>21.54</span> / <span>30.41</span> (-29%)</td><td><span>33.63</span> / <span>50.96</span> (-34%)</td><td><span>90.32</span> / <span>94.76</span> (-5%)</td></tr></tbody></table></div><p>Let’s start with the algorithm for computing the GCD of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq>. Suppose for now that <eq><math><mi>b</mi></math></eq> is odd. Here’s the core idea:</p><ul><li>If <eq><math><mi>a</mi></math></eq> is divisible by <eq><math><msup><mn>2</mn><mi>k</mi></msup></math></eq>, this factor can be removed: <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msup><mn>2</mn><mi>k</mi></msup><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>. This decreases the bit length of <eq><math><mi>a</mi></math></eq> by at least <eq><math><mn>1</mn></math></eq>, guaranteeing <eq><math><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>a</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> time complexity if we can apply this reduction consistently.</li><li>If both <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> are odd, rewriting <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo>−</mo><mi>b</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> guarantees <eq><math><mrow><msup><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo></mrow><mrow><mi>a</mi><mo>−</mo></mrow><mrow><mi>b</mi></mrow></math></eq> will be even and reducible on the next iteration. To avoid negative integers, swap <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> if <eq><math><mrow><mi>a</mi><mo>&lt;</mo></mrow><mrow><mi>b</mi></mrow></math></eq> beforehand; new <eq><math><mi>b</mi></math></eq> remains odd because <eq><math><mi>a</mi></math></eq> was odd.</li></ul><p>The implementation is very short:</p><pre><code><span>while</span> a != <span>0</span> { a &gt;&gt;= a.<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b, a); } a -= b; } <span>return</span> b; </code></pre><p>If the initial <eq><math><mi>b</mi></math></eq> is not guaranteed to be odd, some adjustments are necessary:</p><pre><code><span>let</span> <span>shift</span> = (a | b).<span>trailing_zeros</span>(); <span>// == min(a.trailing_zeros(), b.trailing_zeros())</span> b &gt;&gt;= b.<span>trailing_zeros</span>(); <span>/* loop from the previous snippet */</span> <span>return</span> b &lt;&lt; shift; </code></pre><p>But for modular inversion, the modulus is usually odd, so I won’t dwell on this.</p><p>This covers the general structure of the algorithm, but some optimizations are crucial for getting good performance.</p><p>The conditional swap should be compiled to branchless code to avoid branch misprediction. Compiler hints like <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#builtin-unpredictable\">__builtin_unpredictable</a> or <a href=\"https://doc.rust-lang.org/stable/core/hint/fn.select_unpredictable.html\">core::hint::select_unpredictable</a> may be useful.</p><p>The loop has a high latency because <code>trailing_zeros</code>, <code>&gt;&gt;=</code>, <code>if</code>, and <code>-=</code> are computed sequentially. But since <code>(-a).trailing_zeros() == a.trailing_zeros()</code>, <code>a.trailing_zeros()</code> can in principle be computed before the swap on the previous iteration:</p><pre><code><span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { a &gt;&gt;= q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); } <span>else</span> { (a, b) = (a - b, b); } } </code></pre><p>This brings the latency down to 3 operations: <code>&gt;&gt;=</code>; <code>a - b</code> and <code>b - a</code> computed in parallel; <code>trailing_zeros</code> and <code>if</code> computed in parallel. It also slightly increases the number of operations (computing <code>b - a</code> and <code>a - b</code> and only using one), but the tradeoff pays off.</p><p>Pay close attention to <code>trailing_zeros</code> if you’re implementing this in C. The algorithm can invoke it with a zero input on the last iteration. This is well-defined in Rust, which maps <eq><math><mn>0</mn></math></eq> to the bit width of the data type, but in C <code>__builtin_clz(0)</code> is UB. Use <code>__builtin_clzg</code> to avoid issues. In C++, <code>std::countr_zero(0)</code> is well-defined.</p><blockquote><p>GCC <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Bit-Operation-Builtins.html\">documents</a> <code>__builtin_clz(0)</code> as having an “undefined result”, so I initially assumed it means an indeterminate value. In reality, <a href=\"https://gcc.gnu.org/bugzilla/show_bug.cgi?id=116989\">GCC maintainers consider it UB</a> and <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#builtin-clzg-and-builtin-ctzg\">LLVM documents it as UB</a>… but the optimizers seem to model it exactly like an indeterminate value? (e.g. LLVM considers <code>@llvm.cttz(0)</code> to produce <code>poison</code>) This is frankly ridiculous, someone do something about it.</p></blockquote><div><p>You might be wondering how this algorithm is related to modular inversion.</p><p>The trick is to express the values of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> at each point as weighted sums of the original <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> (denoted <eq><math><mrow><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>) with some coefficients <eq><math><mrow><msub><mi>k</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mi>i</mi></msub></mrow></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>If <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> is invertible modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, their GCD is <eq><math><mn>1</mn></math></eq>, and so at the end of the algorithm <eq><math><mrow><mi>b</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>. This gives us:</p><section><eqn><math display=\"block\"><mrow><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><mo stretchy=\"false\">⟹</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>That is, <eq><math><msub><mi>k</mi><mn>1</mn></msub></math></eq> is the inverse of <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>. So all we need to do is track the coefficients across iterations. We start with:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mn>0</mn><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><msub><mi>b</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>When <eq><math><mi>a</mi></math></eq> is divided by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, the coefficients are divided by the same value:</p><section><eqn><math display=\"block\"><mrow><mi>a</mi><mo>=</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo stretchy=\"false\">⟹</mo><mfrac><mi>a</mi><msup><mn>2</mn><mi>q</mi></msup></mfrac><mo>=</mo><mfrac><msub><mi>k</mi><mn>0</mn></msub><msup><mn>2</mn><mi>q</mi></msup></mfrac><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mfrac><msub><mi>l</mi><mn>0</mn></msub><msup><mn>2</mn><mi>q</mi></msup></mfrac><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eqn></section><p>When <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> are swapped, the pairs <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> and <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq> are swapped.</p><p>When <eq><math><mi>b</mi></math></eq> is subtracted from <eq><math><mi>a</mi></math></eq>, the coefficients are subtracted:</p><section><eqn><math display=\"block\"><mrow><mi>a</mi><mo>−</mo><mi>b</mi><mo>=</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo>−</mo><msub><mi>k</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>l</mi><mn>0</mn></msub><mo>−</mo><msub><mi>l</mi><mn>1</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eqn></section><p>In other words, whatever we do to <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq>, we also do to the coefficient pairs <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>l</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>.</p></div><p>Implementation attempts quickly reveal a problem: coefficients are not necessarily divisible by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, so it’s not clear how to represent them. Surely not with floats.</p><p>This is actually a core difference between Stein’s algorithm and the textbook Euclidean algorithm, which is implemented as <eq><math><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>b</mi><mo separator=\"true\">,</mo><mi>a</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><mi>b</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>.</p><p>The Euclidean algorithm uses division (<code>q = a / b</code>), but only to compute constant factors. The values are updated with subtraction and multiplication alone (<code>a -= b * q</code>). Stein’s algorithm divides values (<code>a /= 2^q</code>), causing non-integer coefficients.</p><p>This is likely why the extended Stein’s algorithm is unpopular. We’ll use tricks tailored to modular inverse, but the general-purpose case covered at the end of the post essentially boils down to “compute modular inverse and post-process”. I believe it can still be faster than the textbook implementation, but I haven’t tested it.</p><p>We can track coefficients as fractions to stay in integers. The most efficient approach uses the same denominator <eq><math><msup><mn>2</mn><mi>p</mi></msup></math></eq> for all variables:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>a</mi><mo>=</mo><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mi>p</mi></mrow></msup><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>0</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>0</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi><mo>=</mo><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mi>p</mi></mrow></msup><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>k</mi><mn>1</mn></msub><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msub><mi>l</mi><mn>1</mn></msub><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>We start with <eq><math><mrow><mi>p</mi><mo>=</mo></mrow><mrow><mn>0</mn></mrow></math></eq>. Instead of dividing <eq><math><mrow><msub><mi>k</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mn>0</mn></msub></mrow></math></eq> by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>, we increase <eq><math><mi>p</mi></math></eq> by <eq><math><mi>q</mi></math></eq> and multiply <eq><math><mrow><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>l</mi><mn>1</mn></msub></mrow></math></eq> by <eq><math><msup><mn>2</mn><mi>q</mi></msup></math></eq>. Subtraction can ignore <eq><math><mi>p</mi></math></eq> because all coefficients use the same precision.</p><p>This seems pointless at first, since we need to know <eq><math><mrow><msup><mn>2</mn><mrow><mo lspace=\"0em\" rspace=\"0em\">−</mo><mi>p</mi></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, but if the modulus is fixed, we can precompute it. Each iteration reduces the total bit length of <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> by at least <eq><math><mi>q</mi></math></eq>, and after the last right-shift <eq><math><mrow><mi>a</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>b</mi><mo>≠</mo></mrow><mrow><mn>0</mn></mrow></math></eq>, so if the input numbers fit in <eq><math><mi>k</mi></math></eq> bits, the sum of <eq><math><mi>q</mi></math></eq> (and thus <eq><math><mi>p</mi></math></eq>) is limited by <eq><math><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq>. This means that we can increase precision to <eq><math><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq> at the end and use a single precomputed value <eq><math><mrow><msup><mn>2</mn><mrow><mo lspace=\"0em\" rspace=\"0em\">−</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mn>2</mn><mi>k</mi><mo>−</mo><mn>2</mn><mo form=\"postfix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">)</mo></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>.</p><p>The multitude of variables is getting confusing, so let’s simplify it. We’re looking for <eq><math><mrow><msub><mi>k</mi><mn>1</mn></msub><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> and don’t care about <eq><math><msub><mi>l</mi><mi>i</mi></msub></math></eq>, so tracking just <eq><math><msub><mi>k</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>k</mi><mn>1</mn></msub></math></eq> suffices. Let’s rename these variables to <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> respectively to get rid of indices. This gives us:</p><pre><code><span>// Example for 32-bit inputs (k = 32).</span> <span>let</span> <span>mut </span><span>u</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v</span> = <span>0</span>; <span>let</span> <span>mut </span><span>p</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { a &gt;&gt;= q; v &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (u, v) = (v, u); } <span>else</span> { (a, b) = (a - b, b); } u -= v; } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); v &lt;&lt;= <span>62</span> - p; <span>return</span> (v * inverse_of_2p62) % b0; </code></pre><p>We don’t apply the latency-reducing trick to <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> because the latency is dominated by other calculations. Computing both <code>u - v</code> and <code>v - u</code> would most likely reduce performance, since we’re already pushing the CPU limit of parallel operations.</p><div><p>It’s easy to prove by induction that at the beginning of each iteration,</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>&lt;</mo><mi>u</mi><mo>&lt;</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>&lt;</mo><mi>v</mi><mo>≤</mo><msup><mn>2</mn><mi>p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></eqn></section></div><p>This means that <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> fit in signed <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq>-bit integers. Since <eq><math><mrow><mi>p</mi><mo>≤</mo></mrow><mrow><mn>2</mn><mi>k</mi><mo>−</mo></mrow><mrow><mn>2</mn></mrow></math></eq>, that amounts to <eq><math><mrow><mn>2</mn><mi>k</mi></mrow></math></eq>-bit types, i.e. twice as wide as the input. And that’s a problem: while it works just fine for <eq><math><mn>32</mn></math></eq>-bit inputs, <eq><math><mn>64</mn></math></eq>-bit inputs require <code>i128</code> arithmetic, which slows down the algorithm considerably. We’ll discuss what to do about it in a bit.</p><p>Before we do this, though, let’s finish the <eq><math><mn>32</mn></math></eq>-bit case. There’s just one thing left to improve: computing <eq><math><mrow><mi>v</mi><mo>⋅</mo></mrow><mrow><msup><mn>2</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>62</mn></mrow></msup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>.</p><p>On the face of it, this is one multiplication and one reduction, but <a href=\"https://en.wikipedia.org/wiki/Montgomery_modular_multiplication\">Montgomery multiplication</a> demonstrates that these operations can be performed faster together.</p><p>Assume for a moment that <eq><math><mi>v</mi></math></eq> is non-negative. The idea is to subtract a multiple of <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> from <eq><math><mi>v</mi></math></eq> such that the bottom <eq><math><mn>62</mn></math></eq> bits become zero, so that the remainder remains the same, but division by <eq><math><msup><mn>2</mn><mn>62</mn></msup></math></eq> can be performed with a shift. We’re looking for <eq><math><mi>t</mi></math></eq> such that</p><section><eqn><math display=\"block\"><mrow><mi>v</mi><mo>−</mo><mi>t</mi><mo>⋅</mo><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>This is equivalent to <eq><math><mrow><mi>t</mi><mo>=</mo></mrow><mrow><mi>v</mi><mo>⋅</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>, and by precomputing <eq><math><mrow><mi>j</mi><mo>=</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq>, we obtain <eq><math><mrow><mi>v</mi><mo>−</mo></mrow><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> as the easily divisible value. Since <eq><math><mi>v</mi></math></eq> and <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq> have equal bottom <eq><math><mn>62</mn></math></eq> bits,</p><section><eqn><math display=\"block\"><mrow><mfrac><mrow><mi>v</mi><mo>−</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo>=</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mi>v</mi><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo>−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow></mrow></math></eqn></section><p>We’ve just found that <eq><math><mrow><mi>v</mi><mo>≤</mo></mrow><mrow><msup><mn>2</mn><mi>p</mi></msup><mo>≤</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq>, so unless <eq><math><mrow><mi>v</mi><mo>=</mo></mrow><mrow><msup><mn>2</mn><mn>62</mn></msup></mrow></math></eq> exactly, this is just</p><section><eqn><math display=\"block\"><mrow><mo>−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mi>j</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>62</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>62</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo>=</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mfrac><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">(</mo><mi>v</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mn>4</mn><mi>j</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>64</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo><msub><mi>b</mi><mn>0</mn></msub></mrow><msup><mn>2</mn><mn>64</mn></msup></mfrac><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow></mrow></math></eqn></section><p>This number is in range <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><mn>0</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>. We know that <eq><math><mn>0</mn></math></eq> can never be an inverse, so it’s actually <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><mn>1</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, and by adding <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, we obtain the exact remainder. This can be computed with only two multiplications and some glue:</p><pre><code><span>fn</span> <span>redc62</span>(v: <span>i64</span>) <span>-&gt;</span> <span>u32</span> { <span>if</span> v == (<span>1</span> &lt;&lt; <span>62</span>) { <span>1</span> } <span>else</span> { <span>let</span> <span>x</span> = v.<span>unsigned_abs</span>().<span>wrapping_mul</span>(j &lt;&lt; <span>2</span>).<span>widening_mul</span>(b0 <span>as</span> <span>u64</span>).<span>1</span> <span>as</span> <span>u32</span>; <span>if</span> v &gt; <span>0</span> { b0 - x } <span>else</span> { x } } } </code></pre><p>That’s it for <eq><math><mn>32</mn></math></eq>-bit and smaller inputs. Yay! Buy yourself a cupcake.</p><p>For <eq><math><mn>64</mn></math></eq>-bit inputs, coefficients only fit in <code>i128</code>. This makes each operation twice as slow. We can reduce <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> on each iteration so that coefficients fit in <eq><math><mn>64</mn></math></eq> bits, since we only need <eq><math><mrow><mi>v</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, but this tanks performance too.</p><p>Hmm. Notice that at the beginning of the algorithm, <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> fit in <eq><math><mn>1</mn></math></eq> bit and then grow slowly. Only once their length exceeds <eq><math><mn>64</mn></math></eq> bits do we need long integers. What if we could somehow reset the length every few iterations, so that <eq><math><mn>64</mn></math></eq>-bit integers suffice?</p><p>Just like <eq><math><mi>a</mi></math></eq> and <eq><math><mi>b</mi></math></eq> can be represented as weighted sums of <eq><math><mrow><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>, <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq> can be represented as weighted sums of their earlier versions <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>u</mi><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><msub><mi>g</mi><mn>0</mn></msub><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>v</mi><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><msub><mi>g</mi><mn>1</mn></msub><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>The trick is to save <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> and update short coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> instead of long values <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> in the loop. We start with <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo>=</mo></mrow><mrow><mn>1</mn><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub><mo>=</mo></mrow><mrow><mn>0</mn></mrow></math></eq> and trivial coefficients:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mi>u</mi><mo>=</mo><msub><mi>u</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><mn>0</mn><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>v</mi><mo>=</mo><msub><mi>v</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><msub><mi>u</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn><msub><mi>v</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>When the coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> grow past <eq><math><mn>64</mn></math></eq> bits, we pause, compute <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> based on these formulas, replace <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> with <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq>, and reset the coefficients <eq><math><mrow><msub><mi>f</mi><mi>i</mi></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow></math></eq> back to trivial, bringing the length back to <eq><math><mn>1</mn></math></eq>.</p><pre><code><div><p><span>let</span> <span>mut </span><span>u0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v0</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>while</span> a != <span>0</span> { <span>// The coefficients relating (u, v) to (u0, v0).</span> <span>let</span> <span>mut</span> (f0, g0) = (<span>1</span>, <span>0</span>); <span>let</span> <span>mut</span> (f1, g1) = (<span>0</span>, <span>1</span>); <span>let</span> <span>mut </span><span>p</span> = <span>0</span>; <span>// Run the algorithm until p reaches the limit.</span> <span>while</span> a != <span>0</span> &amp;&amp; p + q &lt;= <span>62</span> { a &gt;&gt;= q; f1 &lt;&lt;= q; g1 &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (f0, f1) = (f1, f0); (g0, g1) = (g1, g0); } <span>else</span> { (a, b) = (a - b, b); } f0 -= f1; g0 -= g1; } <span>// This section means different things depending on the reason the loop stopped:</span> <span>// - If we ran out of precision, this performs as much of the last action as possible and</span> <span>// adjusts `q` so that the operation completes on the next iteration.</span> <span>// - If `a = 0`, this effectively raises the precision of f1/g1 to 62. It doesn't adjust</span> <span>// `f0, g0` correctly, but this doesn't matter because `u` is not read on the exit path.</span> a &gt;&gt;= <span>62</span> - p; f1 &lt;&lt;= <span>62</span> - p; g1 &lt;&lt;= <span>62</span> - p; q -= <span>62</span> - p; <span>// Apply the coefficients.</span> <span>let</span> <span>f0</span> = <span>redc62</span>(f0); <span>let</span> <span>g0</span> = <span>redc62</span>(g0); <span>let</span> <span>f1</span> = <span>redc62</span>(f1); <span>let</span> <span>g1</span> = <span>redc62</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % b0, (f1 * u0 + g1 * v0) % b0); } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); <span>return</span> v0; </p><p><label for=\"expansible1\">Expand</label></p></div></code></pre><p>The astute among you might realize this doesn’t improve much, since we went from updating two <eq><math><mn>128</mn></math></eq>-bit numbers in a loop to updating four <eq><math><mn>64</mn></math></eq>-bit numbers in a loop. But since we apply the exact same operations to <eq><math><msub><mi>f</mi><mi>i</mi></msub></math></eq> and <eq><math><msub><mi>g</mi><mi>i</mi></msub></math></eq>, we can vectorize them.</p><div><p>We can’t use SIMD because x86 doesn’t have <code>cmov</code> for vector registers, but we can decrease the coefficient length to <eq><math><mn>32</mn></math></eq> bits and pack two coefficients into one integer:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><msub><mi>c</mi><mn>0</mn></msub><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><mo>+</mo><msup><mn>2</mn><mn>32</mn></msup><msub><mi>g</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><mo>+</mo><msup><mn>2</mn><mn>32</mn></msup><msub><mi>g</mi><mn>1</mn></msub></mrow></mtd></mtr></mtable></mrow></math></eqn></section></div><p>This simplifies the inner loop to:</p><pre><code><span>while</span> a != <span>0</span> &amp;&amp; p + q &lt;= <span>30</span> { a &gt;&gt;= q; c1 &lt;&lt;= q; p += q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (c0, c1) = (c1, c0); } <span>else</span> { (a, b) = (a - b, b); } c0 -= c1; } </code></pre><p>Just like <eq><math><mi>u</mi></math></eq> and <eq><math><mi>v</mi></math></eq>, <eq><math><msub><mi>c</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>c</mi><mn>1</mn></msub></math></eq> take <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq> bits, so we limit <eq><math><mi>p</mi></math></eq> by <eq><math><mrow><mn>32</mn><mo>−</mo></mrow><mrow><mn>2</mn><mo>=</mo></mrow><mrow><mn>30</mn></mrow></math></eq>. But with care, we can squeeze out one more bit. Recall the inequalities:</p><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>&lt;</mo><mi>u</mi><mo>&lt;</mo><msup><mn>2</mn><mrow><mi>p</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>&lt;</mo><mi>v</mi><mo>≤</mo><msup><mn>2</mn><mi>p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>Only <eq><math><mi>u</mi></math></eq> takes <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>2</mn></mrow></math></eq> bits. <eq><math><mi>v</mi></math></eq> fits in <eq><math><mrow><mi>p</mi><mo>+</mo></mrow><mrow><mn>1</mn></mrow></math></eq>, if barely: signed integer types represent the range <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msup><mn>2</mn><mi>p</mi></msup><mo separator=\"true\">;</mo><msup><mn>2</mn><mi>p</mi></msup><mo>−</mo><mn>1</mn><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, while this is <eq><math><mrow><mo form=\"prefix\" stretchy=\"false\">[</mo><mo form=\"prefix\" stretchy=\"false\">−</mo><msup><mn>2</mn><mi>p</mi></msup><mo>+</mo><mn>1</mn><mo separator=\"true\">;</mo><msup><mn>2</mn><mi>p</mi></msup><mo form=\"postfix\" stretchy=\"false\">]</mo></mrow></math></eq>, but the number of distinct values is the same. So even if we run out of the <eq><math><mn>30</mn></math></eq>-bit limit, we can shift <eq><math><mi>v</mi></math></eq> once more. This affects the code after the inner loop:</p><pre><code><span>// 31 would be 30 without this optimization</span> a &gt;&gt;= <span>31</span> - p; c1 &lt;&lt;= <span>31</span> - p; q -= <span>31</span> - p; <span>let</span> (f0, g0) = <span>parse_coefficients</span>(c0); <span>let</span> (f1, g1) = <span>parse_coefficients</span>(c1); <span>let</span> <span>f0</span> = <span>redc31</span>(f0); <span>let</span> <span>g0</span> = <span>redc31</span>(g0); <span>let</span> <span>f1</span> = <span>redc31</span>(f1); <span>let</span> <span>g1</span> = <span>redc31</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % b0, (f1 * u0 + g1 * v0) % b0); </code></pre><p>Note that the inner loop is still limited by <eq><math><mn>30</mn></math></eq>, since it not only shifts <eq><math><mi>v</mi></math></eq>, but also subtracts from <eq><math><mi>u</mi></math></eq>, which could cause an overflow with a limit of <eq><math><mn>31</mn></math></eq>.</p><div><p>Parsing coefficients from <eq><math><msub><mi>c</mi><mi>i</mi></msub></math></eq> is slightly tricky due to the unusual signed integer format, but not impossibly so:</p><section><eqn><math display=\"block\"><mrow><mrow><mi>int</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>x</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mi>x</mi></mtd><mtd><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>≤</mo><msup><mn>2</mn><mn>31</mn></msup></mrow></mtd></mtr><mtr><mtd><mrow><mi>x</mi><mo>−</mo><msup><mn>2</mn><mn>32</mn></msup></mrow></mtd><mtd><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>&gt;</mo><msup><mn>2</mn><mn>31</mn></msup></mrow></mtd></mtr></mtable></mrow></mrow></math></eqn></section><section><eqn><math display=\"block\"><mrow><mo fence=\"true\" form=\"prefix\">{</mo><mtable><mtr><mtd><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>int</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo><msup><mn>2</mn><mn>32</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>int</mi></mrow><mrow><mo fence=\"true\" form=\"prefix\">(</mo><mrow><mo fence=\"true\" form=\"prefix\">⌊</mo><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mfrac><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>+</mo><msup><mn>2</mn><mn>31</mn></msup><mo>−</mo><mn>1</mn></mrow><msup><mn>2</mn><mn>32</mn></msup></mfrac></mstyle><mo fence=\"true\" form=\"postfix\">⌋</mo></mrow><mo fence=\"true\" form=\"postfix\">)</mo></mrow></mrow></mtd></mtr></mtable></mrow></math></eqn></section><p>This assumes that <eq><math><msub><mi>c</mi><mi>i</mi></msub></math></eq> is stored in an unsigned type.</p></div><p>With packed coefficients, the inner loop is similar to the unoptimized version, differing only in <eq><math><mrow><msub><mi>c</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>c</mi><mn>1</mn></msub></mrow></math></eq> vs <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq>. This allows us to cheaply combine two approaches: track the true values <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> for the first <eq><math><mn>62</mn></math></eq> iterations and then switch to coefficients. It’s faster than relying on coefficients alone because it recalculates <eq><math><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator=\"true\">,</mo></mrow><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow></math></eq> less often.</p><p>The final implementation looks something like this:</p><pre><code><div><p><span>let</span> <span>mut </span><span>u0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>v0</span> = <span>0</span>; <span>let</span> <span>mut </span><span>q</span> = a.<span>trailing_zeros</span>(); <span>let</span> <span>mut </span><span>is_first_iteration</span> = <span>true</span>; <span>while</span> a != <span>0</span> { <span>// Either coefficients in SWAR format, or the values u/v, depending on the iteration.</span> <span>let</span> <span>mut </span><span>c0</span> = <span>1</span>; <span>let</span> <span>mut </span><span>c1</span> = <span>if</span> is_first_iteration { <span>0</span> } <span>else</span> { <span>1</span> &lt;&lt; <span>32</span> }; <span>let</span> <span>mut </span><span>p_left</span> = <span>if</span> is_first_iteration { <span>63</span> } <span>else</span> { <span>31</span> }; <span>while</span> a != <span>0</span> &amp;&amp; q &lt; p_left { <span>// &lt; instead of &lt;= is load-bearing</span> a &gt;&gt;= q; c1 &lt;&lt;= q; p_left -= q; q = (a - b).<span>trailing_zeros</span>(); <span>if</span> a &lt; b { (a, b) = (b - a, a); (c0, c1) = (c1, c0); } <span>else</span> { (a, b) = (a - b, b); } c0 -= c1; } a &gt;&gt;= p_left; c1 &lt;&lt;= p_left; q -= p_left; <span>if</span> is_first_iteration { u0 = <span>redc63</span>(c0); v0 = <span>redc63</span>(c1); } <span>else</span> { <span>let</span> (f0, g0) = <span>parse_coefficient</span>(c0); <span>let</span> (f1, g1) = <span>parse_coefficient</span>(c1); <span>let</span> <span>f0</span> = <span>redc31</span>(f0); <span>let</span> <span>g0</span> = <span>redc31</span>(g0); <span>let</span> <span>f1</span> = <span>redc31</span>(f1); <span>let</span> <span>g1</span> = <span>redc31</span>(g1); (u0, v0) = ((f0 * u0 + g0 * v0) % m, (f1 * u0 + g1 * v0) % m); } is_first_iteration = <span>false</span>; } <span>assert!</span>(b == <span>1</span>, <span>\"not invertible\"</span>); <span>return</span> v0; </p><p><label for=\"expansible2\">Expand</label></p></div></code></pre><p>We store <code>p_left</code> instead of <code>p</code> so that <code>p_left -= q</code> and <code>q &lt; p_left</code> can be computed with a single instruction.</p><p>The <eq><math><mn>32</mn></math></eq>-bit and <eq><math><mn>64</mn></math></eq>-bit cases can use the same implementation, as replacing <code>q &lt; p_left</code> with <code>true</code> makes it identical to the <eq><math><mn>32</mn></math></eq>-bit algorithm, and compilers recognize this.</p><p><code>redc31(x)</code> can be implemented as <code>redc63(x &lt;&lt; 32)</code>.</p><p>And that’s it! You now know a cool way to compute <eq><math><mn>64</mn></math></eq>-bit modular inverses.</p><p>To support variable <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, we can compute <eq><math><mrow><mi>j</mi><mo>=</mo></mrow><mrow><msubsup><mi>b</mi><mn>0</mn><mrow><mo form=\"prefix\" lspace=\"0em\" rspace=\"0em\" stretchy=\"false\">−</mo><mn>1</mn></mrow></msubsup><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msup><mn>2</mn><mn>64</mn></msup></mrow></math></eq> in runtime. This can be done very quickly with <a href=\"https://arxiv.org/pdf/2204.04342\">an algorithm by Jeffrey Hurchalla</a>.</p><p><eq><math><mi>j</mi></math></eq> only exists if <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq> is odd. If it’s even, swap <eq><math><msub><mi>a</mi><mn>0</mn></msub></math></eq> and <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>. If both are even, divide them by their common power of two and choose whichever becomes odd as <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>.</p><p>To replace the extended Euclidean algorithm, we need to find <em>integers</em> <eq><math><mrow><mi>x</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>y</mi></mrow></math></eq> such that:</p><section><eqn><math display=\"block\"><mrow><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>0</mn></msub><mi>y</mi><mo>=</mo><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>Luckily, our <eq><math><mi>v</mi></math></eq> is no longer a fraction, but rather a remainder modulo <eq><math><msub><mi>b</mi><mn>0</mn></msub></math></eq>, so we can substitute <eq><math><mrow><mi>x</mi><mo>=</mo></mrow><mrow><mi>v</mi><mo lspace=\"0.2222em\" rspace=\"0.2222em\">mod</mo></mrow><mrow><msub><mi>b</mi><mn>0</mn></msub></mrow></math></eq>. <eq><math><mi>y</mi></math></eq> can then be computed from the equation:</p><section><eqn><math display=\"block\"><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mrow><mi>gcd</mi></mrow><mo form=\"prefix\" stretchy=\"false\">(</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>b</mi><mn>0</mn></msub><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi></mrow><msub><mi>b</mi><mn>0</mn></msub></mfrac><mo>=</mo><mfrac><mrow><mi>b</mi><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi></mrow><msub><mi>b</mi><mn>0</mn></msub></mfrac></mrow></math></eqn></section><p>Since this division is exact, it can be calculated with multiplication by <eq><math><mi>j</mi></math></eq>:</p><section><eqn><math display=\"block\"><mrow><mi>y</mi><mo>=</mo><mi>j</mi><mo>⋅</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mi>b</mi><mo>−</mo><msub><mi>a</mi><mn>0</mn></msub><mi>x</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>mod</mi></mrow><msup><mn>2</mn><mn>64</mn></msup><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eqn></section><p>Despite this complexity, I believe this method can be faster than the extended Euclidean algorithm, since the auxiliary logic takes constant time, except for computing <eq><math><mi>j</mi></math></eq> in <eq><math><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>k</mi><mo form=\"postfix\" stretchy=\"false\">)</mo><mo>=</mo></mrow><mrow><mi>𝒪</mi><mo form=\"prefix\" stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>⁡</mo></mrow><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>a</mi><mo form=\"postfix\" stretchy=\"false\">)</mo></mrow></math></eq>, which is still pretty good.</p><p>As a reminder, you can find my code <a href=\"https://github.com/purplesyringa/mod2k/blob/104603af3866ac274073a5b2af28f7a41550add1/src/xgcd.rs\">on GitHub</a>. The source of latency-optimized GCD is <a href=\"https://lemire.me/blog/2024/04/13/greatest-common-divisor-the-extended-euclidean-algorithm-and-speed/\">this post</a>. Using coefficients to reset bit lengths of <eq><math><mrow><mi>u</mi><mo separator=\"true\">,</mo></mrow><mrow><mi>v</mi></mrow></math></eq> comes from <a href=\"https://eprint.iacr.org/2020/972.pdf\">this paper</a>, which also covers the case when values don’t fit in general-purpose registers.</p><p>Thanks to many friends of mine for contributing to the benchmarking results, to Ian Qvist for the motivation to complete this post and editorial comments, and to Yuki for saving me from going insane over unexplainable performance phenomena.</p></div></div>"},{"id":"https://news.ycombinator.com/item?id=46346648","title":"Ask HN: Resources to get better at outbound sales?","link":"https://news.ycombinator.com/item?id=46346648","hnCommentsUrl":"https://news.ycombinator.com/item?id=46346648","content":"<a href=\"https://news.ycombinator.com/item?id=46346648\">Comments</a>","date":1766339376000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div id=\"bigbox\"><table><tbody><tr id=\"46346648\"><td><span><a href=\"https://news.ycombinator.com/item?id=46346648\">Ask HN: Resources to get better at outbound sales?</a></span></td></tr><tr><td><span><span id=\"score_46346648\">24 points</span> by <a href=\"https://news.ycombinator.com/user?id=sieep\">sieep</a> <span title=\"2025-12-21T17:49:36 1766339376\"><a href=\"https://news.ycombinator.com/item?id=46346648\">3 hours ago</a></span> | <a href=\"https://news.ycombinator.com/hide?id=46346648&amp;goto=item%3Fid%3D46346648\">hide</a> | <a href=\"https://hn.algolia.com/?query=Ask%20HN%3A%20Resources%20to%20get%20better%20at%20outbound%20sales%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0\">past</a> | <a href=\"https://news.ycombinator.com/fave?id=46346648&amp;auth=a597db5a077f6cac5b9fe138a9f71496ed4351c7\">favorite</a> | <a href=\"https://news.ycombinator.com/item?id=46346648\">10&nbsp;comments</a></span></td></tr><tr><td><div><p>Hi!</p><p>I run a small custom software company in Michigan.</p><p>I want to get better at outbound sales beyond just cold emailing or messaging people through LinkedIn.</p><p>We’re about to start publishing case studies and doing some outreach, so I want to take some time to study outbound sales and improve my skills.</p><p>Any recommended courses, books, or frameworks for B2B outbound sales, consultative selling, or building effective outreach pipelines?</p><p>Thanks!</p></div></td></tr></tbody></table><br> <table><tbody><tr id=\"46402782\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>There are lots of online resources for outbound sales which will likely be better than advice you’ll find on a forum full of engineers (unless engineers are your target market)</p><p>I’d focus on zeroing in on a niche (even if it’s an artificial niche). Develop case studies for how you’ve helped people in your specific niche. Then find people in that niche and offer them those same niche services.</p><p>Do not try to be everything to everyone. No one wants to work with a software agency that “does anything”. (Well it’s possible but then you’re competing with thousands of other consultancies).</p><p>If you develop into a niche well, you’ll have less competition, you’ll be able to target the right people more easily, and youll be able to write messaging that speaks to people in that niche.</p><p>Everything gets easier when you narrow in on a small slice of a market. The problem set becomes smaller and easier to solve.</p><p>Once you see some traction, start to expand your niche.</p></div></td></tr></tbody></table></td></tr><tr id=\"46402682\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>When have you bought something?</p><p>Example 1: The other day I was trying to fix a sprinkler. My results were mid, then I saw a truck at my neighbors house with a phone number.</p><p>1. I was not in the market for sprinkler repair until that day. 2. I was too busy to make a market comparison, seeing that my neighbor did it was enough.</p><p>Example 2: I was thinking about refining my mortgage this year. My current servicer called me one day with an offer. It was a competitive but not t optimal deal, but the lady on the phone signaled to me she understood my values and would get it done.</p><p>That’s what you are looking for with outbound, people who are in need, willing to part with cash, but probably not shopping for the thing.</p><p>This is why cold calling works and why volume is so important. You aren’t trying to persuade people who aren’t interested, but trying to find those who are.</p><p>The biggest fear of people with money is not spending money, but that what they pay for won’t work out.</p></div></td></tr></tbody></table></td></tr><tr id=\"46380063\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>Figure out who your target customer is. Imagine yourself in their shoes - how/where do you spend your time, what do you like learning about, under what circumstances would you consider a rando small software company in Michigan.</p></div></td></tr></tbody></table></td></tr><tr id=\"46347046\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>I generally recommend the book Founding Sales (available for free online), but it's targeted at SaaS founders.</p><p>But you're actually doing something even more common: running a consulting business, and there's plenty of content on that for just that reason, so I would go find content on how to scale a consulting business, e.g. this seems like the start of a thread to pull on <a href=\"https://training.kalzumeus.com/newsletters/archive/consulting_1\" rel=\"nofollow\">https://training.kalzumeus.com/newsletters/archive/consultin...</a></p></div></td></tr></tbody></table></td></tr><tr id=\"46402617\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>- Go hangout where your potential buyers hangout. It could be LI, IG, TikTok, Golf clubs, High end bars, Charity events. Make those connections.</p><p>- Make two (nested) lists - the people you know in real life- and the people they might know. Now, can any of these people be your potential buyers? if they are in first list, good, just talk to them, if they are in second list, ask for an introduction from your connection in first list.</p><p>- Advertise where your potential buyers might notice.</p></div></td></tr></tbody></table></td></tr><tr id=\"46346931\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>Relationships are the best resource for sales.</p><p>Because to solve someone's problems, they have to tell you their problems.</p><p>Or to put it another way, the thing you do is to solve the actual problems other people have. That's what you need to sell. You aren't selling the fact that you know how to use a hammer. You are selling the idea that you can build the right hammer for the job.</p><p>So sales is not \"out reach.\" It is \"what do you need?\" and you will probably do better by optimizing for getting to that conversation, not through optimizing for low effort on your part.</p><p>Linked-in is best used for networking not push notification. Networking is about trust. Maybe you can't help with someone's problem but you know someone who can.</p><p>Finally, you can't sell desperately. Good luck.</p></div></td></tr></tbody></table></td></tr><tr id=\"46361117\"><td><table><tbody><tr><td indent=\"0\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"0\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>Hot take, but outbound selling is so ineffective today, that if its it in a playbook, it most likely means it doesnt work</p></div></td></tr></tbody></table></td></tr><tr id=\"46402670\"><td><table><tbody><tr><td indent=\"1\"><img src=\"https://news.ycombinator.com/s.gif\" height=\"1\" width=\"40\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></td><td><br> <div><p>So what would you say should be in the effective playbook for selling going into 2025?</p><p>Also running a small consultancy firm like OP and coming from a technical background, building an effective sales motion is the hardest challenge.</p></div></td></tr></tbody></table></td></tr></tbody></table></div></div>"},{"id":"https://gmpy.dev/blog/2025/psutil-heap-introspection-apis","title":"Detect memory leaks of C extensions with psutil and psleak","link":"https://gmpy.dev/blog/2025/psutil-heap-introspection-apis","hnCommentsUrl":"https://news.ycombinator.com/item?id=46376608","content":"<a href=\"https://news.ycombinator.com/item?id=46376608\">Comments</a>","date":1766591621000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div> <!-- /.post-info --> <p>Memory leaks in Python are often straightforward to diagnose. Just look at RSS, track Python object counts, follow reference graphs. But leaks inside <strong>C extension modules</strong> are another story. Traditional memory metrics such as RSS and VMS frequently fail to reveal them because Python's memory allocator sits above the platform's native heap (see <a href=\"https://docs.python.org/3/c-api/memory.html#the-pymalloc-allocator\">pymalloc</a>). If something in an extension calls <code>malloc()</code> without a corresponding <code>free()</code>, that memory often won't show up where you expect it. You have a leak, and <strong>you don't know</strong>.</p> <p>psutil 7.2.0 introduces two new APIs for <strong>C heap introspection</strong>, designed specifically to catch these kinds of native leaks. They give you a window directly into the underlying platform allocator (e.g. glibc's malloc), letting you track how much memory the C layer is actually consuming.</p> <p>These C functions bypass Python entirely. They don't reflect Python object memory, arenas, pools, or anything managed by <a href=\"https://docs.python.org/3/c-api/memory.html\">pymalloc</a>. Instead, they examine the allocator that C extensions actually use. If your RSS is flat but your C heap usage climbs, you now have a way to see it.</p> <h2>Why native heap introspection matters</h2> <p>Many Python projects rely on C extensions: psutil, NumPy, pandas, PIL, lxml, psycopg, PyTorch, custom in-house modules, etc. And even cPython itself, which implements many of its standard library modules in C. If any of these components mishandle memory at the C level, you get a leak that:</p> <ul> <li>Doesn't show up in Python reference counts (<a href=\"https://docs.python.org/dev/library/sys.html#sys.getrefcount\">sys.getrefcount</a>).</li> <li>Doesn't show up in <a href=\"https://docs.python.org/3/library/tracemalloc.html\">tracemalloc module</a>.</li> <li>Doesn't show up in Python's <a href=\"https://docs.python.org/dev/library/gc.html\">gc</a> stats.</li> <li>Often don't show up in RSS, VMS or <a href=\"https://gmpy.dev/blog/2016/real-process-memory-and-environ-in-python\">USS</a> due to allocator caching, especially for small objects. This can happen, for example, when you forget to <code>Py_DECREF</code> a Python object.</li> </ul> <p>psutil's new functions solve this by inspecting platform-native allocator state, in a manner similar to Valgrind.</p> <h2>heap_info(): direct allocator statistics</h2> <p><code>heap_info()</code> exposes the following metrics:</p> <ul> <li><code>heap_used</code>: total number of bytes currently allocated via <code>malloc()</code> (small allocations).</li> <li><code>mmap_used</code>: total number of bytes currently allocated via <code>mmap()</code> or via large <code>malloc()</code> allocations.</li> <li><code>heap_count</code>: (Windows only) number of private heaps created via <code>HeapCreate()</code>.</li> </ul> <p>Example:</p> <div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>psutil</span> <span>&gt;&gt;&gt;</span> <span>psutil</span><span>.</span><span>heap_info</span><span>()</span> <span>pheap</span><span>(</span><span>heap_used</span><span>=</span><span>5177792</span><span>,</span> <span>mmap_used</span><span>=</span><span>819200</span><span>)</span> </code></pre></div> <p>Reference for what contributes to each field:</p> <table> <thead> <tr> <th>Platform</th> <th>Allocation type</th> <th>Field affected</th> </tr> </thead> <tbody> <tr> <td>UNIX / Windows</td> <td>small <code>malloc()</code> ≤128 KB without <code>free()</code></td> <td><code>heap_used</code></td> </tr> <tr> <td>UNIX / Windows</td> <td>large <code>malloc()</code> &gt;128 KB without <code>free()</code>, or <code>mmap()</code> without <code>munmap()</code> (UNIX)</td> <td><code>mmap_used</code></td> </tr> <tr> <td>Windows</td> <td><code>HeapAlloc()</code> without <code>HeapFree()</code></td> <td><code>heap_used</code></td> </tr> <tr> <td>Windows</td> <td><code>VirtualAlloc()</code> without <code>VirtualFree()</code></td> <td><code>mmap_used</code></td> </tr> <tr> <td>Windows</td> <td><code>HeapCreate()</code> without <code>HeapDestroy()</code></td> <td><code>heap_count</code></td> </tr> </tbody> </table> <h2>heap_trim(): returning unused heap memory</h2> <p><code>heap_trim()</code> provides a cross-platform way to request that the underlying allocator free any unused memory it's holding in the heap (typically small <code>malloc()</code> allocations).</p> <p>In practice, modern allocators rarely comply, so this is not a general-purpose memory-reduction tool and won't meaningfully shrink RSS in real programs. Its primary value is in <strong>leak detection tools</strong>.</p> <p>Calling <code>heap_trim()</code> before taking measurements helps reduce allocator noise, giving you a cleaner baseline so that changes in <code>heap_used</code> come from the code you're testing, not from internal allocator caching or fragmentation.</p> <h2>Real-world use: finding a C extension leak</h2> <p>The workflow is simple:</p> <ol> <li>Take a baseline snapshot of the heap.</li> <li>Call the C extension hundreds of times.</li> <li>Take another snapshot.</li> <li>Compare.</li> </ol> <div><pre><code><span>import</span> <span>psutil</span> <span>psutil</span><span>.</span><span>heap_trim</span><span>()</span> <span># reduce noise</span> <span>before</span> <span>=</span> <span>psutil</span><span>.</span><span>heap_info</span><span>()</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>200</span><span>):</span> <span>my_cext_function</span><span>()</span> <span>after</span> <span>=</span> <span>psutil</span><span>.</span><span>heap_info</span><span>()</span> <span>print</span><span>(</span><span>\"delta heap_used =\"</span><span>,</span> <span>after</span><span>.</span><span>heap_used</span> <span>-</span> <span>before</span><span>.</span><span>heap_used</span><span>)</span> <span>print</span><span>(</span><span>\"delta mmap_used =\"</span><span>,</span> <span>after</span><span>.</span><span>mmap_used</span> <span>-</span> <span>before</span><span>.</span><span>mmap_used</span><span>)</span> </code></pre></div> <p>If <code>heap_used</code> or <code>mmap_used</code> values increase consistently, you've found a native leak.</p> <p>To reduce false positives, repeat the test multiple times, increasing the number of calls on each retry. This approach helps distinguish real leaks from random noise or transient allocations.</p> <h2>A new tool: psleak</h2> <p>The strategy described above is exactly what I implemented in a new PyPI package, which I called <strong><a href=\"https://github.com/giampaolo/psleak\">psleak</a></strong>. It runs the target function repeatedly, trims the allocator before each run, and tracks differences across retries. Memory that grows consistently after several runs is flagged as a leak.</p> <p>A minimal test suite looks like this:</p> <div><pre><code> <span>from</span> <span>psleak</span> <span>import</span> <span>MemoryLeakTestCase</span> <span>class</span> <span>TestLeaks</span><span>(</span><span>MemoryLeakTestCase</span><span>):</span> <span>def</span> <span>test_fun</span><span>(</span><span>self</span><span>):</span> <span>self</span><span>.</span><span>execute</span><span>(</span><span>some_c_function</span><span>)</span> </code></pre></div> <p>If the function leaks memory, the test will fail with a descriptive exception:</p> <div><pre><code>psleak.MemoryLeakError: memory kept increasing after 10 runs Run # 1: heap=+388160 | uss=+356352 | rss=+327680 | (calls= 200, avg/call=+1940) Run # 2: heap=+584848 | uss=+614400 | rss=+491520 | (calls= 300, avg/call=+1949) Run # 3: heap=+778320 | uss=+782336 | rss=+819200 | (calls= 400, avg/call=+1945) Run # 4: heap=+970512 | uss=+1032192 | rss=+1146880 | (calls= 500, avg/call=+1941) Run # 5: heap=+1169024 | uss=+1171456 | rss=+1146880 | (calls= 600, avg/call=+1948) Run # 6: heap=+1357360 | uss=+1413120 | rss=+1310720 | (calls= 700, avg/call=+1939) Run # 7: heap=+1552336 | uss=+1634304 | rss=+1638400 | (calls= 800, avg/call=+1940) Run # 8: heap=+1752032 | uss=+1781760 | rss=+1802240 | (calls= 900, avg/call=+1946) Run # 9: heap=+1945056 | uss=+2031616 | rss=+2129920 | (calls=1000, avg/call=+1945) Run #10: heap=+2140624 | uss=+2179072 | rss=+2293760 | (calls=1100, avg/call=+1946) </code></pre></div> <p>Psleak is now part of the psutil test suite, to make sure that the C code does not leak memory. All psutil APIs are tested (see <a href=\"https://github.com/giampaolo/psutil/blob/1a946cfe738045cecf031222cd5078da21946af4/tests/test_memleaks.py\">test_memleaks.py</a>), making it a de facto <strong>regression-testing tool</strong>.</p> <p>It's worth noting that without inspecting heap metrics, missing calls such as <code>Py_CLEAR</code> and <code>Py_DECREF</code> often go unnoticed, because they don't affect RSS, VMS, and USS. Something I confirmed from experimenting by commenting them out. Monitoring the heap is therefore essential to reliably detect memory leaks in Python C extensions.</p> <h2>Under the hood</h2> <p>For those interested in seeing how I did this in terms of code:</p> <ul> <li><strong><a href=\"https://github.com/giampaolo/psutil/blob/d40164f1/psutil/arch/linux/heap.c\">Linux</a></strong>: uses glibc's <a href=\"https://man7.org/linux/man-pages/man3/mallinfo.3.html\">mallinfo2()</a> to report <code>uordblks</code> (heap allocations) and <code>hblkhd</code> (mmap-backed blocks).</li> <li><strong><a href=\"https://github.com/giampaolo/psutil/blob/d40164f1/psutil/arch/windows/heap.c\">Windows</a></strong>: enumerates heaps and aggregates <code>HeapAlloc</code> / <code>VirtualAlloc</code> usage.</li> <li><strong><a href=\"https://github.com/giampaolo/psutil/blob/d40164f1/psutil/arch/osx/heap.c\">macOS</a></strong>: uses malloc zone statistics.</li> <li><strong><a href=\"https://github.com/giampaolo/psutil/blob/d40164f1/psutil/arch/bsd/heap.c\">BSD</a></strong>: uses jemalloc's arena and stats interfaces.</li> </ul> <h2>Summary</h2> <p>psutil 7.2.0 fills a long-standing observability gap: native-level memory leaks in C extensions are now visible directly from Python. You now have a simple method to <strong>test C extensions for leaks</strong>. This turns psutil into not just a monitoring library, but a practical debugging tool for Python projects that rely on native C extension modules.</p> <p>To make leak detection practical, I created <a href=\"https://github.com/giampaolo/psleak\">psleak</a>, a test-regression framework designed to integrate into Python unit tests.</p> <h2>References</h2> <ul> <li><strong><a href=\"https://github.com/giampaolo/psleak\">psleak</a></strong>, the new memory leak testing framework.</li> <li><strong><a href=\"https://github.com/giampaolo/psutil/pull/2692/\">psutil PR #2692</a></strong>, the implementation.</li> <li><strong><a href=\"https://github.com/giampaolo/psutil/issues/1275\">psutil issue #1275</a></strong>, the original proposal from 8 years earlier.</li> </ul> <h2>Discussion</h2> <ul> <li><a href=\"https://www.reddit.com/r/Python/comments/1puqgfg/detect_memory_leaks_of_c_extensions_with_psutil/\">Reddit</a></li> <li><a href=\"https://news.ycombinator.com/item?id=46376608\">Hacker News</a></li> </ul> </div><!-- /.entry-content -->"},{"id":"https://exe.dev/","title":"Exe.dev","link":"https://exe.dev/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46397609","content":"<a href=\"https://news.ycombinator.com/item?id=46397609\">Comments</a>","date":1766792566000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://graydon2.dreamwidth.org/193447.html","title":"Always bet on text (2014)","link":"https://graydon2.dreamwidth.org/193447.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46397379","content":"<a href=\"https://news.ycombinator.com/item?id=46397379\">Comments</a>","date":1766790580000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div id=\"content\" role=\"main\"> <p> Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button! </p> </div></div>"},{"id":"https://t3x.org/nmhbasic/index.html","title":"NMH BASIC","link":"https://t3x.org/nmhbasic/index.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46401938","content":"<a href=\"https://news.ycombinator.com/item?id=46401938\">Comments</a>","date":1766844344000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"> <hr> <img src=\"https://t3x.org/nmhbasic/nmhbasic.png\" alt=\"NMH BASIC Logo\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> <h2>NMH BASIC</h2> <p>Download: <a href=\"https://t3x.org/nmhbasic/nmhbas23c.zip\">nmhbas23c.zip</a>&nbsp;(version&nbsp;1.2,&nbsp;74KB) &nbsp;|&nbsp; <a href=\"https://t3x.org/nmhbasic/nmhbas25c.zip\">nmhbas25c.zip</a>&nbsp;(version&nbsp;2.1,&nbsp;90KB) &nbsp;|&nbsp; <a href=\"https://t3x.org/nmhbasic/basic.0.html\">man page</a> </p> <p>This is a small BASIC interpreter that I wrote in the early 1990s. For some reason I think it is one of the coolest programs I have ever written. Maybe because it is just a bit under 5K bytes large and still does something useful. Maybe it is just nostalgia. </p> <ol> <li><a href=\"#prog\">Programs</a> </li><li><a href=\"#impl\">Implementation</a> </li><li><a href=\"#hack\">Hacks and Quirks</a> <a href=\"#arr\">Arrays</a> | <a href=\"#i/o\">Input/Output</a> | <a href=\"#cond\">Conditional Statements</a> | <a href=\"#list\">Listings</a> </li><li><a href=\"#v2\">NMH BASIC II</a> </li><li><a href=\"#v3\">NMH BASIC III</a> </li></ol> <h2>Programs</h2> <a href=\"https://t3x.org/nmhbasic/swep.png\"><img src=\"https://t3x.org/nmhbasic/swep-s.png\" alt=\"Minesweeper screenshot\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <p>One of the more interesting programs I have written in NMH&nbsp;BASIC is a variant of the well-known mine sweeper game that runs in text mode. Not just text mode, actually, but (tele)typewriter mode, as it reprints the playing field after every move. </p> <p>The screenshots use Viacheslav Slavinsky's excellent <a href=\"https://github.com/svofski/glasstty\">GlassTTY</a> font, a TrueType font that perfectly resembles the one used in the DEC VT-220 terminal. The same font, at bigger magnification, is used in the NMH&nbsp;BASIC logo. </p> <p>What is maybe interesting about the mine sweeper clone is that it uses a stackless floodfill algorithm that stores its state in the playing field itself and needs no dynamic memory at all. I have recently described it in the paper <a href=\"https://t3x.org/files/floodfill.pdf\">A Stackless Floodfill Automaton</a> (PDF, 34KB). A demo showing an animation of the algorithm is included in the NMH&nbsp;BASIC package. </p> <a href=\"https://t3x.org/nmhbasic/flood.png\"><img src=\"https://t3x.org/nmhbasic/flood-s.png\" alt=\"Floodfill demo screenshot\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> <p>There are other programs in the package, most of them rather simple, like an implementation of the Hangman game, the (rather pointless) Nim game, a banner printer, a random number generator, etc. NMH&nbsp;BASIC does not have a RNG, so a 15-bit linear feedback shift register is implemented in BASIC to generate pseudo-random numbers. </p> <p>The first program I have ever written in NMH&nbsp;BASIC was the inevitable prime number sieve. I have no idea how often I have loaded and run it in the past decades - until the Floodfill demo became my new favorite. Here is the code of my first NMH&nbsp;BASIC program (the backslash is the division remainder operator): </p> <pre>10 REM 'PRINT PRIME NUMBERS' 20 REM 'M = NUMBER OF PRIMES TO PRINT' 100 LET M = 1000 105 DIM Z(M) 110 LET Z(0) = 2 : LET T = 1 : LET P = 1 115 PRINT 2, 120 IF T &gt;= M GOTO 200 130 LET P = P+2 : LET O = 1 140 FOR I = 0 TO T-1 150 IF P\\Z(I) = 0 LET O = 0 : LET I = T 160 NEXT 170 IF O = 0 GOTO 120 180 LET Z(T) = P : LET T = T+1 185 PRINT P, 190 GOTO 120 200 END </pre> <h2>Implementation</h2> <p>I wrote the first version of NMH&nbsp;BASIC in 1994, recycling some parts that I had written in the years 1991..1993. The first version that I wrote in 1994 was a prototype in BASYL-II which I then translated, function by function, to 8086 assembly language. The resulting executable had a size of about 4700bytes and because the token representation that the interpreter uses internally is quite efficient, you could do interesting things with NMH&nbsp;BASIC in as little as 12Kbytes of memory. I had named the interpreter 12K-BASIC initially, but soon learned that others had had that idea before me. </p> <p>Of course in 1994 memory was already measured in megabytes, so you might say that writing a tiny BASIC interpreter was kind of pointless at that time. It depends I would say; it is better than getting drunk in a bar, and now, almost 30 years later, I still enjoy playing with this little program. So much, in fact, that I decided to translate the original code to <a href=\"https://t3x.org/t3x/0/index.html\">T3X/0</a>, so that I can play with it on Unix without having to use an emulator. </p> <p>All the above versions are included in the package: the original BASYL-II version, the assembly language version, and the new T3X version. You can recompile the T3X version with T3X/0 and the 8086 assembly language version with TASM or MASM. You need to create a COM file or it will not run. A precompiled COM file and Tcode machine executable (as well as a Tcode machine for Unix) are also included in the package. </p> <p>There is also a simplified version of the interpreter that runs under CP/M. A COM file for CP/M (BASICS.COM) is also included in the archive. The CP/M version currently needs 32K bytes of TPA to run. </p> <h2>Hacks and Quirks</h2> <h3>Arrays</h3> <p>The NMH&nbsp;BASIC language contains some interesting (IMHO) hacks to make its implementation simpler. </p> <p>All variables have either single-character names or names consisting of a character and a digit, like A0, B2, Z9, etc. The expressions A and A0 and A(0) all refer to the same variable. If you do not use A0..A9, you can use A as a 10-slot array A(0) .. A(9). Or you can use A5 in the place of A(5) if you are refering to a fixed slot. </p> <p>It is getting even weirder. A(10) is the same as B or B0 or B(0). A(22) is equal to C2 or C(2) and, finally, A(259) would be equal to Z(9). So, for instance, if you do not use any Z's, you can use Y as a 20-slot array. In this case the command <code>DIM&nbsp;Y(20)</code> is really a null-operation. It merely serves as a reminder that Y is a 20-slot array (and Z should not be used). </p> <p>You could also use Y as a 50-alot array by dimensioning it with <code>DIM&nbsp;Y(50)</code>. In this case the elements of Z will still be used, but 40 additional slots will be allocated to integer variable storage, so Z becomes a 40-slot array and Y a 50-slot array. It probably goes without saying that most programs either use single-character variables as 10-slot arrays or dimension Z, if a larger array is needed. </p> <p>This also means that <code>DIM&nbsp;Y(50)</code> and <code>DIM&nbsp;Z(50)</code> in the same program would just allocate 50 integer slots to Z and the last 40 slots of Y would overlap with the slots of Z. Having multiple large arrays in the same NMH&nbsp;BASIC program requires some hacking, like using Z(0)..Z(99) for one array and Z(100)..Z(199) for the other. </p> <p>Note the definition of \"large\" above. NMH&nbsp;BASIC uses 12Kbytes of memory in total: for integer variables, string variables, program memory, stacks, and the machine code of the interpreter itself! You could probably write a version of this interpreter that would run on a CP/M machine with as little as 16K bytes of transient program area (but I have never done so). </p> <h3>Input/Output</h3> <p>The interpreter performs I/O on \"units\", where each unit is assigned a file or device when the interpreter is started. NMH&nbsp;BASIC programs cannot open or close any files. They can only redirect input and output to the assigned units. I/O is sequential, i.e. each unit is like a tape drive. The following program prints the data stored on unit #5: </p> <pre>100 LET X = IOCTL(5, 100) : INPUT #5 110 INPUT A$ : IF ASC(A$) = 255 INPUT #0 : END 120 PRINT A$ : GOTO 110 </pre> <p>The statement <code>INPUT&nbsp;#5</code> redirects input to unit #5, so from that point on all INPUT statements will read from that unit. (Analogously, <code>PRINT&nbsp;#5</code> would redirect output to unit #5.) When a string read from a unit contains the value 255 in its first slot, there is no more input available from the current input unit. <code>INPUT&nbsp;#0</code> connects input back to the keyboard. Note that <code>PRINT&nbsp;#1</code> would connect output back to the screen. </p> <p>There is an IOCTL function that can perform several \"services\" on a unit, like rewinding it, appending to it (moving the read/write pointer to the end of the unit), or truncating it (or writing an EOF marker on a tape). The IOCTL call in the above example rewinds the unit. </p> <p>The maximum length of a line or string is 64 bytes. Reading anything longer, either via INPUT or by entering it at the interpreter prompt, will result in an error. The CR,LF characters that separate lines are not counted. </p> <h3>Conditional Statements</h3> <p>I have forgotten how other BASIC dialects handle this, but I suspect that NMH&nbsp;BASIC is the odd one out here: in an IF statement the entire rest of the line is executed conditionally. For example </p> <pre>IF 1 = 1 PRINT 'FOO' : PRINT 'BAR' </pre> <p>would print both FOO and BAR. There is no THEN or ELSE keyword. The first keyword after the condition of IF starts the conditional part of the IF statement. When the condition in IF is false, the interpreter advances to the next line. An alternative branch is implemented with jump around jumps using GOTO: </p> <pre>100 IF condition GOTO 130 110 alternative statements 120 GOTO 140 130 consequent statements 140 REM </pre> <p>Or, if the condition and statements are short: </p> <pre>100 IF condition statements 110 IF # condition statements </pre> <p>The # operator implements the logical NOT. It had high precedence in NMH BASIC up to version 1.2, but has very low precedence in NMH&nbsp;BASIC&nbsp;II. Interestingly, this change did not affect any programs in the archive. There is a logical AND, but not a logical OR in IF. If there are multiple conditions separated by commas then the conditional statements will only execute, if all conditions are true. For example, the statement </p> <pre>IF 0 &lt; C, C &lt; 11 STOP </pre> <p>will stop program execution, if C is in the range 1..10. To implement a logical OR, multiple IF statemements with the same conditional part (or jumps around jumps) have to be used. </p> <h3>Listings</h3> <p>NMH&nbsp;BASIC 1.x listed programs with blanks between <em>all</em> adjacent tokens. NMH&nbsp;BASIC&nbsp;II uses a more compact representation. Either way is merely a characteristic of the LIST routine, though. You can enter a program as </p> <pre>FOR I=1TO10:PRINT A(I):NEXT </pre> <p>but the LIST command will print it as </p> <pre>FOR I = 1 TO 10 : PRINT A ( I ) : NEXT </pre> <p>in NMH BASIC and as </p> <pre>FOR I = 1 TO 10 : PRINT A(I) : NEXT </pre> <p>in NMH&nbsp;BASIC&nbsp;II. </p> <p>This has the weird side effect that sometimes you can SAVE a program but cannot LOAD it later, because some lines will be shorter than 64 characters when you enter them, but LIST (and hence SAVE) will blow them up to a bigger size. </p> <p>This is mostly a problem in NMH BASIC 1.x, which inserts blanks between all tokens. For example: </p> <pre>100 IF ASC(MID$(A$, I, 1)) = ASC('X') LET X = X+1 : GOTO 120 ----+----1----+----2----+----3----+----4----+----5----+----6---| 100 IF ASC( MID$( A$ , I , 1 ) ) = ASC( 'X' ) LET X = X + 1 : GOTO 120 </pre> <p>There is no workaround. When a program cannot be loaded, the only remedy is to edit it with a text editor and fix it, either by removing unnecessary blanks or, even better, by splitting the offending line. E.g.: </p> <pre>100 LET C = ASC( MID$( A$ , I , 1 ) ) 105 IF C = ASC( 'X' ) LET X = X + 1 : GOTO 120 </pre> <p>Finally, it is a good idea to keep NMH&nbsp;BASIC programs in DOS text format with CR/LF line separators, even on Unix systems, because otherwise the DOS version of the interpreter will refuse to load them. </p> <h2>NMH BASIC II</h2> <p>In December 2024 I changed a few things and pubished a new version of NMH BASIC, which I called, for lack of imagination, NMH BASIC&nbsp;II. The new version changes the precedence of the # (logical NOT) operator from highest to lowest (this was a mistake in the original version!) and uses a more compact and more comprehensible LIST format, which is also used for saving programs. Because some code was simplified in the interpreter at the same time, the new version is one byte smaller than the original version. </p> <h2>NMH BASIC III</h2> <p>Download: <a href=\"https://t3x.org/nmhbasic/nmhbas3_30.zip\">nmhbas3_30.zip</a>&nbsp;(version&nbsp;3.0,&nbsp;105KB) &nbsp;|&nbsp; <a href=\"https://t3x.org/nmhbasic/basic3.0.html\">man page</a> </p> <p>Version 3.x of NMH&nbsp;BASIC is an in-progress version that differs from the previous versions in a few points that are described in detail in the <a href=\"https://t3x.org/nmhbasic/basic3.0.html#diffs\">manual</a>. Most prominently, the CMPS (\"compare strings\") function has been replaced with string comparison operators, so, for example, </p> <pre>IF CMPS(A$, 'FOO') = 0 PRINT 'YEP' </pre> <p>would now be written as </p> <pre>IF A$ = 'FOO' PRINT 'YEP' </pre> <p>Then, NMH&nbsp;BASIC&nbsp;III supports <em>baudot-encoded units</em>. This means that any unit connected to the interpreter can be written to and read from using five-channel baudot-encoding (CCITT-2, US-TTY). So the interpreter can, in theory, save and load programs to/from five-hole paper tape. </p> <p>The T3X/0 version of the interpreter is currently fully working. There also is a more efficient Z80 version written in assembly language, which is work in slow progress. It currently runs all the example programs, but lacks baudot-encoded units and may still have a few bugs. An 8086 version written in assembly language may appear later. </p> <hr> </div>"},{"id":"https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/","title":"QNX Self-Hosted Developer Desktop","link":"https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46398201","content":"<a href=\"https://news.ycombinator.com/item?id=46398201\">Comments</a>","date":1766798213000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<section> <p>The team and I are beyond excited to share what we've been cooking up over the last little while: <strong>a full desktop environment running on QNX 8.0, with support for self-hosted compilation</strong>! This environment both makes it easier for newly-minted QNX developers to get started with building for QNX, but it also vastly simplifies the process of porting Linux applications and libraries to QNX 8.0.</p><p>This self-hosted target environment is pre-loaded with many of the ports you'll find on <a href=\"https://oss.qnx.com/?ref=devblog.qnx.com\" rel=\"noreferrer\">the QNX Open-source Dashboard</a>. (The portal currently includes over 1,400 ports across various targets, QNX versions, and architectures, of which more than 600 are unique ports!)</p><p>In this initial release, you can grab a copy of the QEMU image and give it a try for yourself. There's still so much more to add, but it's in a great place today for this first release. The team is really passionate about this one, and we're eagerly looking forward to your feedback!</p><h2 id=\"whats-included\">What's Included</h2><p>For the initial release of Desktop, we tried to cover all the basics: windowing, terminal, IDEs, browser, file management, and samples. To that end, here's what makes up the QNX Developer Desktop:</p><ul><li>A customizable XFCE desktop environment running on Wayland</li><li>The tools you need to compile and/or run your code (<code>clang</code>, gcc, <code>clang++</code>, Python, <code>make</code>, <code>cmake</code>, <code>git</code>, etc)</li><li>A web browser (can you join <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">the QNX Discord</a> from the QNX Desktop? 🏅👀)</li><li>Ports of popular IDEs/editors, like Geany, Emacs, Neovim, and vim</li><li>Thunar, for file management</li><li>Preloaded samples, like Hello World in C, C++, and Python, and GTK demos OpenGL ES demos</li><li>... and of course, a terminal.</li></ul><h2 id=\"system-requirements\">System Requirements</h2><p>This environment runs as a virtual machine, using QEMU on Ubuntu. To try the image, you'll need:</p><ul><li>Ubuntu 22.04 or 24.04</li></ul><h2 id=\"try-it-yourself\">Try It Yourself</h2><p>(Keep in mind this is the first release, so it takes a minute to get started and it's a bit rough around the edges.)</p><p>With <a href=\"https://qnx.com/getqnx?ref=devblog.qnx.com\" rel=\"noreferrer\">a free QNX license</a>, you can find this release in QNX Software Center. On the <strong>Available</strong> tab of the <strong>Manage Installation</strong> pane, search for \"quick start\" and install the \"QNX SDP 8.0 Quick Start Target Image for QEMU\".</p><p>You'll find the image in your QNX installation directory, usually <code>~/qnx800/images</code> by default. Follow the <code>README.md</code> file in the <code>qemu</code> directory to extract &amp; combine the multiple QNX packages downloaded under the hood.</p><p>Next, follow the PDF instructions found in the new <code>./qemu_qsti/docs/</code> directory to install the required dependencies and boot up.</p><div><p>💡</p><p>If you experience any trouble starting the environment, check the PDF's <b><strong>Troubleshooting</strong></b> chapter, or come <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">ask us on Discord</a>.</p></div><h2 id=\"whats-next\">What's Next</h2><p>This is just the very first release! Over the next few months and beyond, we'll drop more updates of Desktop. You can look forward to:</p><ul><li>QEMU images for Windows &amp; macOS, and native images for x86</li><li>A native Desktop image on Raspberry Pi</li><li>Enhanced documentation</li><li>Features to help use this self-hosted environment in CI jobs</li><li>More samples &amp; stability</li><li>... and more! Have suggestions? Let us know.</li></ul><p>Lastly, if you want some help with your QNX journey, you can find the QNX team and community:</p><ul><li>in Discord here: <a href=\"https://discord.gg/Jj4EkkrFTT?ref=devblog.qnx.com\" rel=\"noreferrer\">discord.gg/Jj4EkkrFTT</a></li><li>on Reddit at: <a href=\"https://reddit.com/r/qnx?ref=devblog.qnx.com\" rel=\"noreferrer\">reddit.com/r/qnx</a></li></ul> </section>"},{"id":"https://github.com/Syn-Nine/gar-lang/blob/main/DEVLOG.md","title":"Langjam-Gamejam Devlog: Making a language, compiler, VM and 5 games in 52 hours","link":"https://github.com/Syn-Nine/gar-lang/blob/main/DEVLOG.md","hnCommentsUrl":"https://news.ycombinator.com/item?id=46348251","content":"<a href=\"https://news.ycombinator.com/item?id=46348251\">Comments</a>","date":1766349875000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false},{"id":"https://carette.xyz/posts/deep_dive_into_crossover/","title":"An exploration of playing three generations of windows games on macOS","link":"https://carette.xyz/posts/deep_dive_into_crossover/","hnCommentsUrl":"https://news.ycombinator.com/item?id=46336604","content":"<a href=\"https://news.ycombinator.com/item?id=46336604\">Comments</a>","date":1766242404000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div> <p>If you read my previous post about <a href=\"https://carette.xyz/posts/crossover_mac_retro_games\">gaming on mac</a>, you know I have a soft spot for running Windows games on Apple Silicon.</p> <p>Early this year I upgraded from a M1 MacBook Air to an M3 Max MacBook Pro. Naturally, I had to test three completely different generations of games at it: <a href=\"https://en.wikipedia.org/wiki/ARC_Raiders\"><em>ARC Raiders</em></a> (2025), <a href=\"https://en.wikipedia.org/wiki/Routine_(video_game)\"><em>Routine</em></a> (2025), <a href=\"https://en.wikipedia.org/wiki/Watch_Dogs_2\"><em>Watch Dogs 2</em></a> (2016) and <a href=\"https://en.wikipedia.org/wiki/Tron_2.0\"><em>Tron 2.0</em></a> (2003).</p> <p>I expected the modern game to struggle and the old game to fly. The reality was exactly the opposite, and it forced me to dig deep into how <a href=\"https://www.codeweavers.com/crossover\">CrossOver</a> handles translation layers under the hood.</p> <p>This article summarizes my investigations and challenges to play DirectX 12, Direct 11, and DirectX 9 games, using Crossover.</p> <h3 id=\"there-is-no-place-for-anti-cheats\"> There is no place for anti-cheats <a href=\"#there-is-no-place-for-anti-cheats\">#</a> </h3> <p>Let’s start with the bad news: no, you still can’t play everything. Despite the M3 Max being a hardware beast, there is a hard software wall called Kernel-level Anti-Cheat.<br> I am not going to get into the debate of if it is useful or not, but if you are interested in that debate you can feed <a href=\"https://steamcommunity.com/app/2807960/discussions/0/664963107066558385/\">this Steam forum discussion</a>.<br> Games like <em>ARC Raiders</em> are strictly unplayable because Wine cannot emulate the deep Windows kernel access that Easy Anti-Cheat (EAC) or BattlEye require. If your target game relies on invasive anti-cheat then the Crossover solution is not the good one, as there is no “userspace bridge” built by Apple and / or Crossover to support those software.<br> For that kind of games you might be interested in installing a Windows VM and then install Steam and your game(s) on that system, but this is not the purpose of this blog post.</p> <p>However, for the vast majority of single-player titles that don’t treat the OS like a crime scene, the landscape has changed dramatically.</p> <p><em>ARC Raiders</em> : <strong>Fail</strong>.</p> <h3 id=\"the-routine\"> The routine <a href=\"#the-routine\">#</a> </h3> <p>First, I tried the most recent game, <em>Routine</em>. <em>Routine</em> is made using Unreal Engine and uses the DirectX 12 graphics API under the hood.<br> I tried this game on a default “Steam” bottle on Crossover, with “Auto” settings, and… it launched successfully! No graphics or performance issue, no issue recovering my saves through Steam cloud, and I successfully continued the game I began on my other machine.</p> <p>Great!</p> <p><em>Routine</em> : <strong>Great success</strong>.</p> <h3 id=\"the-hackerspace\"> The hackerspace <a href=\"#the-hackerspace\">#</a> </h3> <p>Next, I tried <em>Watch Dogs 2</em>. This game is almost 10 years old, and runs on DirectX 11.<br> As <em>Routine</em> I tried with the auto settings, but the game did run poorly, and glitchees appeared too regularly.<br> It was time to tweak the machine!</p> <p>On modern versions of CrossOver (23+), we have a new toy: <strong>D3DMetal</strong>. This is essentially <a href=\"https://developer.apple.com/games/game-porting-toolkit/\">Apple’s Game Porting Toolkit (GPTK)</a> integrated directly into CrossOver.<br> Using GPTK, instead of the traditional translation path: <code>DirectX</code> -&gt; <code>Vulkan</code> (via DXVK) -&gt; <code>Metal</code> (via MoltenVK), D3DMetal translates DirectX headers <em><strong>directly</strong></em> to Metal.<br> GPTK is a great tech, and enable some modern games to run on macOS. If you want to know more for a list of compatible games I invite you to look for <a href=\"https://macgametoolkit.com/\">this website</a>.</p> <p>Going back to Crossover, I enabled the D3DMetal flag it in the bottle settings, along with MSync and the performances were <strong>much</strong> better, despite regular stutters I investigated and actually solved (more in the next section).</p> <p><em><strong>Note:</strong></em><br> For those who missed the memo, MSync replaces the old ESync/FSync methods. Instead of using <code>eventfd</code> (which is a Linux kernel feature that macOS lacks and must emulate), MSync maps Wine synchronization primitives directly to macOS native <code>kqueue</code> or Mach semaphores. The result is a <strong>much</strong> lower CPU overhead.</p> <h3 id=\"the-retina-problem\"> The Retina Problem <a href=\"#the-retina-problem\">#</a> </h3> <p>However, performance was initially terrible. Why? Because macOS tells the game: “Hey, I have a 3024x1964 screen!” and the game engine says “OK!” and tries to render a poorly optimized open-world at 4K.</p> <p>The fix was simple:</p> <ol> <li>turn <strong>OFF</strong> “High Resolution Mode” in the bottle settings.</li> <li>force the game to 1920x1080.</li> <li>enable <strong>Temporal Filtering</strong> in the game engine (which essentially renders at lower res and upscales).</li> </ol> <p>Suddenly, the M3 Max was pushing stable frames. Unfortunately this “modern” approach completely breaks when you look backward.</p> <p><em>Watch Dogs 2</em> : <strong>Success</strong>.</p> <p>I then tried to run <em>Tron 2.0</em>, a monolith classic from 2003 running on the LithTech engine (DirectX 9).</p> <p>I naively kept D3DMetal on. The result? An instant crash.</p> <p>Here is the technical reason: <strong>D3DMetal does not support DirectX 9</strong>. It currently only handles DX11 and DX12 instructions. For older games, you <em>must</em> fallback to the translation chain: <code>DirectX 9</code> -&gt; <code>DXVK</code> -&gt; <code>MoltenVK</code> -&gt; <code>Metal</code>.</p> <p>So, I created a separate bottle (and this is crucial: <strong>never mix eras</strong>).<br> I set this bottle to Windows XP mode to avoid modern OS overhead, and enabled DXVK.</p> <h3 id=\"the-case-of-the-missing-dll\"> The case of the missing DLL <a href=\"#the-case-of-the-missing-dll\">#</a> </h3> <p>Even with the correct graphics layer, the game wouldn’t start. This is where it gets interesting for C++ developers.</p> <p>The crash wasn’t graphical. It was a missing dependency: <code>msvcirt.dll</code>.</p> <p>This library is the <em>old</em> C++ runtime (MSVC 6.0 era). Modern Windows (and by extension, modern Wine bottles) have largely deprecated or removed it. The game was calling functions in a dynamic library that simply didn’t exist in the virtual <code>system32</code> folder.</p> <p>To fix this, I had to:</p> <ol> <li>manually create a <code>Windows XP</code> bottle (which is more likely to handle legacy calls).</li> <li>use the “Install Software” tool to inject <code>DirectX for Modern Games</code> (which oddly enough, contains legacy DX9 redistributables).</li> <li>manually patch the executable with the community-made “Killer App Mod” to strip the DRM that Wine couldn’t parse.</li> </ol> <p><em>Tron 2.0</em> : <strong>Partial success</strong>.</p> <h2 id=\"the-proton-reality-check\"> The Proton Reality Check <a href=\"#the-proton-reality-check\">#</a> </h2> <p>On the four games I wanted to test only <strong>one</strong> launched with great perfor,ances “out of the box“. Two have been tweaked to run great, and only one did not run at all (due to anti-cheats software compatibility).</p> <p>We often think of “emulation” (or translation, in Wine’s case) as a linear performance cost. But on Apple Silicon, it’s really about choosing the right translation path:</p> <ul> <li><strong>“retro” Games</strong> (&lt;= 2012): use <code>DXVK</code> as it handles the fixed-function pipeline of older DirectX versions way better than Apple’s toolkit does,</li> <li><strong>“modern” Games</strong> (&gt; 2012): use <code>D3DMetal</code> and <code>MSync</code> provides the best combo here as it skips the Vulkan translation overhead.</li> </ul> <p>However, we have to address the elephant in the room: <strong>Proton on Linux</strong>.</p> <p>If you own a Steam Deck or run Linux on your desktop, you know that the experience is lightyears ahead of what we have on macOS. Why? Because Proton (Valve’s fork of Wine) is solving a much simpler equation.</p> <p>On Linux (x86_64), the CPU instructions are native. Proton only needs to translate Windows API calls to Linux Kernel calls, and DirectX to Vulkan. It’s a 1:1 translation.</p> <p>On macOS (Apple Silicon), the translations are more expensive:</p> <ol> <li>Rosetta 2 translates x86_64 instructions to ARM64 (CPU overhead),</li> <li>CrossOver translates Windows API to macOS API (OS overhead),</li> <li>D3DMetal translates DirectX to Metal (GPU overhead).</li> </ol> <p>This triple-layer cake is technical wizardry, but it explains why my $400 Steam Deck can sometimes launch a game with fewer glitches (and slightly better performance) than an Apple Silicon MacBook Pro. Proton simply has less distance to cover, and Vulkan is a first-class citizen on Linux.</p> <p>I actually tried to run the same four games on another machine using CachyOS with Proton and… <strong>all four games launched without any tweak</strong>. That is a <strong>major success</strong> for the Linux community.</p> <p>Maybe MacBooks will come to launch and run natively Windows games (<strong>if</strong> Apple wants to).</p> </div></div>"},{"id":"https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html","title":"The best things and stuff of 2025","link":"https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html","hnCommentsUrl":"https://news.ycombinator.com/item?id=46365726","content":"<a href=\"https://news.ycombinator.com/item?id=46365726\">Comments</a>","date":1766501493000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"> <p>Great things and people that I discovered, learned, read, met, etc. in 2025. No particular ordering is implied. Not everything is new.</p> <p><em>also: see the lists from <a href=\"https://blog.fogus.me/2024/12/23/the-best-things-and-stuff-of-2024.html\">2024</a>, <a href=\"https://blog.fogus.me/2023/12/18/the-best-things-and-stuff-of-2023/\">2023</a>, <a href=\"http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/\">2022</a>, <a href=\"https://blog.fogus.me/2021/12/27/the-best-things-and-stuff-of-2021/\">2021</a>, <a href=\"http://blog.fogus.me/2020/12/31/the-best-things-and-stuff-of-2020/\">2020</a>, <a href=\"http://blog.fogus.me/2019/12/30/the-best-things-and-stuff-of-2019/\">2019</a>, <a href=\"http://blog.fogus.me/2019/01/02/the-best-things-and-stuff-of-2018/\">2018</a>, <a href=\"http://blog.fogus.me/2018/01/02/the-best-things-and-stuff-of-2017/\">2017</a>, <a href=\"http://blog.fogus.me/2016/12/29/the-best-things-and-stuff-of-2016/\">2016</a>, <a href=\"http://blog.fogus.me/2015/12/29/the-best-things-and-stuff-of-2015/\">2015</a>, <a href=\"http://blog.fogus.me/2014/12/29/the-best-things-and-stuff-of-2014/\">2014</a>, <a href=\"http://blog.fogus.me/2013/12/27/the-best-things-and-stuff-of-2013/\">2013</a>, <a href=\"http://blog.fogus.me/2012/12/26/the-best-things-and-stuff-of-2012/\">2012</a>, <a href=\"http://blog.fogus.me/2011/12/31/the-best-things-and-stuff-of-2011/\">2011</a> and <a href=\"http://blog.fogus.me/2010/12/30/the-best-things-in-2010/\">2010</a></em></p> <h2 id=\"great-posts-articles-vids-readwatched\">Great posts | articles | vids read/watched</h2> <ul> <li><em><a href=\"https://chadnauseam.com/coding/random/calculator-app\">A calculator app? Anyone could make that</a></em> by Chad Nauseam, esquire - <em>I love the story about how Hans Boehm and friends developed a mind-blowing approach called recursive real arithmetic for numbers like pi and (sqrt 2). The post details various symptom -&gt; problem definition -&gt; alternative solutions -&gt; solution cycles that the team met along the way and should be required reading for programmers.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=JVyz17kwIv4\">Lost in Manboo</a></em> - <em>マンガ喫茶マンボ (manga cafe manboo) shows life for some folks who live in 24-hour game cafes in Japan. The video is dystopic in a way that matches our modern world perfectly.</em><a href=\"#fn1\" id=\"fnref1\" role=\"doc-noteref\"><sup>1</sup></a></li> <li><em><a href=\"https://www.youtube.com/watch?v=0z7_A_8il_g\">The Making of Deeper in You on the OP-1</a></em> - <em>Shows an artist’s approach to song creation/composition using the OP-1 synthesizer. This is hypnotic to watch for someone with zero musical talent like myself.</em></li> <li><em><a href=\"https://thecreativeindependent.com/people/multi-disciplinary-artist-jack-rusher-on-the-need-to-sustain-your-creative-drive-in-the-face-of-technological-change/\">An interview with Jack Rusher</a></em> by The Creative Independent - <em>A lovely interview with online friend Jack Rusher discussing the thoughtful application of tech in art, flow, and the state of research in the modern computing industry.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=MWteJW-wYas\">Uncredited: Searching for Lost Board Game Designers</a></em> by Amabel Holland - <em>Amabel describes her trials and tribulations while trying to find the designers of the long-forgotten board game <a href=\"https://boardgamegeek.com/boardgame/4791/duplicate-ad-lib-crossword-cubes\">Duplicate Ad-Lib Crossword Cubes</a>.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=TldMsMtHvW8\">Brian Weissman on his Magic the Gathering history</a></em> - <em>For anyone who came of age during the earliest years of Magic, the name Brian Weissman is legendary. In this interview he gives countless anecdotes about his experiences in those early days.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/08/before-arcturus-david-lindsays-lost.html\">Before Arcturus: David Lindsay’s Lost Novels</a></em> by Mark Valentine - <em>Mark’s research into David Lindsay revealed evidence that he submitted at least two earlier novels, Aletheus and The Confessions of an Egoist, to the publisher Chatto &amp; Windus in 1902 and 1908. These submissions predated his first published masterpiece, <a href=\"https://bookshop.org/p/books/a-voyage-to-arcturus-an-illuminated-edition-david-lindsay/76f8dc45a1376ddf?aid=98208&amp;ean=9781948886307&amp;listref=best-things-2025&amp;next=t\">A Voyage to Arcturus</a>.</em></li> <li><em><a href=\"https://what-dan-read.com/\">What Dan Read</a></em> by Dan - <em>An amazing account of a lifetime of reading.</em></li> <li><em><a href=\"https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/\">Two Years After Cormac McCarthy’s Death, Rare Access to His Personal Library Reveals the Man Behind the Myth</a></em> by Richard Grant - <em>A glimpse into Cormac McCarthy’s massive, chaotically organized personal library reveals the reclusive author as a polymath with an insatiable curiosity. Scholars are currently cataloging the estimated 20,000 volumes, many of which contain the author’s annotations.</em></li> </ul> <h2 id=\"most-viewed-postsvideos-withby-me\">Most viewed posts/videos with/by me</h2> <p>While I’ve posted a few technical post on my personal blog, I’ve taken a lot of time to guest-post on the <a href=\"https://wormwoodiana.blogspot.com/search/label/Fogus\">Wormwoodania blog</a> about weird, macabre, and sardonic fiction and other related, non-technical topics. I hope to continue this trend into next year. Also, my most assiduous readers will have noticed that I’ve written more about games. I’ve decided to keep those posts on this blog since my intent for the site has always been about systems and systems-thinking and games are a great way to study and model systems.</p> <ul> <li><em><a href=\"https://blog.fogus.me/langdev/long-season.html\">The long season of langdev</a></em> - <em>Whereby I speculate if programming language development is in a lull.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/08/on-baron-corvo-greatest-asshole-who.html\">On ‘Baron Corvo: The Greatest Asshole Who Ever Lived’</a></em> - <em>My review of Johan Kugelberg’s pamphlet on why Baron Corvo still intrigues people.</em><a href=\"#fn2\" id=\"fnref2\" role=\"doc-noteref\"><sup>2</sup></a></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/09/derek-raymond-and-black-novel-guest.html\">Derek Raymond and ‘The Black Novel’</a></em> - <em>Discusses the author Derek Raymond’s criteria for what he calls ‘black novels’.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/06/corvos-icicle-guest-post-by-fogus.html\">Corvo’s Icicle</a></em> - <em>Did Baron Corvo invent the mystery trope of the melting weapon?</em></li> <li><em><a href=\"https://blog.fogus.me/clojure/arities-as-proto.html\">Arities as Pseudo-Protocol</a></em> - <em>Whereby I describe a little-used Clojure technique leveraging function arities as a lightweight interface/protocol.</em></li> <li><em><a href=\"https://www.youtube.com/watch?v=_g69GKN6lAM\">My appearance on the Apropos Podcast</a></em> - <em>Sat down with the Apropos crew and had a great time talking Clojure.</em></li> <li><em><a href=\"https://wormwoodiana.blogspot.com/2025/03/meeting-corvo-and-weeks-in-georgetown.html\">Meeting Corvo and Weeks in Georgetown</a></em> - <em>A brief description of some of my hobby research.</em></li> <li><em><a href=\"https://blog.fogus.me/games/18XX/intro.html\">18XX: A System of Systems</a></em> - <em>A description of 18XX board games as a system of systems.</em></li> <li><em><a href=\"https://blog.fogus.me/games/bird-poker.html\">The Bird-Poker Deck</a></em> - <em>A truncated pack of playing cards that displays some interesting game-play characteristics.</em></li> <li><em><a href=\"https://blog.fogus.me/games/checkers-arcade.html\">Checkers Arcade</a></em> - <em>Using an American Checkers set to play many deep games of abstract strategy.</em></li> </ul> <h2 id=\"favorite-technical-books-discovered-and-read\">Favorite technical books discovered (and read)</h2> <ul> <li><strong><a href=\"http://mouse.davidgsimpson.com/\">Mouse, a Language for Microcomputers</a></strong> by Peter Grogono - <em>Mouse is basically an esolang with barely any abstraction facilities, but the book was well-written and the language compelling enough to explore further.</em></li> <li><strong><a href=\"https://explodingthephone.com/hoppdocs/nodd1956.pdf\">Notes on Distance Dialing</a></strong> (pdf) by AT&amp;T - <em>Described the telephone systems of the USA and Canada in the mid-1950s. The reading is a dry as it gets, but it was a fascinating dive into a vastly complex system solving extremely hard problems. This is a must-read for folks interested in systems-thinking. That said, I am actively looking for recommendations for books about the process of designing and building the unbelievably complex telephony system over the rudiments of the earlier systems. Recommendations welcomed!</em></li> </ul> <h2 id=\"favorite-non-technical-books-read\">Favorite non-technical books read</h2> <p>The vast majority of my reading this year was fiction, and I discovered some real gems.<a href=\"#fn3\" id=\"fnref3\" role=\"doc-noteref\"><sup>3</sup></a></p> <ul> <li><strong><a href=\"https://www.gutenberg.org/ebooks/24201\">The Eye of Osiris</a></strong> by R. Austin Freeman - <em>This is the first book that I’ve read from Freeman and I suspect that I will read many more in the future. The story follows the disappearance of John Bellingham, Egyptologist and the subsequent investigation. As the investigation stalls, the eminent Dr.&nbsp;Thorndyke digs into the case. The story sets up the mystery nicely and indeed provides enough information to the reader to infer how the disappearance occurred and who or what facilitated it. The book is one of the best whodunits that I’ve ever read.</em></li> <li><strong><a href=\"https://www.gutenberg.org/ebooks/564\">The Mystery of Edwin Drood</a></strong> by Charles Dickens - <em>His final work remains unfinished as he passed away before he could complete it. Further complicating the meta-story is that he also didn’t outline the ending nor even put to paper the “villain” of the story. The meta-mystery of the ending has motivated a mountain of speculation around the ending including dozens of continuations of the story from other authors, all deriving their pet endings from textual hints, accounts from Dickens’ friends, illustration notes, and even in some cases seances supposedly accompanied by the spirit of Dickens himself. What was written by Dickens is spectacular and a compelling mystery and although it would be great to know the resolution, in some ways the “Droodiana” that has cropped up over the past 150+ years is reason enough for it to remain a mystery. The whole lore around Edwin Drood is a worthwhile hobby in itself and well-worth exploring. The <a href=\"https://www.amazon.com/dp/B0000CHQCS/?tag=fogus-20\">Chiltern Library edition</a> of the book contains the story and a good bit of the lore around the writing and the meta-works available at the time of its publication.<a href=\"#fn4\" id=\"fnref4\" role=\"doc-noteref\"><sup>4</sup></a></em></li> <li><strong><a href=\"https://www.amazon.com/shadow-people-Margaret-St-Clair/dp/B00005XVNT/?tag=fogus-20\">The Shadow People</a></strong> by Margaret St.&nbsp;Clair - <em>Sadly out of print and difficult to find, but I’ve had it on my shelves for decades and finally got around to reading it. The book came onto my radar in the 1980s when I learned about it in the <a href=\"https://en.wikipedia.org/wiki/Appendix_N\">appendix-n</a> of the 1st edition Advanced D&amp;D Dungeon Masters Guide. I enjoyed many of the books at the time and have slowly swung around to re-reading them over the past few years. Sadly, most on the list do not stand the test of time for me, but St.&nbsp;Clair’s mixture of 60s counter-cultural leanings in a fantasy/sf world still works. The cultural touch-points in the book feel quite dated, but despite the occasional awkwardness, the story is unique even today.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/lolly-willowes-warbler-classics-annotated-edition-sylvia-townsend-warner/793f95da3bb968a0?aid=98208&amp;ean=9781959891635&amp;listref=best-things-2025&amp;next=t\">Lolly Willowes</a></strong> by Sylvia Townsend Warner - <em>The book started as a passable novel of manners focused on a turn of the century British middle-class family. The titular character was mostly background decoration for the first third of the novel and AFAIR was talked about only in the third-person. It’s only when she made the choice to move out on her own to the country<a href=\"#fn5\" id=\"fnref5\" role=\"doc-noteref\"><sup>5</sup></a> in her middle age does she gain a central role in the narrative and her inner thoughts revealed. This is where things really pick up because I was shocked to learn that this unassuming woman’s inner thoughts had a delicious darkness to them. I don’t want to give away too much, but I’ll just say that you will not expect how the story ends.</em></li> <li><strong><a href=\"https://www.fantagraphics.com/collections/daniel-clowes/products/patience\">Patience</a></strong> by Daniel Clowes - <em>A profound graphic novel using time-travel to explore the idea of enduring love with a story that proceed through time, following Jack as he tries to alter the past and save the woman he loves. This well-known science fiction motif is elevated by Clowes’ signature psychological complexity.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/narcissus-and-goldmund-hermann-hesse/2249287049aa22fb?aid=98208&amp;ean=9780553275865&amp;listref=best-things-2025&amp;next=t\">Narcissus and Goldmund</a></strong> by Herman Hesse - <em>I’ve read most of the books by Hermann Hesse but this one escaped my attention until this year. The story follows the parallel lives of a monk Narcissus and his passionate friend Goldmund as they respectively search for meaning in life through spiritual means and through pleasures of the flesh.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/we-who-are-about-to-joanna-russ/a7176b6dc2109f04?aid=98208&amp;ean=9780819567598&amp;listref=best-things-2025&amp;next=t\">We Who Are About To…</a></strong> by Joanna Russ - <em>A small group of astronauts crash land on a hostile alien world and quickly realize that rescue is unlikely to come. Many SF stories have started this way and so the expectation is that this is a colonization story… but Russ thrives on subverting reader expectations.</em></li> <li><strong><a href=\"https://tartaruspress.com/russell-fifty-forgotten-records.html\">Fifty Forgotten Records</a></strong> by R.B. Russell - <em>Another lovely entry in Russell’s series (one can hope) of autobiographical explorations of art, so far covering literature and now music. This book describes 50 records of varying popularity and Russell’s personal connections to each. While I certainly enjoyed finding a dozen or so new albums to explore, the true triumph of the book lies in the vulnerable, reflective memoir threaded throughout.</em></li> <li><strong><a href=\"https://bookshop.org/p/books/the-way-of-all-flesh-samuel-butler/b5c2be53f34c9706?aid=98208&amp;ean=9780375752490&amp;listref=best-things-2025&amp;next=t\">The Way of All Flesh</a></strong> by Samuel Butler *A novel that follows 4-generations of the Ponitifex family, with a particular bildungsromanesque thread around Ernest, a young man who’s naivete leads to his downfall and how his life unfolds thereafter.<a href=\"#fn6\" id=\"fnref6\" role=\"doc-noteref\"><sup>6</sup></a></li> </ul> <h2 id=\"number-of-books-written-or-published\">Number of books written or published</h2> <p>As I mentioned, I have taken to writing more on non-technical topics, but I’ve even taken to dabble in fiction this year. I wrote a lot of fiction when I was (much) younger but all that I wrote from those days resides at the bottom of a landfill in Baltimore… which is probably for the best. I doubt that this avenue will result in any publications or even anything worth reading at all, but I’m having a great time regardless.</p> <h2 id=\"number-of-programming-languages-designed\">Number of programming languages designed</h2> <p>I’ve tinkered with a concatenative functional programming language named Juxt for years, but it’s not something that anyone should ever use. My thoughts are almost entirely focused exclusively on moving Clojure into the future, but I take a moment to think in stacks from time to time.<a href=\"#fn7\" id=\"fnref7\" role=\"doc-noteref\"><sup>7</sup></a></p> <h2 id=\"favorite-musicians-albums-discovered\">Favorite musicians / albums discovered</h2> <ul> <li><em><a href=\"https://lovesliescrushing.bandcamp.com/\">lovesliescrushing</a></em> - <em>It’s been quite a while since I’ve discovered any good ambient. This duo’s catalog has accompanied many of my 2025 coding activities.</em></li> <li><em><a href=\"https://deathandvanillamusic.bandcamp.com/album/whistle-and-ill-come-to-you\">Whistle And I’ll Come to You</a></em> by Death and Vanilla - <em>An album that conjures the atmosphere of folk horror films despite its electronic and psychedelic tones. It has a vaguely similar ethereal beauty that drew me to Dead Can Dance 100 years ago.</em></li> <li><em><a href=\"https://mariachiaramusic.bandcamp.com/album/closer\">Closer</a></em> by Maria Chiara Argirò - <em>Her jazz-infused electronic ambient music drilled its way into my ear and nested in my brain for months.</em></li> </ul> <p>The artist that I listened to the most in 2025 was <a href=\"https://cocteautwins.com/\">Cocteau Twins</a> – which probably mirrors a couple of years around when I was 15 or 16.<a href=\"#fn8\" id=\"fnref8\" role=\"doc-noteref\"><sup>8</sup></a></p> <h2 id=\"favorite-show-about-a-misanthrope-tasked-with-saving-a-humanity-that-might-not-be-worth-saving-at-all\">Favorite show about a misanthrope tasked with saving a humanity that might not be worth saving at all</h2> <p><a href=\"https://www.imdb.com/title/tt22202452/\">Pluribus</a></p> <h2 id=\"favorite-films-discovered\">Favorite films discovered</h2> <ul> <li><strong><a href=\"https://www.imdb.com/title/tt26581740/\">Weapons</a></strong> by Zach Cregger - <em>This one was probably my pick for the best new horror film released in 2025. Like Cregger’s other horror film <a href=\"https://www.imdb.com/title/tt15791034/\">Barbarian</a>,<a href=\"#fn9\" id=\"fnref9\" role=\"doc-noteref\"><sup>9</sup></a> Weapons mixed in black humor without being ham-handed about it. The highlight of the film was the performance by Amy Madigan, who stole every scene that she was in.</em></li> <li><strong><a href=\"https://www.imdb.com/title/tt7322224/\">Triangle of Sadness</a></strong> by Ruben Östlund - <em>Östlund is truly the master of the cringey moment, but his work is not “cringe comedy” as we commonly encounter. The cringe tension in his films instead comes from the mismatched expectations of the characters and a dogged insistence on magnifying the cringe that arises by stretching scenes to their breaking point.</em></li> </ul> <h2 id=\"favorite-podcasts\">Favorite podcasts</h2> <ul> <li><strong><a href=\"https://quietlittlehorrors.com/\">Quiet Little Horrors</a></strong> by <a href=\"https://jenmyers.net/about/\">Jen Meyers</a> and <a href=\"https://jessichartier.com/\">Jessi Chartier</a> - <em>By far my favorite horror-related podcast going right now. The cinematic analysis from the hosts is surpassed only by the texture of their personal experiences informing their analysis of films. I consider myself extremely lucky to have had the chance to sit down with the hosts and talk about Roman Polanski’s film, and Roland Topor’s book on which it’s based, <a href=\"https://bookshop.org/p/books/the-tenant-valancourt-international-roland-topor/b99ff27c8d84505f?aid=98208&amp;ean=9781948405775&amp;listref=best-things-2025&amp;next=t\">The Tenant</a> for their <a href=\"https://quietlittlehorrors.com/episode-06-14-the-tenant/\">penultimate 2025 episode</a>.</em></li> <li><strong><a href=\"https://open.spotify.com/show/0mYti5kalrRraItbZubwvk\">Beyond Yacht Rock 2000</a></strong> - <em>A podcast with a brilliant premise – devise a fictional genre of music and then try to find musicians, albums, and songs that adhere to that genre.</em></li> <li><strong><a href=\"http://www.youtube.com/channel/UCXat06LvIYIyE2SpV_IuVjA\">Malcom Guite</a></strong> - <em>Tolkien, Arthurian epic poetry, pipe-smoking… I wish this guy was my dad.</em></li> <li><strong><a href=\"https://www.youtube.com/@QuinnsIdeas\">Quinn’s Ideas</a></strong> - <em>I enjoy his long-form science fiction analysis, which is a YT genre that I typically skip. I’m pleased that the channel has so far avoided devolving into the inevitable booktube haul morass.</em></li> </ul> <h2 id=\"favorite-games-discovered\">Favorite games discovered</h2> <p>Usually tabletop games, but occasionally video games.</p> <ul> <li><strong>Jacoby</strong> - <em>While reading Montague Rhodes James’ memoir I came across the mention of a card game called Jacoby. After searching high and low for months, I finally found the rules in a book from 1890 titled The young folk’s cyclopædia of games and sports.<a href=\"#fn10\" id=\"fnref10\" role=\"doc-noteref\"><sup>10</sup></a> This long-lost game is a 3-player trick-taking game with some very nice tension.</em><a href=\"#fn11\" id=\"fnref11\" role=\"doc-noteref\"><sup>11</sup></a></li> <li><strong><a href=\"https://boardgamegeek.com/boardgame/354132/east-india-companies\">East India Companies</a></strong> designed by Pascal Ribrault - <em>The best tabletop game that I’ve found in 2-3 years. The game is a distilled <a href=\"https://blog.fogus.me/games/18XX/intro.html\">18XX</a> game with a dash of luck thrown in for good measure. It’s a purely stock holding and market manipulation game where a little bit of information compounds to large advantages if you can leverage it at the right time. I would play this 50 more times if I could.</em></li> <li><strong><a href=\"https://boardgamegeek.com/boardgame/262939/far-away\">Far Away</a></strong> designed by Alexander Jerabek - <em>A science fiction cooperative sandbox game for 2-players but that I’ve only ever played solo. While I think that the game as designed would be a better 2p affair, as a solo game it’s still an interesting world-builder. I enjoy the meta-nature of the game that allows the player(s) to not only build the world as they explore it, but they are tasked with defining the “mechanics” of the world along the way.</em></li> </ul> <ul> <li><em><a href=\"https://hypercubed.github.io/joy/joy.html\">Joy</a></em> - <em>Joy is a mindfrak of a programming language in the concatenative functional language family. The core of Joy is beautiful and among the foundational programming languages in my opinion.</em></li> </ul> <ul> <li><a href=\"http://www.clojure.org/\">Clojure</a> - <em>2025 marks the 16th year<a href=\"#fn12\" id=\"fnref12\" role=\"doc-noteref\"><sup>12</sup></a> as a full-time Clojure programmer.</em></li> <li><a href=\"https://mail.openjdk.org/pipermail/amber-spec-experts/2023-December/003959.html\">Java</a> - <em>Working deep in the Clojure compiler means that a portion of my 2025 work was in Java.</em></li> </ul> <ul> <li><em><a href=\"https://clojerl.org/\">Clojerl</a></em> - <em>There was once a dialect of Clojure targeting Erlang/BEAM so I would like to catch up on it to see where it stands.</em></li> <li><em><a href=\"https://github.com/babashka/scittle\">Scittle</a></em> - <em>A very lightweight, Clojure-like, skin on top of JavaScript that it super simple to include in HTML pages. I would like to produce something that uses Scittle to get a feel for its “Clojure-ness.”</em></li> </ul> <h2 id=\"favorite-papers-discovered-and-read\">Favorite papers discovered (and read)</h2> <p>none of particular note.</p> <h2 id=\"still-havent-read\">Still haven’t read…</h2> <p>I Ching, A Fire upon the Deep, Don Quixote, and <strong><a href=\"http://blog.fogus.me/2012/09/21/the-amazing-colossal-science-fiction-ketchup/\">a boat-load of sci-fi</a></strong></p> <h2 id=\"favorite-technical-conferences-attended\">Favorite technical conferences attended</h2> <ul> <li><em><a href=\"https://www.2025.clojure-conj.org/\">Clojure/conj 2025</a></em> - <em>The 2025 edition of the Conj was the first organized entirely by <a href=\"https://www.nubank.com/\">Nubank</a>’s amazing Clojure community-focused team: Magdalena Useglio, Christoph Neumann, and Jordan Miller. Unsurprisingly, I think that this was one of the best Clojure/conj events ever, and I’ve seen my fair share. I’m perpetually humbled to be part of a community of amazingly thoughtful Clojure friends.</em></li> <li><em><a href=\"https://sites.google.com/nubank.com.br/clojure-south\">Clojure South 2025</a></em> - <em>Before that I was fortunate to be in Brazil when Clojure South happened. I had such a great time and was impressed by how well the conference was run. I met many new Clojure programmers and dozens of brilliant Brazilian programmers for the first time. I would love to attend the next one if at all possible.</em></li> </ul> <h2 id=\"favorite-code-read\">Favorite code read</h2> <ul> <li><em><a href=\"https://www.redblobgames.com/grids/hexagons/implementation.html\">Implementation of Hex Grids</a></em> - <em>Useful functions for game developers/designers.</em></li> <li><em><a href=\"https://small-js.org/Home/Home.html\">SmallJS</a></em> - <em>A little Smalltalk-80 that compiles to JavaScript.</em></li> <li><em><a href=\"https://github.com/historicalsource/zork1\">Zork I</a></em> - <em>The original Zork source code. I’ve only started digging into the <a href=\"https://setsideb.com/learning-zork-implementation-language-by-steve-meretzky/\">ZIL</a> definitions, but I plan to keep digging for months to come.</em></li> <li><em><a href=\"https://computerhistory.org/blog/xerox-alto-source-code/\">Xerox Alto</a></em> - <em>So far I’ve only scratched the surface of the mountains of system code in the archive. The wisdom contained in here is likely to take a lifetime to explore.</em><a href=\"#fn13\" id=\"fnref13\" role=\"doc-noteref\"><sup>13</sup></a></li> </ul> <h2 id=\"life-changing-technology-discovered\">Life-changing technology “discovered”</h2> <ul> <li><em>LLMs</em> <em>are here to stay, so it behooves me to learn to navigate this new world. That said…</em></li> <li><em><a href=\"https://en.wikipedia.org/wiki/Zettelkasten\">Zettelkasten</a></em> <em>… has had a much larger impact on my life in 2025. I’ve only just started collecting my notes using the system, but I’ve managed to leverage the system to put together a handful of non-technical posts (see the section on my posts above) this year and found the system very helpful in composing ideas. This is a long-term WiP, but I’ve very pleased so far.</em><a href=\"#fn14\" id=\"fnref14\" role=\"doc-noteref\"><sup>14</sup></a></li> </ul> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-zettelkasten-ca.jpg\" alt=\"Some Zettelkasten notes used for Checkers Arcade post\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <h2 id=\"state-of-plans-from-2025\">State of plans from 2025</h2> <p>2025 was a particularly productive year for meeting my plans for the year. Starting early in the year I knew that I needed a better way to track my tasks. So to start the year I visited a couple of Japanese stationary stores<a href=\"#fn15\" id=\"fnref15\" role=\"doc-noteref\"><sup>15</sup></a> to get some ideas. In 2024 I had used the Hobonichi Techo<a href=\"#fn16\" id=\"fnref16\" role=\"doc-noteref\"><sup>16</sup></a> and while I found it to be a lovely system, it didn’t quite work for me. First, it wasn’t clear how or if I was making progress on my tasks without spelunking into the past pages of the schedule. Second, I take a lot of notes longhand in cheap composition notebooks and so I found myself jumping back and forth between those and the Hobonichi. I tried using an insert into my Techo case for note-taking but I didn’t like the form-factor. I take big sprawling notes and filled the pages too quickly. So after the new year I took a minimalist approach with a Japanese calendar stamp:</p> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-stamp-cal.jpg\" alt=\"Rubber stamp calendar\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <p>The image above shows an example, but the problem with it should be apparent… there’s just not enough room for fidelity. OK, sure it didn’t work as a real task tracker, but I still use it to keep track of small bits of detail associated with days of the week like: energy level, mood, sleep, exercise, etc. It became apparent that I needed something that solved three problems: 1) track any number of tasks, 2) give me an idea of my progress at a glance, and 3) be on hand already. My first pass at this was to draw a 4-week grid on my notebook and scribble tasks in pencil into the cells. I would then color the grid as I progressed through tasks. This worked great for about 5 weeks until I went on a week-long trip without my notebook, killing my solution to #3. Even before that however I had found that I wanted to make frequent changes and move things around, defer items, and change the colors, so it became apparent that I had another problem to solve; 4) allow for easy change. While I was on my week-long trip I decided to find a solution that account for all four of my problems, and it turned out that my solution was the solution to so many other problems… spreadsheets!</p> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-tasks-sheet.jpg\" alt=\"My ongoing tasks sheet\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <p>Above you’ll see a representational image that gives the basics of the task tracking. The rows correspond to tasks and the columns to the months. The white section on the left are the tasks details like category, name, description, and success criteria. The colored segments represent the state of the tasks regarding progress. The left-most colored column is the current month. Each cell is filled in before the month starts with high-level goals which are amended and modified as I make progress (or not). The meaning of the colors are:</p> <ul> <li>Light green: Task completed and success criteria met</li> <li>Dark green: Task completed, but its success criteria changed during the process</li> <li>Light orange: Not started</li> <li>Dark orange: In progress (not shown above)</li> <li>Red: Incomplete and/or unsuccessful</li> <li>Gray: Not applicable. This is for new tasks that are added to the tracker, or removed and brought back. All months are back-filled in gray.</li> </ul> <p>And that’s the whole system. It’s easy to change and rearrange. It’s on-hand.<a href=\"#fn17\" id=\"fnref17\" role=\"doc-noteref\"><sup>17</sup></a> I can see how I’m doing at a glance. Can track any number of simultaneous tasks. Perfect.</p> <p>Enough of this meta-discussion… how did my plans for 2025 go?</p> <ul> <li><em><a href=\"https://www.clojure.org/\">Clojure 1.13</a></em> - <em>While a 1.13 release didn’t happen, we did release numerous updates to 1.12 and made plans for how to fill out the next version.</em></li> <li><em><a href=\"https://github.com/clojure/core.async\">core.async next</a></em> - <em>We made some interesting changes to core.async to leverage JDK 21+ virtual threads, but before that we made changes to smooth the path for allowing opt-in use of vthreads. At the moment there are some challenges around the way that the JVM tracks vthreads, but I feel pretty good that if we can address those then the implementation is solid.</em></li> <li><em><a href=\"https://blog.fogus.me/\">Simplify my blog</a></em> - <em>I completely moved away from Wordpress onto a hacked-together Markdown/org-mode + pandoc + bash to static pipeline. It’s a piece of junk, but so much more lightweight that what I had running for years.</em></li> <li><em><a href=\"https://gist.github.com/fogus/224d658be2a1afaaffe4ac1f25d1fa61\">Juxt</a></em> - <em>Juxt is my exploration in functional concatenative language design built on the JVM. It’s not yet clear to me if or when I would ever release this into the wild, but the explorations have been great fun and I’ve used Juxt as a vehicle for finding relevant books and papers.<a href=\"#fn18\" id=\"fnref18\" role=\"doc-noteref\"><sup>18</sup></a> That said, most of my programming time is spent maintaining and evolving Clojure, but there are rare moments of time that I can spend on Juxt, and I plan to continue to do so in 2025. You’ll see some interesting progress in the gist link.</em></li> </ul> <h2 id=\"plans-for-2026\">Plans for 2026</h2> <ul> <li><em>More non-technical writing in 2026.</em> - <em>I would like to continue explorations of fiction and games. That’s not to say that there aren’t a few technical posts in me still, but they will not be my priority.</em></li> <li><em>Publish the rules for a card game of my own design.</em> - <em>I have a couple in the pipeline, and feel like one of them could be a keeper.</em></li> <li><em><a href=\"https://www.clojure.org/\">Clojure 1.13</a></em> - <em>Thinking around the 1.13 release is ongoing and we’d like to get it out sooner rather than later. Stay tuned.</em></li> <li><em>Create something with my hands</em> - <em>I have no idea what this might be, but I’ve been putting off artifact creation for waaaaay too long.</em></li> <li><em>Read more non-fiction</em> - <em>I’m particularly interested in biographies and books-on-books.</em><a href=\"#fn19\" id=\"fnref19\" role=\"doc-noteref\"><sup>19</sup></a></li> <li><em>Read an untranslated book</em> - <em>Inspired by the <a href=\"https://theuntranslated.wordpress.com/\">Untranslated Blog</a>… my best chance for success is something written in French. Topic TBD.</em></li> </ul> <h2 id=\"tech-radar\">2026 Tech Radar</h2> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-zettelkasten.jpg\" alt=\"My Zettelkasten stack\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <ul> <li>try: <a href=\"https://www.goodnotes.com/\">Goodnotes</a> - <em>I’ve bounced off of numerous note-taking apps in my time, but my older son swears by it for annotating PDFs.</em></li> <li>adopt: <a href=\"https://www.amazon.com/Antinet-Zettelkasten-Knowledge-Prolific-Researcher/dp/B0BPVTBYG7/?tag=fogus-20\">Antinet Zettelkasten</a> - <em>I used my growing card file to great effect while writing a few essays this year.</em></li> <li>assess: LLMs - <em>I’m into the 3rd AI hype-cycle in my life (at least) and this is not much different than they other two, save for the potential market and job disruptions in play. I tried in earnest to make AI work for me, with varying degrees of un-success. I’ve had zero success leveraging it in my work maintaining and evolving Clojure. For problem formation in the face of novelty, LLMs have been more frustrating than helpful and the little gains that I’ve found were in the very early phases of problem solving requiring a bare minimum of experimental code. But even these examples operate wholly in the known rather than in the unknown where I’d like to operate instead. Even in these early stages the “hand-holding” involved was more frustrating than helpful. In my work, the bottleneck is absolutely not the code. While I think that the kind of up-front work that I do could inform prompt-engineering to some degree, by the time that I get to that point the code is often perfunctory. Most of the work that I do is devising and investigating new problem framing rather than in interpolation of the known (i.e.&nbsp;analogy play). While the latter is important for sure, what’s known often acts as a source of tension to help motivate and tease out potentially new solutions. And this is a huge problem in the very nature of LLMs. That is, they are trained on the products of problem solving processes rather then also in the very processes themselves. Further, as a Socratic partner, LLMs are incredibly frustrating in their inability to move a “discussion” forward. A good Socratic partner creates pressure to move toward truth, but LLMs are too sycophantic, lack an awareness of useful tension,<a href=\"#fn20\" id=\"fnref20\" role=\"doc-noteref\"><sup>20</sup></a> cannot often identify contradiction, and lack any ability to adhere to the trajectory of a conversation. So far I’m left wanting, but because LLMs are likely to never go away then I’ll see if these downsides get better in the future.</em><a href=\"#fn21\" id=\"fnref21\" role=\"doc-noteref\"><sup>21</sup></a></li> <li>hold: <a href=\"https://www.amazon.com/BOOX-Tablet-Go-10-3-ePaper/dp/B0D4DFT3W3/?tag=fogus-20\">Boox Go 10.3 tablet</a> - <em>I just couldn’t pull the trigger on this and suspect that I will not ever.</em><a href=\"#fn22\" id=\"fnref22\" role=\"doc-noteref\"><sup>22</sup></a></li> <li>stop: <a href=\"https://www.typescriptlang.org/\">TypeScript</a> - <em>I just don’t do enough in this space to justify continuing down this road.</em></li> </ul> <figure> <img src=\"https://blog.fogus.me/2025/12/23/images/bts25-c64ai.jpg\" alt=\"Have you heard of an AI?\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </figure> <h2 id=\"people-who-inspired-me-in-2025-in-no-particular-order\">People who inspired me in 2025 (in no particular order)</h2> <p>Yuki, Keita, Shota, Craig Andera, Carin Meier, Justin Gehtland, Rich Hickey, Nick Bentley, Paula Gearon, Zeeshan Lakhani, Brian Goetz, David Nolen, Jeb Beich, Paul Greenhill, Kristin Looney, Andy Looney, Kurt Christensen, Samm Deighan, David Chelimsky, Chas Emerick, Stacey Abrams, Paul deGrandis, Nada Amin, Michiel Borkent, Alvaro Videla, Slava Pestov, Yoko Harada, Mike Fikes, Dan De Aguiar, Christian Romney, Russ Olsen, Alex Miller, Adam Friedman, Tracie Harris, Alan Kay, Wayne Applewhite, Naoko Higashide, Zach Tellman, Nate Prawdzik, Bobbi Towers, JF Martel, Phil Ford, Nate Hayden, Sean Ross, Tim Good, Chris Redinger, Steve Jensen, Christian Freeling, Jordan Miller, Mia, Christoph Neumann, Tim Ewald, Stu Halloway, Jack Rusher, Jenn Meyers, Michael Berstein, Benoît Fleury, Rafael Ferreira, Robert Randolph, Joe Lane, Renee Lee, Pedro Matiello, Jarrod Taylor, Magdalena Useglio, Jaret Binford, Ailan Batista, Matheus Machado, Quentin S. Crisp, John Cooper, Conrad Barski, Amabel Holland, Ben Kamphaus, Barry Malzberg (RIP), Kory Heath (RIP).</p> <p>Onward to 2026!</p> <p>:F</p> <section id=\"footnotes\" role=\"doc-endnotes\"> <hr> <ol> <li id=\"fn1\"><p>The video has similar vibes to Haruki Murakami’s excellent book After Dark.<a href=\"#fnref1\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn2\"><p>I’d love to try and write something about Corvo’s obsession with the Catholic hierarchy and the tenuous idea that it was a kind of occult architecture. This may be a bridge too far for my ability and knowledge.<a href=\"#fnref2\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn3\"><p>I have some of these books listed at <a href=\"https://bookshop.org/lists/best-things-2025\">bookshop.org</a> if you’re interested in grabbing copies.<a href=\"#fnref3\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn4\"><p>A lot more Droodiana has been written since 1950 of course.<a href=\"#fnref4\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn5\"><p>The “move to the country” theme present in a significant number of pre-WWII fiction representing a reclamation of feminine power. I would love to find/create a list of books exploring this theme.<a href=\"#fnref5\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn6\"><p>Interestingly, this was a recommendation from friend <a href=\"https://www.linkedin.com/in/david-nolen-37b42813/\">David Nolen</a>, who also mentioned another book that just barely missed this list, <a href=\"https://bookshop.org/p/books/melville-s-short-novels-authoritative-texts-contexts-criticism-herman-melville/f3008086921a816b?aid=98208&amp;ean=9780393976410&amp;listref=best-things-2025&amp;next=t\">Benito Cereno</a> which I think needs another read in the future.*<a href=\"#fnref6\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn7\"><p>If you’re interested in exploring an interesting new programming language that mixes interesting ideas, then I recommend <a href=\"https://www.uiua.org/\">Uiua</a> that bills itself as a point-free, APL-style, array-oriented modern language.<a href=\"#fnref7\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn8\"><p>I was in a “junk shop” a couple of weeks ago and found both Black Sabbath’s <em>Master of Reality</em> and the <em>Complete Vatican Recordings</em> of the works of Alessandro Moreschi… two albums that couldn’t be more different. I suspect that one of both of these albums will get a lot of play in 2026.<a href=\"#fnref8\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn9\"><p>I could have also added Cregger’s <em>Barbarian</em> to the year’s best filmatic discoveries, but I would like another watch to really focus in on the depths.<a href=\"#fnref9\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn10\"><p>I also found a POD copy of the Nichureki, a 13th-century Japanese book containing the earliest written record of Heian Shogi… a topic for another day perhaps.<a href=\"#fnref10\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn11\"><p>I wrote an essay about Jacoby and its connection to the author M.R. James that is due to be published next year in the journal <em>Ghosts and Scholars</em> #50.<a href=\"#fnref11\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn12\"><p>This is strictly my work-life time. My total use of Clojure has been longer.<a href=\"#fnref12\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn13\"><p>While the Alto source code is certainly interesting, it’s unclear how the repository credits Douglas Engelbart’s NLS vision and Intellect Augmentation, if at all.<a href=\"#fnref13\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn14\"><p>My ultimate dream is to build a giant card-file and then build a Jack Kirby-esque relentless idea-collage universe along the lines of his “Fourth World” mythos tying together all of the concepts in said file… I may need another lifetime for this.<a href=\"#fnref14\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn15\"><p>Japanese stationary stores and thrift-shops are two of my guilty pleasures. Has anyone else noticed that in the States, there are more young people shopping in thrift shops than ever before. I would love to understand why. Is it a growing prevalence of Tik-Tok thrift-haul videos, an appreciation for retro, an economic indicator, all, some, or none?<a href=\"#fnref15\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn16\"><p>I put my best effort into the Techo, but I could never fully buy into the very Japanese view of the planner as a life-book.<a href=\"#fnref16\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn17\"><p>I’m already in Google Sheets all the time anyway, and can access it on my phone if needed. Really though, I’d love to see a device in the spirit of the TRS-80 model 100 to do this kind of work on the go… but I would still probably not get one. ¯_(ツ)_/¯<a href=\"#fnref17\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn18\"><p>You can see the <em>current</em> <a href=\"https://gist.github.com/fogus/6d716276678b0698c96dd13e040c71eb\">Juxt bibtex</a> on GitHub.<a href=\"#fnref18\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn19\"><p>I would also love to read the complete work of the comic book creator Jack Kirby. There are some lovely omnibus editions of his work, but I don’t quite know how I feel about the fact that the comics industry is embracing this format. Certainly singles are a joke, but omnibuses have turned comics enjoyment from reading into weightlifting.<a href=\"#fnref19\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn20\"><p>The tension problem is also why I’ve found LLMs to be terrible at aiding tabletop game design. A prime characteristic of the kinds of games that I enjoy is emergent complexity, but if LLMs identify complexity at all, they have so far been terrible at deciding which complexity is useful. That is, LLMs have no notion of “delicious tension” nor how to devise it.<a href=\"#fnref20\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn21\"><p>A huge problem with LLMs are that they are by their very nature dependent on digitized information. While a larger proportion of scientific and computing information is available in digitized form, there are still whole fields of knowledge left on paper, so to speak. First, a large problem with this fact is that only a small fraction of total knowledge is available to training LLMs, leaving large gaps in the knowledge base exacerbating the problem of decoupled confidence and reality. Second, this is problematic because training these models on digital-data leads to an amplification of the biases inherent in the digitized records. This can be mitigated by the search-augmented and human-in-the-loop systems, but these are also incomplete sources of validation and even the validation itself has bias (e.g.&nbsp;SEO, status quo, liability constraints, etc.) and often reduce the traceability of an answer. A second informational downside of LLMs is that they take training data at face-value rather than inherent value. However, in my programming career I’ve learned a lot more from bad code than good code. Likewise, code input to training is heavily biased to work at all and the ingestion itself it geared strictly to work to build a plausible-continuation model. Good code works as exemplars of clarity, layering abstractions, maintainability, and sad-path security, but so does bad code. Heavily curated or contrasting training data could mitigate this to some degree, but at the moment, a lot of the code generated by LLMs is often lacking these fundamental code characteristics. This matches my actual observation of code generation, but I would imagine that the inability of the ingestion to distinguish valid examples from cautionary examples is more general problem. These are all technical points and do not take into account the societal problems that LLMs present… which are bountiful! These are evolving critiques that I’ll refine through more exposure.<a href=\"#fnref21\" role=\"doc-backlink\">↩︎</a></p></li> <li id=\"fn22\"><p>The Boox is a truly lovely device, but I’ve developed a diametric motivation to de-device myself. This was born from my perennial obsession with Cyberdecks and “minimalist” writing devices. Every so often I’m hit with a driving urge to build such things, but then I get turned off by the supporting communities around them, especially its gross fetishization of an “aesthetic of productivity” where the act of building (and buying of course) these tools supersedes and stands-in for their actual use.<a href=\"#fnref22\" role=\"doc-backlink\">↩︎</a></p></li> </ol> </section> </div>"},{"id":"https://arxiv.org/abs/1902.01989","title":"A Century of Noether's Theorem","link":"https://arxiv.org/abs/1902.01989","hnCommentsUrl":"https://news.ycombinator.com/item?id=46402611","content":"<a href=\"https://news.ycombinator.com/item?id=46402611\">Comments</a>","date":1766850122000,"feedTitle":"Hacker News","isHackerNews":true,"isGoogleNews":false,"fullContent":"<div id=\"readability-page-1\" class=\"page\"><div> <h2>Submission history</h2><p> From: Chris Quigg [<a href=\"https://arxiv.org/show-email/cdeaf937/1902.01989\" rel=\"nofollow\">view email</a>] <br> <strong><a href=\"https://arxiv.org/abs/1902.01989v1\" rel=\"nofollow\">[v1]</a></strong> Wed, 6 Feb 2019 00:51:17 UTC (183 KB)<br> <strong>[v2]</strong> Tue, 9 Jul 2019 18:15:15 UTC (183 KB)<br> </p></div></div>"}]}