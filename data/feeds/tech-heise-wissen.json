{"title":"Heise Wissen","items":[{"id":"http://heise.de/-11124865","title":"Nasa-Mondmission: Maskottchen-Entwurf aus Deutschland nominiert","link":"https://www.heise.de/news/Nasa-Mondmission-Maskottchen-Entwurf-aus-Deutschland-nominiert-11124865.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Nasa-Mondmission-Maskottchen-Entwurf-aus-Deutschland-nominiert-11124865.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/1/4/0/5/Artemis-II-Crew-8a238189332bd914.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Mit der Artemis 2-Mission will die US-Raumfahrtbehörde Nasa demnächst wieder Menschen in die Nähe des Mondes schicken. Mit an Bord soll ein Maskottchen sein.</p>","date":1766674260000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Wenn 2026 erstmals seit über 50 Jahren wieder Menschen in die Nähe des Mondes fliegen, könnte ein in Deutschland entworfenes Maskottchen mit an Bord sein. Ein Entwurf der in Berlin lebenden 34 Jahre alten Italienerin Giulia Bona schaffte es aus mehr als 2.600 Einreichungen von Kindern und Erwachsenen aus der ganzen Welt in die Endrunde der 25 Finalisten, wie die US-Raumfahrtbehörde Nasa mitteilte. Der Gewinner-Entwurf soll von der Artemis 2-Crew – Reid Wiseman,Victor Glover, Christina Koch und Jeremy Hansen – ausgewählt werden. Die vier Raumfahrer sollen mit der auf rund zehn Tage angelegten Mission in der ersten Jahreshälfte 2026 den Mond umrunden. Sie wären die ersten Menschen in der Nähe des Mondes, seit die Astronauten der Apollo 17-Mission den Erdtrabanten im Jahr 1972 betraten.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Bonas Schwerelosigkeits-Maskottchen ist ein kleiner Astronaut, der auf der Schulter eines Giganten sitzt. Ein Schwerelosigkeits-Maskottchen ist ein Objekt, das in einem Raumschiff zu schweben beginnt, sobald nach dem Start die Schwerelosigkeit eingesetzt hat. So wird der neue Zustand sichtbar demonstriert.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die 24 anderen ausgewählten Entwürfe stammen nach Nasa-Angaben aus den USA, Kanada, Kolumbien, Finnland, Frankreich,Japan, Peru, Singapur und Großbritannien.</p> <h3 id=\"nav_schon_gagarin__0\">Schon Gagarin hatte wohl ein Schwerelosigkeits-Maskottchen</h3> <p>Angeblich geht die Tradition des sogenannten Zero-G-Indicators schon auf Juri Gagarin zurück, den ersten Menschen im Weltraum. Der sowjetische Kosmonaut soll bei seinem Flug im Jahr 1961 eine kleine Puppe dabeigehabt haben. Seitdem waren zahlreiche Objekte, darunter viele Stofftiere, im All. Sie habe im Internet von der Aktion gelesen und spontan beschlossen mitzumachen - unter anderem, weil sie schon seit ihrer Kindheit vom Weltraum fasziniert sei, sagte die in Berlin als freiberufliche Wissenschaftskommunikatorin arbeitende Bona der Deutschen Presse-Agentur. „Ich hätte nicht wirklich gedacht, dass ich so weitkommen könnte.“ Nach „Wochen voll schlechter Ideen“ sei sie auf den schlussendlich eingereichten Entwurf gekommen: einen Astronauten, der auf der Schulter eines Giganten namens Orion sitzt. Orion heißt auch die Raumkapsel der Nasa, sowie ein Partner der Göttin Artemis, nach der die Mondmission benannt ist.</p> <p>Dass ihr Entwurf es in die Endrunde geschafft habe, sei eine«unerwartete Freude» gewesen, sagte Bona. Viele der anderen Entwürfe finde sie auch großartig, sie wolle aber nicht lügen: Natürlich würde sie liebend gerne den Livestream des Artemis-Starts verfolgen und dann ihr Maskottchen „zwischen den Astronauten schweben sehen.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:kst@heise.de\" title=\"Kathrin Stoll\">kst</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11124422","title":"Größtes Elektroschiff der Welt geht erstmals in Betrieb","link":"https://www.heise.de/news/Groesstes-Elektroschiff-der-Welt-geht-erstmals-in-Betrieb-11124422.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Groesstes-Elektroschiff-der-Welt-geht-erstmals-in-Betrieb-11124422.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/1/1/8/0/hp-9ac62ade76c121b7.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Die australische Werft Incap hat das größte Elektroschiff der Welt fertiggestellt. Jetzt startet das Testprogramm.</p>","date":1766564400000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Leinen los für die Elektrofähre: Die australische Werft Incat Tasmania hat erstmals die Systeme der Fähre Incat Hull 096 hochgefahren und den Jet-Antrieb getestet. Das Schiff ist nach Angaben der Werft derzeit das größte Elektroschiff der Welt.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Das Schiff verfügt über einen Wasserstrahlantrieb mit acht Jets: Durch Düsen wird Wasser mit großem Druck ausgestoßen, was einen Rückstoß erzeugt, der das Schiff antreibt. Vor geladenen Gästen, darunter der australische Wirtschaftsminister Don Farrell und der tasmanische Premierminister Jeremy Rockliff, hat Incat-Chef Robert Clifford die Jets gestartet und deren Leistung demonstriert, <a href=\"https://incat.com.au/history-made-as-worlds-largest-battery-electric-ship-powers-up/\" rel=\"external noopener\" target=\"_blank\">teilte Incat mit</a>. Das sei der Auftakt für das Testprogramm gewesen, bevor das Schiff ausgeliefert werde.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die <a href=\"https://incat.com.au/incat-vessels/096/\" rel=\"external noopener\" target=\"_blank\">Incat Hull 096</a> ist eine Fähre, die die uruguayische Reederei Buquebus in Auftrag gegeben hat. Buquebus betreibt Fähren auf dem Río de la Plata, dem Grenzfluss zwischen Uruguay und Argentinien. Dort soll auch die Elektrofähre eingesetzt werden.</p> <h3 id=\"nav_auf_den__0\">Auf den Katamaran passen über 200 Fahrzeuge</h3> <p>Die Fähre stellt einen 130 Meter langen und 32 Meter breiten Katamaran aus Aluminium dar. Auf dem Schiff, das <a href=\"https://www.heise.de/news/Groesstes-Elektroschiff-der-Welt-erhaelt-40-MWh-Batterie-10371728.html\">im Mai in Hobart vom Stapel gelaufen</a> ist, sollen 225 Fahrzeuge und 2100 Passagiere Platz finden.</p> <!-- RSPEAK_STOP --> <a-lightbox src=\"/imgs/18/5/0/0/1/1/8/0/lMcHY2fY-a3145f387a1976e8.jpeg\" tabindex=\"1\"> <figure> <p><a href=\"https://www.heise.de/imgs/18/5/0/0/1/1/8/0/lMcHY2fY-a3145f387a1976e8.jpeg\"> <img alt=\"Jet-Antrieb der Elektrofähre von Incat\" decoding=\"async\" height=\"522\" loading=\"lazy\" onload=\"this.style=null;\" sizes=\"\" src=\"https://heise.cloudimg.io/width/696/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/5/0/0/1/1/8/0/lMcHY2fY-a3145f387a1976e8.jpeg\" width=\"696\" data-old-src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> <figcaption> <p>Jet-Antrieb der Elektrofähre</p> <p> (Bild:&nbsp;Incat) </p> </figcaption> </figure> </a-lightbox> <!-- RSPEAK_START --> <p>Details wie die Leistung des Antriebs hat Incat nicht bekannt gegeben. Der Energiespeicher hat eine Kapazität von 400 Megawattstunden und wiegt rund 250 Tonnen. Er stammt von dem norwegischen Unternehmen Corvus Energy. Den Wasserstrahlantrieb hat das finnische Unternehmen Wärtsilä zugeliefert.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>„Das ist weltweit das erste Mal, dass ein Schiff dieser Größe mit einem hundertprozentigen batterieelektrischen Antrieb getestet wurde“, sagte Clifford. Das Schiff ist laut Incap nicht nur das größte Elektroschiff der Welt, sondern auch das größte bis dato gebaute elektrische Vehikel überhaupt. Die Werft will es nach den Tests voraussichtlich in einigen Monaten ausliefern.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Etwa 90 Prozent des Welthandels werden auf dem Seeweg abgewickelt. Der Schiffsverkehr macht knapp drei Prozent der weltweiten Kohlendioxidemissionen aus, 13 Prozent der Schwefel- sowie etwa 30 Prozent der Stickoxidemissionen. Hinzu kommen Rußpartikel und Feinstaub. Die Internationale Seeschifffahrts-Organisation (IMO) der Vereinten Nationen hat 2023 das Ziel ausgegeben, dass Schiffe 2050 klimaneutral sein müssen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11124279","title":"CE-Zertifizierung für Maker: GetSmandered macht's erschwinglich","link":"https://www.heise.de/news/CE-Zertifizierung-fuer-Maker-GetSmandered-macht-s-erschwinglich-11124279.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/CE-Zertifizierung-fuer-Maker-GetSmandered-macht-s-erschwinglich-11124279.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/1/1/0/5/Aufimachi-aff2911dd683e56e.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Eine Gruppenzertifizierung senkt die Kosten der CE für den Einzelnen drastisch. Das Projekt GetSmandered ist aber auf Open-Source-Hardware beschränkt.</p>","date":1766559900000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\"> </a-collapse> <!-- RSPEAK_START --> <p>Wer sein elektronisches Maker-Projekt in Europa verkaufen möchte, kommt meist nicht um die CE-Kennzeichnung (Conformité Européenne) herum. Ein Ausweg mag es sein, Bausätze zu verkaufen, aber dies ist oft nur eine Lösung für Kunden, die ebenfalls Maker und Bastler sind. Professionelle Zertifizierungen kosten schnell 5000 Euro aufwärts – ein Betrag, der viele Maker abschreckt. Das österreichische Start-up „Smander“ bietet mit „GetSmandered“ nun einen innovativen Ansatz: Gruppenzertifizierung zu deutlich reduzierten Kosten.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_das_prinzip__0\">Das Prinzip: Gemeinsam günstiger</h3> <p><a href=\"https://early.smander.com/\">GetSmandered</a> funktioniert nach einem einfachen Prinzip: Je mehr Maker sich für eine Zertifizierungsrunde anmelden, desto geringer werden die Kosten für alle Teilnehmer. Durch die Bündelung typischer Maker-Produkte und einen optimierten Prozess sollen Overheadkosten geteilt werden. <a href=\"https://early.smander.com/getsmandered-round-0\">Aktuell startet die „Round 0“ – Bewerbungen sind kostenlos und unverbindlich</a>. Voraussetzung: Das Produkt muss Open Source sein. Diese Einschränkung ermöglicht auch Kosteneinsparungen bei der Dokumentation und Datenverarbeitung.</p> <h3 id=\"nav_was_maker__1\">Was Maker bekommen</h3> <p>Im Basispaket sind:</p> <ul data-mark=\"-\"><li><strong>Produktanalyse</strong> durch zertifizierte CE-Produktkoordinatoren</li><li><strong>Regulatorische Recherche</strong>: Welche Richtlinien und Normen gelten für mein Produkt?</li><li><strong>To-Do-Sheet</strong>: Konkrete Schritt-für-Schritt-Anleitung in verständlicher Sprache statt juristischem Kauderwelsch</li><li><strong>Eine Stunde Beratung inklusive</strong> zur Erklärung aller Aufgaben</li><li><strong>Finale Dokumentation</strong>: „Declaration of Conformity“, Sicherheitshinweise, technische Dokumentation</li></ul> <p>Optional buchbar:</p> <ul data-mark=\"-\"><li>Komplette Risikoanalyse (sonst nur Template zum Selbstausfüllen)</li><li>Zusätzliche Beratungssessions</li><li>Gebundene Druckversion der CE-Dokumentation</li><li>EU-REP-Service für Hersteller außerhalb der EU</li></ul> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_der_prozess_2\">Der Prozess</h3> <ol><li><strong>Bewerbung</strong> über die Website bis zum Stichtag (derzeit keine Bewerbungsgebühr)</li><li><strong>Prüfung der Eignung</strong> und Benachrichtigung mit Preisangabe</li><li><strong>Produkteinsendung</strong> nach Österreich für die Analyse</li><li><strong>Erhalt des To-do-Sheets</strong> mit konkreten Anweisungen</li><li><strong>Bearbeitung der Aufgaben</strong> (Labortests, Lieferantendaten, etc.)</li><li><strong>Finale Dokumentation</strong> zum Unterzeichnen</li></ol> <p>Der 3. Punkt ist wichtig: Ein physisches Muster muss eingeschickt werden – idealerweise professionell bestückte Platinen, da die Fertigungsqualität Teil der Risikoanalyse ist.</p> <h3 id=\"nav_was_spart_man__3\">Was spart man konkret?</h3> <p>Während klassische CE-Assessments bei etwa 5000 Euro starten, verspricht GetSmandered durch die Gruppenzertifizierung deutlich niedrigere Kosten. Der genaue Preis wird erst nach Bewerbungsschluss bekannt gegeben und hängt von der Teilnehmerzahl ab. Ein garantierter Maximalpreis wird jedoch vorab kommuniziert.</p> <p>Zusätzliche Einsparungen:</p> <ul data-mark=\"-\"><li>Vermeidung kostspieliger Fehlversuche bei Labortests durch Vorabanalyse</li><li>Zeitersparnis durch klare Handlungsanweisungen statt aufwendiger Eigenrecherche</li><li>Keine Notwendigkeit, externe Berater zu beauftragen</li></ul> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_auch_für__4\">Auch für Privatpersonen</h3> <p>Anders als viele B2B-Services richtet sich Smander auch an Maker ohne eingetragenes Unternehmen. Wer später eine Firma gründet, kann die Dokumentation gegen eine Bearbeitungsgebühr aktualisieren lassen.</p> <p>Die Experten warnen eindringlich davor, einfach ein CE-Zeichen auf das Produkt zu kleben, ohne ordnungsgemäße Zertifizierung. Dies stellt eine ernsthafte Rechtsverletzung dar und kann zu erheblichen Konsequenzen führen. <a href=\"https://early.smander.com/faq\">Mehr Informationen und eine FAQ</a> stehen auf der Website zur Verfügung, Kontakt <a href=\"https://discord.smander.com/\">direkt am besten per Discord</a>.</p> <p><em>Hinweis: Der Service befindet sich aktuell in der Startphase. Interessierte sollten sich frühzeitig unverbindlich registrieren, da mehr Teilnehmer niedrigere Preise für alle bedeuten.</em></p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:caw@make-magazin.de\" title=\"Carsten Wartmann\">caw</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11124087","title":"Renaults elektrisches Rekordfahrzeug fährt über 1000 Kilometer ohne Ladestopp","link":"https://www.heise.de/news/Renaults-elektrisches-Rekordfahrzeug-faehrt-ueber-1000-Kilometer-ohne-Ladestopp-11124087.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Renaults-elektrisches-Rekordfahrzeug-faehrt-ueber-1000-Kilometer-ohne-Ladestopp-11124087.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/1/0/0/8/hp-5d6a3d072196451a.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Renault ist mit einem speziellen Elektrofahrzeug einen Langstreckentest gefahren. Das Auto fuhr mit einer Ladung über 1000 km.</p>","date":1766498580000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Rekordfahrt mit einem retrofuturistischen Testwagen: Der französische Automobilhersteller Renault hat nach eigenen Angaben einen Effizienzrekord mit dem elektrischen Demonstrationsfahrzeug Filante Record 2025 aufgestellt, das eine Reminiszenz an ein Rekordauto aus den 1920er Jahren darstellt.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Mit dem Filante Record 2025 sei es gelungen, „die Leistungsfähigkeit moderner Elektromobilität unter Beweis“ zu stellen, <a href=\"https://presse.renault.de/rekordfahrt-ins-neue-jahr/?lang=deu&amp;preview=true\" rel=\"external noopener\" target=\"_blank\">teilte Renault mit</a>. Das Fahrzeug drehte 239 Runden auf der UTAC-Teststrecke in Marokko ohne Ladestopp und legte dabei 1008 Kilometer zurück – der einzige Stopp war ein Fahrerwechsel, der sieben Minuten dauerte. Dabei verbrauchte das Fahrzeug laut Renault auf 100 Kilometer gerade einmal 7,8 Kilowattstunden. Die Fahrt, die am 18. Dezember stattfand, dauerte weniger als zehn Stunden, die Durchschnittsgeschwindigkeit betrug 102 km/h.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Über den Antrieb des Fahrzeugs macht Renault keine Angaben. Der Akku hat eine Kapazität von 87 Kilowattstunden und stammt aus einem Serienfahrzeug, dem aktuellen <a href=\"https://www.heise.de/tests/E-Auto-Renault-Scenic-E-Tech-220-im-Test-Alternative-zum-Tesla-Model-Y-9839333.html\">Scenic E-Tech Electric Long Range</a>. Am Ende der Fahrt betrug der Ladestand noch elf Prozent. Das hätte laut Renault noch für weitere 120 Kilometer gereicht.</p> <h3 id=\"nav_reminiszenz_an__0\">Reminiszenz an historische Rekordfahrzeuge</h3> <p>Der <a href=\"https://www.renault.de/concept-cars-range/z41-filante-demo-car.html\" rel=\"external noopener\" target=\"_blank\">Renault Filante Record 2025</a> ist einsitziges Fahrzeug mit frei stehenden Rädern. Das Design ist an zwei frühere Rekordfahrzeuge von Renault angelehnt – den <a href=\"https://theoriginals.renault.com/de/40-cv-des-records\" rel=\"external noopener\" target=\"_blank\">100 Jahre alten 40 CV</a> und den <a href=\"https://theoriginals.renault.com/etoile-filante\" rel=\"external noopener\" target=\"_blank\">Étoile Filante (Sternschnuppe) aus dem Jahr 1956</a> –, mit denen die Franzosen auf die Jagd nach Geschwindigkeits- und Langstreckenrekorden gingen.</p> <p>Der Filante Record 2025 ist 5,12 Meter lang, aber nur 1,71 Meter breit und 1,19 Meter hoch. Die windschnittige Karosserie und spezielle reibungsmindernde Reifen sollen ebenso zur Effizienz des Fahrzeugs beitragen wie eine elektronische Steuerung und Bremsen (Steer-by-Wire und Brake-by-Wire) statt herkömmlicher mechanischer.</p> <p>Die Aerodynamik ist von der Luftfahrt inspiriert: Die Formen stammen von Hochleistungsflugzeugen. Die Kuppel über dem Fahrersitz ähnelt dem Cockpit eines Kampfflugzeugs. Sie wurde seit der <a href=\"https://www.heise.de/news/Renault-will-mit-E-Rekordfahrzeug-im-Retrolook-auf-Effizienzrekordjagd-gehen-10268197.html\">Vorstellung des Fahrzeugs Anfang des Jahres</a> noch einmal verbessert.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_sitz_aus__1\">Sitz aus Segeltuch spart Gewicht</h3> <p>Optimiert wurde auch beim Gewicht: Das ganze Fahrzeug wiegt etwa eine Tonne, wovon allein 600 Kilogramm auf den Akku entfallen. Um Gewicht zu sparen, wurde die Karosserie aus Leichtbaumaterialien wie Kohlefaser-verstärkte Verbundwerkstoffe beziehungsweise einer speziellen Aluminium-Legierung gefertigt. Der Fahrersitz besteht aus Segeltuch.</p> <p>Der Akku stammt zwar aus einem Serienfahrzeug, der Aufbau ist jedoch anders: Im Filante sind die Zellen nicht in Modulen gepackt, sondern direkt in das Batteriepaket integriert (Cell-To-Pack, CTP). Die Batterie wird so zum Teil der Karosserie, was Gewicht spart und Platz besser ausnutzt.</p> <p>Das Design, die Technologien und die Performance seien jedoch „kein Selbstzweck und weit mehr als eine technische Übung“, betonte Renault. Die Erkenntnisse aus der Rekordfahrt sollen „in die Entwicklung künftiger elektrischer Straßenfahrzeuge einfließen“.</p> <!-- RSPEAK_STOP --> <div data-component=\"RecommendationBox\"><a-collapse sneak-peek-elements=\"3\" sneak-peek-elements-selector=\"article\"></a-collapse></div> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11123707","title":"Bundeslebensmittelschlüssel 4.0: Nährstoff-Datenbank jetzt frei verfügbar","link":"https://www.heise.de/news/Bundeslebensmittelschluessel-4-0-Naehrstoff-Datenbank-jetzt-oeffentlich-verfuegbar-11123707.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Bundeslebensmittelschluessel-4-0-Naehrstoff-Datenbank-jetzt-oeffentlich-verfuegbar-11123707.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/8/1/2/bls-f8ff3a463bd2e672.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Nährstoff-Datenbank für alle: Der Bundeslebensmittelschlüssel mit Werten für über 7.100 Lebensmittel ist lizenzfrei verfügbar.</p>","date":1766487000000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Der Bundeslebensmittelschlüssel (BLS), Deutschlands umfangreichste Nährwertdatenbank, steht ab sofort in der Version 4.0 kostenlos zur Verfügung. Die bisherigen Lizenzgebühren entfallen vollständig bei der vom Max-Rubner-Institut (MRI) bereitgestellten Datenbank, die detaillierte Informationen zu den Inhaltsstoffen und Energiegehalten von aktuell 7.140 Lebensmitteln und Gerichten enthält.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>In die überarbeitete Version wurden zudem Lebensmittel wie Pflanzendrinks oder Quinoa und Buchweizen in den Datenbestand aufgenommen. Insgesamt listet der BLS 4.0 pro Lebensmittel bis zu 138 verschiedene Nährstoffe, darunter auch neue Vitaminformen. Für die Aktualisierung wurden neben Laboranalysen des MRI auch Daten von nationalen Kooperationspartnern, aus der Lebensmittelwirtschaft und der wissenschaftlichen Literatur herangezogen. <a href=\"https://www.blsdb.de/\" rel=\"external noopener\" target=\"_blank\">Der BLS</a> dient unter anderem der Auswertung von Ernährungsstudien, als Grundlage für die Ernährungsberatung und wird von Lebensmittelherstellern zur Berechnung der verpflichtenden Nährwertkennzeichnung genutzt.</p> <h3 id=\"nav_beitrag_zu_open__0\">Beitrag zu Open Science und Open Data</h3> <p>Auf Anfrage von heise online erläuterte ein Sprecher des vom Bundesministerium für Landwirtschaft, Ernährung und Heimat (BMLEH) die Hintergründe der Entscheidung. Demnach soll der freie Zugang „allen Interessierten – von Verbraucherinnen und Verbrauchern bis hin zu Wissenschaft und Behörden – die uneingeschränkte Nutzung der BLS-Nährstoffdaten“ ermöglichen. „Der BLS profitiert hiervon, da sein offener Zugang den Austausch mit der Öffentlichkeit und Fachwelt erleichtert, deutlich entbürokratisiert und qualitativ auf Dauer sichert.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Das Ministerium sieht die Maßnahme als wichtigen Beitrag zur „Weiterentwicklung einer offenen Wissenschaft (Open Science), die mehr Transparenz, bessere Möglichkeiten für einen Wissensaustausch und effektivere Möglichkeiten zur Qualitätssicherung anstrebt.“ Man folge dem Grundgedanken eines offenen Verwaltungshandelns im Einklang mit gesetzlichen Regelungen wie dem E-Government-Gesetz, „wonach staatliche, nicht-personenbezogene <a href=\"https://www.heise.de/news/Deutschland-Stack-Rueckgrat-der-staatlichen-Daseinsvorsorge-in-der-Digitalwelt-10699649.html\">Daten frei und ohne Einschränkungen für alle zur Nutzung, Verbreitung und Weiterverwendung zugänglich gemacht werden</a>, um Transparenz, Innovation und Effizienz zu fördern“.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav__essen_ganz__1\">„Essen ganz transparent gemacht“</h3> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>„Das Angebot hochwertiger Lebensmittel in Deutschland ist riesig, dank der hervorragenden Arbeit unserer Landwirte, der Lebensmittelhersteller und des Handels. Daraus können sich die Verbraucherinnen und Verbraucher nach Lust und Laune bedienen – als Bundesregierung machen wir da keine Vorgaben. Wir unterstützen aber dabei, die Entscheidung für eine ausgewogene und gerne regionale Ernährung gut informiert zu treffen. Der kostenlose Zugang zum Bundeslebensmittelschlüssel hilft dabei“, sagt dazu Bundeslandwirtschaftsminister Alois Rainer (CSU).</p> <p>Auch MRI-Präsidentin Tanja Schwerdtle, begrüßt den Schritt: „Der lizenzfreie Zugang zum Bundeslebensmittelschlüssel bietet nun auch der breiten Bevölkerung die Möglichkeit, sich über die Zusammensetzung einzelner Lebensmittel zu informieren. Wer weiß, was in Lebensmitteln steckt, kann sich bewusster ernähren. Dies kann eine ausgewogene und gesunde Ernährung unterstützen.“</p> <p><em>Siehe auch:</em></p> <ul><li><a href=\"https://www.heise.de/download/product/bundeslebensmittelschluessel?wt_mc=intern.red.download.tickermeldung.ho.link.link\" rel=\"external noopener\" target=\"_blank\">Bundeslebensmittelschlüssel</a> bei heise download</li></ul> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:mack@heise.de\" title=\"Marie-Claire Koch\">mack</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11123385","title":"Marsrover Perseverance ist auf Rekordkurs","link":"https://www.heise.de/news/Marsrover-Perseverance-ist-auf-Rekordkurs-11123385.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Marsrover-Perseverance-ist-auf-Rekordkurs-11123385.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/6/4/6/000-58b19a53e3b5c12c.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Der Marsrover Perseverance ist seit fünf Jahren auf dem Mars und hat fast soviel Strecke zurückgelegt wie der Rover Opportunity. Dessen Rekord wackelt.\n</p>","date":1766440140000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Perseverance ist auf Rekordkurs: Der Marsrover ist nach Angaben der US-Raumfahrtbehörde National Aeronautics and Space Administration (NASA) auf dem besten Weg, einen Streckenrekord auf dem Mars aufzustellen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Perseverance ist vor knapp fünf Jahren, <a href=\"https://www.heise.de/news/Perseverance-landet-erfolgreich-auf-dem-Mars-5059955.html\">im Februar 2021, auf dem Mars gelandet</a>. Seither sei der Rover etwa 40 Kilometer auf dem Nachbarplaneten gefahren, <a href=\"https://www.nasa.gov/missions/mars-2020-perseverance/perseverance-rover/nasas-perseverance-mars-rover-ready-to-roll-for-miles-in-years-ahead/\" rel=\"external noopener\" target=\"_blank\">teilt die NASA mit</a>. Sie geht davon aus, dass es noch deutlich mehr werden.</p> <a-opt-in checkbox-text=\"YouTube-Video immer laden\" type=\"Youtube\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein externes YouTube-Video (Google Ireland Limited) geladen. </p> <p><label> YouTube-Video immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Google Ireland Limited) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <p>Rekordhalter ist der Rover Opportunity, der in seiner knapp 15 Jahre dauernden Mission <a href=\"https://www.heise.de/news/NASA-Rover-Opportunity-Ein-Marathon-auf-dem-Mars-2584017.html\">etwa 45 Kilometer schaffte</a>. Wenn nichts Unvorhergesehenes dazwischenkommt, wird Perseverance diesen Rekord deutlich übertreffen: Das Team geht davon aus, dass die Aktoren, die seine Räder antreiben, noch mindestens weitere 60 Kilometer schaffen werden. Das bedeutet, dass Perseverance wohl mehr als 100 Kilometer auf dem Mars zurücklegen wird.</p> <p>Perseverance hat bereits Rekorde aufgestellt: Im Juni legte es an einem einzigen Marstag knapp 412 Meter zurück. Das hat bisher kein Rover geschafft. Ende 2023 fuhr er knapp 700 Meter autonom, also ohne Kontrolle durch einen Menschen. Auch das ist eine Bestmarke.</p> <h3 id=\"nav_länger_als__0\">Länger als geplant im Einsatz</h3> <p>Wie die Vorgänger hat auch Perseverance – zu Deutsch: Ausdauer – seine geplante Missionsdauer von etwa zwei Jahren überschritten. Sein direkter Vorgänger Curiosity hat seine Mission von zwei auf inzwischen mehr als 13 Jahre ausgedehnt. Perseverance ist weitgehend baugleich mit Curiosity. Jedoch wurden einige Teile optimiert, darunter die Räder, denen das scharfkantige Marsgestein zusetzt.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Noch weiter haben die Rover Spirit und Opportunity ihre geplante Missionszeit überschritten: Die beiden im Januar 2004 gestarteten Forschungsfahrzeuge sollten jeweils 90 Tage aktiv sein. Bei Spirit wurden daraus über sechs Jahre, bei Opportunity sogar fast 15 Jahre.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>In den vergangenen zwei Jahren hat das Team die Systeme von Perseverance evaluiert und ist zu dem Schluss gekommen, dass der Rover noch mindestens bis 2031 durchhalten wird. Diese Tests hätten gezeigt, dass der Rover „in einem ausgezeichneten Zustand“ sei, sagte Steve Lee, stellvertretender Projektleiter von Perseverance, am 17. Dezember auf der Jahrestagung der American Geophysical Union. „Alle Systeme sind vollständig in der Lage, eine sehr lange Mission zu unterstützen, bei der diese faszinierende Region des Mars intensiv erforscht werden soll“.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Perseverance ist im Jezero-Krater unterwegs, einem durch einen Meteoriteneinschlag entstandenen, knapp 50 Kilometer großen Krater auf der Nordhalbkugel. In dem Krater existierten einst ein See und ein Flussdelta.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11123329","title":"Wettlauf um Quantencomputer: Europa droht den Anschluss zu verlieren","link":"https://www.heise.de/news/Wettlauf-um-Quantencomputer-Europa-droht-den-Anschluss-zu-verlieren-11123329.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Wettlauf-um-Quantencomputer-Europa-droht-den-Anschluss-zu-verlieren-11123329.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/6/1/7/shutterstock_1787263763-2589b8111a671ff2.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Quantentechnologien versprechen eine Revolution von Medizin bis Kryptografie. Die Patentzahlen steigen, doch Europa hinkt bei der Kommerzialisierung hinterher.</p>","date":1766427060000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\"> </a-collapse> <!-- RSPEAK_START --> <p>Sie klingen noch nach Science-Fiction, sind aber längst im Visier der globalen Wirtschaftsmächte und IT-Giganten: Quantencomputer, die komplexe Moleküle für neue Medikamente in Sekunden simulieren, Sensoren, die Erdbeben Wochen im Voraus spüren, und eine <a href=\"https://www.heise.de/news/Abhoersicher-Erste-quantengesicherte-Videokonferenz-zwischen-Bundesbehoerden-6159925.html\">Kommunikation, die nach den Gesetzen der Physik unknackbar ist</a>. Doch wer beherrscht diese Zukunft? Das Europäische Patentamt (EPA) und die Organisation für wirtschaftliche Zusammenarbeit und Entwicklung (OECD) haben vor wenigen Tagen in Paris eine umfassende Bestandsaufnahme vorgelegt, die Licht und Schatten für den europäischen Innovationsstandort offenbart.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die gute Nachricht: Die Forschungsaktivität ist so hoch wie nie. Die schlechte: Der Weg vom Labor in den Markt wird für europäische Akteure immer steiniger. Während die Wissenschaft glänzt, droht die wirtschaftliche Verwertung mal wieder auf halber Strecke steckenzubleiben.</p> <p>Seit 2015 haben sich <a href=\"https://link.epo.org/web/publications/studies/en-mapping-the-global-quantum-ecosystem.pdf\" rel=\"external noopener\" target=\"_blank\">laut den veröffentlichten Zahlen</a> die Patentaktivitäten im Bereich der Quantentechnologien verfünffacht. Besonders das Quanten-Computing sticht hervor – hier gibt es heute 16-mal mehr patentierte Erfindungen als noch vor neun Jahren. Damit wächst dieser Sektor deutlich schneller als viele andere Technologiefelder.</p> <p>Die OECD bestätigt den Trend: „Die Zahl der internationalen Patentfamilien im Bereich Quantentechnologie hat sich zwischen 2005 und 2024 versiebenfacht.“ Seit 2014 wachse der Bereich mit einer jährlichen Rate von rund 20 Prozent und übertreffe damit das allgemeine Wachstum über alle Technologien hinweg, das bei lediglich 2 Prozent liege.</p> <p>Deutschland, Frankreich und Großbritannien bilden dabei die europäische Speerspitze. Doch EPA-Präsident António Campinos warnt vor verfrühter Euphorie. Die EU müsse ihre Investitionen massiv steigern, um nicht dauerhaft im Schatten der USA zu landen. Während US-Giganten wie IBM, Google und Microsoft das Feld bei den Patentanmeldungen dominierten, kämpfe die europäische Startup-Szene mit einer gefährlichen Stagnation bei der Finanzierung.</p> <h3 id=\"nav_die__0\">Die „akademische Falle“</h3> <p>Ein Merkmal des Sektors ist seine Nähe zur Grundlagenforschung. Ein ungewöhnlich hoher Anteil der Patentanmeldungen – fast ein Drittel – zitiert aus wissenschaftlichen Publikationen. Das zeigt, wie tief die Technologie noch in der akademischen Welt verwurzelt ist. Laut OECD haben über 50 Prozent der Gründer im Quantenbereich einen Doktortitel, verglichen mit nur etwa 10 Prozent in anderen Branchen.</p> <p>Genau hier liegt laut OECD das Problem: Die Kommerzialisierung brauche privates Wagniskapital. Das fließe in den USA deutlich stärker als in Europa. Nach einem Höchststand im Jahr 2021 ist der Geldfluss hier zuletzt ins Stocken geraten. Die OECD spricht von einer Phase der Konsolidierung.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_neue__1\">Neue Plattformen gegen die Unsichtbarkeit</h3> <p>Um gegenzusteuern, setzt das EPA auf Transparenz und Vernetzung. Eine <a href=\"https://www.epo.org/en/searching-for-patents/technology-platforms/quantum-technologies\" rel=\"external noopener\" target=\"_blank\">neue Technologieplattform</a> soll Investoren und Forschern helfen, sich im Dschungel der über 31.000 Quanten-Erfindungen zurechtzufinden. Zudem hat die Behörde <a href=\"https://dtf.epo.org/\" rel=\"external noopener\" target=\"_blank\">ihren Deep Tech Finder aktualisiert</a>: Ein Filter ermöglicht nun gezielt, europäische Start-ups mit Quantenpatenten aufzuspüren. Damit soll die Sichtbarkeit europäischer Exzellenz erhöht und die Brücke zum Kapitalmarkt geschlagen werden.</p> <p>Die Konkurrenz schläft nicht. Über 80 Prozent der Akteure im Ökosystem sind laut der Untersuchung etablierte Unternehmen oder Forschungseinrichtungen, die ihre Position bereits festigen. Große IT-Konzerne dominieren das Feld mit ihrer schieren Masse an Patentportfolios. Ohne einen massiven Schub bei privaten Investitionen drohe der Quanten-Boom für Europa zu einer verpassten Chance zu werden, heißt es, während anderswo bereits die Rechenzentren der nächsten Generation entstünden.</p> <h3 id=\"nav_nadelöhr__2\">Nadelöhr Lieferketten und Fachkräfte</h3> <p>Technik allein wird nicht reichen. Die Forscher machen deutlich, dass auch die globalen Lieferketten für kritische Komponenten zu einem Nadelöhr werden könnten. Wer keinen Zugriff auf Ressourcen wie Industriediamanten, spezielles Aluminiumoxid oder oxometallische Salze habe, könne die Hardware der Zukunft nicht bauen. Die OECD mahnt hier zu strategischer Vorsicht: „Den krisenfesten Zugang zu Schlüsselmaterialien und Technologien sicherzustellen, ist unerlässlich, um Innovationen zu unterstützen und strategische Risiken zu mindern.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Zudem herrscht ein Ungleichgewicht auf dem Arbeitsmarkt. Während Stellen für Forschung und Informatik dominieren, machen kommerziell orientierte weniger als 10 Prozent der Stellenausschreibungen aus. Es fehlen also nicht nur Physiker, sondern auch die Köpfe, die aus der Physik ein Geschäft machen.</p> <p>Europa steht dem Bericht zufolge an einem Scheideweg. Die akademische Basis ist vorhanden, die Patentzahlen steigen, doch die Dominanz der USA und der wachsende Druck aus China und Japan sind hoch. OECD-Generalsekretär Mathias Cormann betont, dass staatliche Strategien nun über die reine Forschungsförderung hinausgehen müssen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Nötig sei es, die richtigen Bedingungen für die Skalierung dieser Technologien zu schaffen – von Investitionen und Fachkräften bis hin zu belastbaren Lieferketten. Mit einer „strategischen Quantenpolitik“ könnten Staaten dazu beitragen, den Beitrag von Durchbrüchen in diesem Sektor zu Wirtschaftswachstum und gesellschaftlichem Wohlstand zu optimieren. Die Bundesregierung <a href=\"https://www.heise.de/news/Quantentechnologien-Deutschland-soll-mit-3-Milliarden-Euro-an-die-Weltspitze-8981278.html\">beschloss 2023 ein Handlungskonzept Quantentechnologien</a>, um Deutschland mit 3 Milliarden Euro an die Weltspitze zu bringen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11122775","title":"KI simuliert Evolution: So entstehen Insekten- und Linsenaugen","link":"https://www.heise.de/news/KI-simuliert-Evolution-So-entstehen-Insekten-und-Linsenaugen-11122775.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/KI-simuliert-Evolution-So-entstehen-Insekten-und-Linsenaugen-11122775.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/3/3/5/fliege-a47662fdc994f740.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Ein Forschungsteam hat die Evolution des Auges in einer Physik-Simulation nachgebaut. Die Ergebnisse zeigen, warum die Natur so unterschiedliche Formen wählte.</p>","date":1766404020000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\"> </a-collapse> <!-- RSPEAK_START --> <p>Ein internationales Team aus Forschern des MIT, der Rice University und der Universität Lund hat die Evolution des Auges simuliert und zeigt auf, dass die Vielfalt von Augenformen in der Natur kein Zufall ist, sondern das Ergebnis von Selektion. Das Team um Kushagra Tiwary vom MIT entwickelte ein Framework namens „What if Eye…?\", das Agenten in einer 3D-Umgebung evolvieren lässt – ähnlich wie Spielfiguren in einem Videospiel, die jedoch nicht von Menschen gesteuert werden, sondern lernen und sich verändern. Dabei entstanden – ohne externe Vorgaben – sowohl die Facettenaugen von Insekten als auch die hochauflösenden Linsenaugen von Raubtieren und Menschen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p><a href=\"https://doi.org/10.1126/sciadv.ady2888\" rel=\"external noopener\" target=\"_blank\">Die Studie</a> erschien kürzlich im Fachjournal „Science Advances\"; eine <a href=\"https://arxiv.org/html/2501.15001v2\" rel=\"external noopener\" target=\"_blank\">Preprint-Fassung der Arbeit</a> ist seit Anfang des Jahres bei arXiv verfügbar.</p> <h3 id=\"nav_evolution_als__0\">Evolution als Single-Player-Game</h3> <p>Zentral an der Arbeit ist ein Framework auf Basis der sogenannten Embodied AI (verkörperte Künstliche Intelligenz). Die Forschenden modellierten ihre Agenten als Single-Player-Games mit spezifischen Spielregeln: Ein Agent erhält Belohnungspunkte für erfolgreiche Aktionen (sogenannte „Rewards\"), genau wie ein Spieler Punkte sammelt. Diese Reward-Struktur treibt die Evolution an.</p> <p>Anders als bei klassischen Computer-Vision-Modellen, die lediglich statische Bilder in Datenbanken klassifizieren, simulierten die Forschenden ganze Agenten in einer physikalisch korrekten 3D-Umgebung auf Basis der MuJoCo-Physics-Engine. Die Agenten bewegen sich durch diese Welt wie NPCs (Non-Player-Characters) in einem Videospiel – mit Sensorik, Körper und Motorik.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Dabei griffen die Wissenschaftler auf einen methodisch anspruchsvollen Mix zurück: Ein genetischer Algorithmus (CMA-ES) steuerte über hunderte von Generationen hinweg die Mutationen des „Genoms\", das sowohl die Bauform der Augen als auch die Architektur des Gehirns festlegte. Innerhalb ihrer „Lebensspanne\" trainierten die individuellen Agenten dann ihr neuronales Netz mittels Reinforcement Learning. Dieses Verfahren wird auch bei modernen Videospiel-KIs wie AlphaGo verwendet. Dabei sollten die Agenten mit der ihnen gegebenen Hardware bestmöglich zurechtkommen. Jeder löste also sein persönliches Mini-Spiel – und wer am besten spielte, durfte seine Gene weitergeben. Dieser Ansatz der Co-Evolution zwang das System dazu, Hardware und Software gleichzeitig zu optimieren – ein hochauflösendes Auge bringt schließlich keinen Vorteil, wenn das Gehirn die Datenflut nicht verarbeiten kann.</p> <p>Um zu prüfen, ob der Selektionsdruck tatsächlich die Bauform der Augen diktiert, konfrontierte das Team die Agenten mit zwei grundlegend verschiedenen Spiel-Szenarien. Im ersten Szenario war die Mission: schneller durch ein Labyrinth navigieren. Die Belohnung kam für jede Sekunde Zeit, die gespart wurde. Die Evolution brachte hier eine Lösung hervor, die stark an die Facettenaugen von Insekten erinnert. Die Agenten entwickelten ein Netzwerk aus weit verteilten, einfachen Augen, die den Kopf umrundeten. Diese Konfiguration opferte Detailschärfe zugunsten eines enormen Sichtfeldes von rund 135 Grad, um den optischen Fluss zur Hinderniserkennung zu nutzen. Wer nicht sehen konnte, was links und rechts kommt, prallte gegen die Wand und verlor Punkte.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Bei einem zweiten Spiel-Szenario mussten die Agenten ein spezifisches Zielobjekt (Nahrung) identifizieren und es erreichen, während sie täuschend ähnliche Objekte (Gift) meiden mussten. Einen Reward gab es nur für den korrekten Fund. Unter diesem Druck selektierte die Simulation gnadenlos in Richtung des „Kamera-Auges\": Die Agenten reduzierten die Anzahl der Augen, richteten sie frontal aus und erhöhten die Dichte der Photorezeptoren massiv. Das Resultat war eine Konstruktion, die funktional den Augen von Raubtieren oder Primaten gleicht. Die Simulation liefert damit den experimentellen Nachweis, dass es keine universell „beste\" Augenform gibt, sondern dass die Spiel-Anforderung – oder in der Natur: die ökologische Nische – die Architektur des Sinnesorgans bestimmt.</p> <h3 id=\"nav_linsen_als__1\">Linsen als physikalische Notwendigkeit</h3> <p>Besonders aufschlussreich ist der Teil der Studie, der sich mit der Entstehung der Linse befasst. Die Forschenden implementierten ein physikalisch korrektes Wellenmodell des Lichts – eine realistische Physics-Engine für optische Effekte. Ihre Frage: Wie „findet\" die Evolution die Lösung, wenn die Spielregeln physikalisch kompliziert sind?</p> <p>In den ersten Generationen „entdeckten\" die Agenten lediglich das Prinzip der Lochkamera: Kleinere Pupillen sorgten für schärfere Bilder. Doch diese Strategie führte schnell in eine Sackgasse – ein klassisches Game-Over-Szenario. Kleine Pupillen lassen nur wenig Licht durch, wodurch das Signal-Rausch-Verhältnis (SNR) so schlecht wurde, dass die Agenten ihre Leistung nicht mehr steigern konnten. Sie waren in einem „lokalen Optimum“ gefangen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Erst als die Simulation Mutationen zuließ, die den Brechungsindex des Materials veränderten – also die Spielregeln neuen Content hinzufügten –, brach das System aus diesem Dilemma aus. Anfangs entstanden Strukturen, die eher diffusen Klumpen glichen – gescheiterte Versuche. Doch über hunderte Generationen hinweg schliff die Selektion diese zu präzisen Linsen mit glatten Oberflächen. Dies erlaubte es den Agenten, ihre Pupillen wieder zu öffnen, um mehr Licht einzufangen, ohne dabei an Bildschärfe zu verlieren. Die Linse erscheint in der Simulation somit nicht als zufällige Laune der Natur, sondern als die eine naheliegende physikalische Lösung, um den Kompromiss zwischen Lichtempfindlichkeit und Auflösung aufzulösen. Ein brillanter Exploit der Natur.</p> <h3 id=\"nav_skalierungsgeset__2\">Skalierungsgesetze für Gehirn und Sensor</h3> <p>Bereits kleine Verbesserungen der Sehschärfe erfordern laut Analyse eine überproportional größere Menge an neuronalen Ressourcen zur Verarbeitung. Die Simulation zeigte, dass eine Verbesserung der optischen Hardware nur dann einen evolutionären Vorteil brachte, wenn gleichzeitig das neuronale Netz wuchs. Ein gutes Auge ohne schnelles Gehirn bringt keine höhere Punktzahl.</p> <p>Dieses Ergebnis deckt sich mit Beobachtungen aus der Biologie, wo Arten mit hochauflösendem Sehen – wie etwa Cephalopoden oder Vögel – im Verhältnis deutlich größere Gehirne besitzen als Organismen mit simplen Lichtsensoren wie Plattwürmer oder Quallen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:mack@heise.de\" title=\"Marie-Claire Koch\">mack</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11122879","title":"Flugtaxi der Boeing-Tochter Wisk Aero absolviert Erstflug","link":"https://www.heise.de/news/Flugtaxi-der-Boeing-Tochter-Wisk-Aero-absolviert-Erstflug-11122879.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Flugtaxi-der-Boeing-Tochter-Wisk-Aero-absolviert-Erstflug-11122879.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/3/8/8/hp-845059fe83b4e578.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Die Boeing-Tochter Wisk Aero hat ihr elektrisches Fluggerät erstmals starten lassen. Es soll künftig als autonomes Flugtaxi eingesetzt werden.</p>","date":1766401980000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Erstflug für ein unbemanntes Lufttaxi: Die Boeing-Tochter Wisk hat ihr Fluggerät der sechsten Generation erstmals aufsteigen lassen. Der Test verlief laut Hersteller erfolgreich.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Das Lufttaxi sei gestartet und geschwebt. Zudem habe es stabil Flugmanöver durchgeführt, <a href=\"https://wisk.aero/newsroom/wisk-completes-first-flight-of-generation-6-autonomous-evtol\" rel=\"external noopener\" target=\"_blank\">teilte Wisk Aero mit</a>. Das sei der Auftakt zu einem umfangreichen Testprogramm. An dessen Ende soll eine Musterzulassung für das Lufttaxi stehen.</p> <a-opt-in checkbox-text=\"YouTube-Video immer laden\" type=\"Youtube\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein externes YouTube-Video (Google Ireland Limited) geladen. </p> <p><label> YouTube-Video immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Google Ireland Limited) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <p>Das <a href=\"https://wisk.aero/aircraft\" rel=\"external noopener\" target=\"_blank\">Fluggerät</a> ist elektrisch angetrieben und startet und landet senkrecht (Electric Vertical Take-off and Landing, eVTOL). Es sieht wie ein konventionelles Flugzeug aus, mit Tragflächen, die eine Spannweite von etwa 15 Metern haben. Darin ist Platz für vier Passagiere. Ein Pilot ist nicht vorgesehen, das Flugtaxi liegt autonom und soll von einem Kontrollzentrum aus überwacht werden, wobei ein Operator bis zu drei der Fluggeräte gleichzeitig kontrollieren soll.</p> <h3 id=\"nav_sechs__0\">Sechs schwenkbare Propeller</h3> <p>Angetrieben wird es von zwölf Elektropropellern, die an den Tragflächen angebracht sind. Sechs davon haben eine vertikale Achse und sorgen für Auftrieb. Sie werden nur für den Start und die Landung benötigt. Die sechs Propeller an der Vorderseite der Tragflächen sind schwenkbar: Während des Starts und der Landung sorgen sie für Auftrieb. Für den Horizontalflug werden sie waagerecht gestellt und erzeugen Vortrieb.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Reisegeschwindigkeit beträgt 120 Knoten, also etwa 220 km/h. Die Reichweite gibt Wisk Aero mit etwa 145 Kilometern plus einer Reserve an. Die Flughöhe soll bei 2.500 Fuß (762 Meter) liegen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Das aktuelle Fluggerät stellt <a href=\"https://wisk.aero/generations\" rel=\"external noopener\" target=\"_blank\">die sechste Iterationsstufe von Wisks eVTOL</a> dar. Dieses Design soll bei der US-Luftfahrtbehörde, der Federal Aviation Association (FAA), zertifiziert werden. Mit den vorherigen Prototypen hat Wisk knapp 1800 Testflüge durchgeführt.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Wisk Aero will nach eigenen Angaben künftig Flugtaxidienste in Houston, Los Angeles und Miami anbieten.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11122572","title":"NASA und Boeing: Längere und schmalere Tragflächen sollen Flugeffizienz steigern","link":"https://www.heise.de/news/NASA-und-Boeing-testen-laengere-schmalere-Tragflaechen-fuer-effizienteres-Fliegen-11122572.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/NASA-und-Boeing-testen-laengere-schmalere-Tragflaechen-fuer-effizienteres-Fliegen-11122572.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/5/0/0/0/2/3/0/Flu__gelflatterm-57c16fd9ad0f3e1a.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Lange, schmale Tragflächen sollen bei Flugzeugen den Treibstoffverbrauch senken und den Komfort steigern. Doch dazu muss das Flügelflattern beseitigt werden.</p>","date":1766396640000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Die US-Raumfahrtbehörde NASA und der Flugzeugkonzern Boeing suchen gemeinsam nach einer Lösung, um das Fliegen mit Passagierflugzeugen effizienter und komfortabler zu gestalten. Im Rahmen des Projektes „Integrated Adaptive Wing Technology Maturation” testen sie längere, schlankere Tragflächen. Die sollen dafür sorgen, dass künftige Passagiermaschinen weniger Treibstoff verbrauchen und zugleich ruhiger fliegen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Im Rahmen der Zusammenarbeit haben die NASA und Boeing Windkanaltests an Tragflächen durchgeführt, die eine höhere Streckung aufweisen und schmaler sind. Längere und dünnere Flügel haben einen geringeren Luftwiderstand bei in etwa gleichem Auftrieb, sodass sie im Flug insgesamt effizienter sind.</p> <h3 id=\"nav_flügelflattern__0\">Flügelflattern verhindern</h3> <p>Zugleich können die schmaleren Tragflächen jedoch neue Probleme verursachen: Durch die hohe Streckung werden sie flexibler. Dadurch kann es im Flug zu größeren Bewegungen innerhalb der Tragflächenstruktur kommen. Die Tragflächen können sich etwa verformen und neigen zum berüchtigten Flügelflattern. Das Flugzeug kann so bei böigem Wind anfangen, zu vibrieren und sich zu schütteln, was zu einem unruhigeren Flug und zu Belastungen der Flugzeugzelle führt.</p> <p>„Flattern ist eine sehr heftige Wechselwirkung“, sagt Jennifer Pinkerton, Luft- und Raumfahrtingenieurin bei der NASA im Langley Research Center in Hampton, Virginia. „Wenn die Strömung über einem Flügel mit der Flugzeugstruktur in Wechselwirkung tritt und die Eigenfrequenzen des Flügels angeregt werden, werden die Flügelschwingungen verstärkt und können exponentiell anwachsen, was zu einem potenziell katastrophalen Ausfall führen kann. Ein Teil unserer Tests besteht darin, aeroelastische Instabilitäten wie Flattern für Flugzeugkonzepte zu charakterisieren, damit diese Instabilitäten im tatsächlichen Flug sicher vermieden werden können.“</p> <p>Um Flügelflattern zu minimieren, arbeiten <a href=\"https://www.heise.de/thema/NASA\">NASA</a> und Boeing daran, die Auswirkungen von Windböen auf Flugzeuge zu mindern, indem sie die Tragflächenbelastungen durch Flugzeugbewegungen verringern. Die Ingenieure nutzten für ihre Untersuchungen den Windkanal Transonic Tunnel der NASA Langley, der mit 4,87 m Höhe und gleicher Breite groß genug ist, um ein halbiertes großformatiges Passagierflugzeugmodell darin zu testen.</p> <a-opt-in checkbox-text=\"YouTube-Video immer laden\" type=\"Youtube\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein externes YouTube-Video (Google Ireland Limited) geladen. </p> <p><label> YouTube-Video immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Google Ireland Limited) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <p>Zum Einsatz kommt ein Modell mit einer etwa 3,96 m langen Tragfläche, das die NASA zusammen mit Boeing und NextGen Aeronautics entwickelt hat. Das Modell ist mit insgesamt zehn beweglichen Steuerflächen an der Hinterkante der Tragfläche ausgestattet. Damit können der Luftstrom kontrolliert und die Kräfte reduziert werden, die auf die Flügel einwirken und sie zum Vibrieren bringen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Ingenieure überwachten dabei mit Sensorik und Messinstrumenten sowohl die auf das Flugzeugmodell einwirkenden Kräfte als auch die Reaktionen des Flugzeugs. Die neue Tragfläche mit seinen zehn Steuerflächen sei nochmals ein Fortschritt gegenüber der Tragfläche, die die NASA und Boeing bereits in einer früheren Kooperation mit der Bezeichnung Subsonic Ultra Green Aircraft Research (SUGAR) entwickelt hatten. Die dabei entstandene SUGAR-Tragfläche hatte lediglich zwei aktive Steuerflächen. Die neue Konstruktion mit zehn Steuerflächen sei komplexer, würde die Steuerungsziele jedoch noch besser erreichen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Ergebnisse aus Testreihen von 2024 und 2025 sowie daraus erwachsenen Computersimulationen flossen in die Entwicklung der neuen Tragfläche mit den erweiterten Steuerungskonfigurationen ein. Die Tests zeigen, dass die Kräfte bei böigem Wind durch die zusätzlichen Steuerungsflächen verringert werden konnten und das Flattern spürbar abnahm.</p> <p>Die NASA und Boeing wollen die ermittelten Daten weiter analysieren und die Ergebnisse veröffentlichen. Diese könnten dann dazu verwendet werden, um sie in der Entwicklung der nächsten Generation von Passagierflugzeugen einzusetzen, um so deren Treibstoffverbrauch zu reduzieren und ruhiger fliegen zu lassen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:olb@heise.de\" title=\"Oliver Bünte\">olb</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11120233","title":"Die beste Wärmebildkamera im Test – gut schon ab 200 Euro","link":"https://www.heise.de/bestenlisten/testsieger/testsieger-die-beste-waermebildkamera-im-test-gut-schon-ab-200-euro/3y515sj?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p>Wärmebildkameras helfen, Wärmebrücken und versteckte Tiere aufzuspüren. Wir zeigen günstige Modelle für den Heimgebrauch.</p>","date":1766343600000,"feedTitle":"Heise Wissen"},{"id":"http://heise.de/-11111199","title":"heise-Angebot: c’t-Webinar – Wärmepumpentechnik verstehen","link":"https://www.heise.de/news/c-t-Webinar-Waermepumpentechnik-verstehen-11111199.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/c-t-Webinar-Waermepumpentechnik-verstehen-11111199.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/4/4/1/0/Waermepumpe-Ticker-Header-16-9-025dc9f4b3457090.png\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Das c’t-Webinar vermittelt das nötige Grundwissen, um die Eignung von Wärmepumpen für das eigene Haus oder die Wohnung realistisch einzuschätzen.</p>","date":1766318400000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Wärmepumpen senken den CO₂-Ausstoß im Vergleich zu herkömmlichen Heizsystemen und dämpfen steigende Heizkosten. Damit spielen sie eine zentrale Rolle in der klimafreundlichen Wärmeversorgung. Dennoch zögern viele Hausbesitzer: Lohnt sich der Einbau auch in älteren Gebäuden? Funktionieren Wärmepumpen ohne Fußbodenheizung? Und rechtfertigen die Anschaffungskosten den Nutzen?</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Im Webinar erhalten Sie eine <a href=\"https://heise-academy.de/webinare/waermepumpentechnik/?wt_mc=intern.conf.ct.web_waermepumpen.ticker-2.link.link\" rel=\"external noopener\" target=\"_blank\">herstellerunabhängige Einführung in die Wärmepumpentechnik</a>. c’t-Redakteur Georg Schnurer erklärt, wie verschiedene Wärmepumpentypen arbeiten und welche Schritte nötig sind, um ihre Eignung für das eigene Haus oder die Wohnung realistisch einzuschätzen.</p> <h3 id=\"nav_vorurteile__0\">Vorurteile unter die Lupe nehmen</h3> <p>Die Veranstaltung richtet sich an Einsteiger ohne Vorkenntnisse. Schnurer nimmt gängige Vorurteile unter die Lupe, zeigt technische Grenzen auf und erklärt, was hinter dem Schlagwort Effizienz im Zusammenhang mit Wärmepumpen steckt. Sie erfahren außerdem, wie Wärmepumpen mit Photovoltaikanlagen zusammenspielen und welche Investitionskosten Sie grob einkalkulieren sollten.</p> <p>Das Webinar ersetzt zwar keine persönliche Energieberatung, da eine fundierte Entscheidung stets eine detaillierte Gebäudeanalyse erfordert. Dennoch vermittelt das rund zweistündige Webinar Ihnen das nötige Wissen, um Angebote von Heizungsbauern besser beurteilen zu können. Im Anschluss bleibt in einer 45-minütigen Fragerunde Raum für individuelle Fragen.</p> <h3 id=\"nav_frühbucherrabatt__1\">Frühbucherrabatt sichern</h3> <p>Der Crashkurs findet am 29. Januar 2026 von 17:00 bis 20:00 Uhr online statt. Wer bereits jetzt bucht, sichert sich den Frühbucherpreis und zahlt nur 59,00 Euro. Ein aktueller Browser reicht für den Livestream aus. Weitere <a href=\"https://heise-academy.de/webinare/waermepumpentechnik/?wt_mc=intern.conf.ct.web_waermepumpen.ticker-2.link.link\" rel=\"external noopener\" target=\"_blank\">Informationen zur Veranstaltung und zur Anmeldung</a> finden Sie auf der heise-academy-Seite zum Webinar.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:abr@ct.de\" title=\"Anke Brandt\">abr</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11119795","title":"Günstige Wärmebildkamera im Test: Yourealstar YXI96 Pro","link":"https://www.heise.de/bestenlisten/testbericht/guenstige-waermebildkamera-fuer-einsteiger-ab-90-euro-yourealstar-yxi96-pro-im-test/m83d6y9?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p>Die Yourealstar YXI96 Pro ist robust und leicht zu bedienen. Damit ist sie eine günstige Wärmebildkamera für Einsteiger.</p>","date":1766242800000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div id=\"DetailExtendedWidgets1--box_middle--4\"> <p>Die Yourealstar YXI96 Pro ist robust und leicht zu bedienen. Damit ist sie eine günstige Wärmebildkamera für Einsteiger.</p><p>Mit der YXI96 Pro bietet Yourealstar ein Handheld-Gerät, das sich vorwiegend an Einsteiger richtet. Anders als kompakte Smartphone-Adapter kommt hier ein eigenständiges Gerät mit Display und Bedienelementen zum Einsatz. Die Kamera verzichtet zwar auf High-End-Technik, liefert aber solide Ergebnisse für den schnellen Check von Temperaturunterschieden im Alltag.</p><p>Die YXI96 Pro ist deutlich größer als die winzigen Adapter des Herstellers. Mit 231 × 79,2 × 84,9 Millimetern und einem Gewicht von 303 Gramm liegt sie angenehm in der Hand und erinnert eher an ein kleines Werkzeug als an ein Gadget. Das Gehäuse besteht aus Kunststoff, wirkt robust und ist für den Außeneinsatz ausreichend stabil. Die Linse ist durch eine Kunststoffabdeckung geschützt, die den empfindlichen Sensor vor Staub und Kratzern bewahrt.</p><p>Die Bedienung erfolgt direkt am Gerät, sodass keine App oder Smartphone-Verbindung erforderlich ist. Damit eignet sich die Kamera besonders für Anwender, die eine unkomplizierte Standalone-Lösung bevorzugen. Auch für Nutzer, die ungern Software von Drittanbietern installieren, ist dies ein Pluspunkt. Aktuell kostet die Wärmebildkamera bei Banggood mit dem Code <strong>BG842251 </strong>nur <a href=\"https://banggood.sjv.io/c/2403718/1107753/14074?u=https%3A%2F%2Fwww.banggood.com%2Fde%2FMUSTOOL-YXI96-YXI96Pro-Thermal-Imaging-Camera-Infrared-240%2B240-Visible-light-Resolution-96x96-Temperature-Range-20C-to-550C-TISR-Technology-Rechargeable-Battery-Photo-Video-Recording-Handheld-Thermal-Inspection-Device-p-2037120.html%3Fcur_warehouse%3DCN%26ID%3D6333809\" id=\"0fdc9d0f-9196-4aa2-9b6d-29ca2de6726e\" data-link-role-code=\"affiliate\" data-link-premium=\"affiliate_plus\">83 Euro</a>.</p><h2>Lieferumfang</h2><p>Der Lieferumfang ist spartanisch: Neben der Kamera selbst liegt nur ein USB-A-auf-USB-C-Kabel zum Laden im Karton. Immerhin lässt sich der Speicher per microSD-Karte erweitern, um Bilder und Messungen dauerhaft zu sichern. Allerdings ist sie schwer zu wechseln, da die umliegende Öffnung nur sehr klein ist. Weitere Extras oder Zubehörteile liefert der Hersteller nicht mit, was in dieser Preisklasse aber keine Seltenheit ist.</p><div id=\"slider_aa1jc477\"> <p><span>Bilderstrecke: Yourealstar YXI96 Pro </span> </p> <swiper-container init=\"false\"> <swiper-slide> <div> <p><span>Yourealstar YXI96 Pro</span></p> <p>heise bestenlisten</p> <div> <a href=\"https://ocdn.eu/pulscms/MDA_/956ebb7d7a8591892d3f8b7158b8fc4e.jpg\" target=\"_blank\" data-pswp-width=\"3000\" data-pswp-height=\"2000\"> <picture><img src=\"https://bestenliste-assets.heise.de/1/IGrk9lBaHR0cHM6Ly9vY2RuLmV1L3B1bHNjbXMvTURBXy85NTZlYmI3ZDdhODU5MTg5MmQzZjhiNzE1OGI4ZmM0ZS5qcGeRkwXNAzfNAiTeAAGhMQQ\" alt=\"Yourealstar YXI96 Pro\" transform=\"resizeCropAuto\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" width=\"823\" height=\"548\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></picture> </a> </div> </div> </swiper-slide><swiper-slide> <div> <p><span>Yourealstar YXI96 Pro</span></p> <p>heise bestenlisten</p> <div> <a href=\"https://ocdn.eu/pulscms/MDA_/82805ef8ef2c1f3d49a5a77925797f38.jpg\" target=\"_blank\" data-pswp-width=\"3000\" data-pswp-height=\"2000\"> <picture><img src=\"https://bestenliste-assets.heise.de/1/1oTk9lBaHR0cHM6Ly9vY2RuLmV1L3B1bHNjbXMvTURBXy84MjgwNWVmOGVmMmMxZjNkNDlhNWE3NzkyNTc5N2YzOC5qcGeRkwXNAzfNAiTeAAGhMQQ\" alt=\"Yourealstar YXI96 Pro\" transform=\"resizeCropAuto\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" width=\"823\" height=\"548\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></picture> </a> </div> </div> </swiper-slide><swiper-slide> <div> <p><span>Yourealstar YXI96 Pro</span></p> <p>heise bestenlisten</p> <div> <a href=\"https://ocdn.eu/pulscms/MDA_/d2c8ffa22e8bf312236f937b45a6b877.jpg\" target=\"_blank\" data-pswp-width=\"3000\" data-pswp-height=\"2000\"> <picture><img src=\"https://bestenliste-assets.heise.de/1/5UTk9lBaHR0cHM6Ly9vY2RuLmV1L3B1bHNjbXMvTURBXy9kMmM4ZmZhMjJlOGJmMzEyMjM2ZjkzN2I0NWE2Yjg3Ny5qcGeRkwXNAzfNAiTeAAGhMQQ\" alt=\"Yourealstar YXI96 Pro\" transform=\"resizeCropAuto\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" width=\"823\" height=\"548\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></picture> </a> </div> </div> </swiper-slide><swiper-slide> <div> <p><span>Yourealstar YXI96 Pro</span></p> <p>heise bestenlisten</p> <div> <a href=\"https://ocdn.eu/pulscms/MDA_/3971dad29c7c046650e93783560f31b4.jpg\" target=\"_blank\" data-pswp-width=\"3000\" data-pswp-height=\"2000\"> <picture><img src=\"https://bestenliste-assets.heise.de/1/JDSk9lBaHR0cHM6Ly9vY2RuLmV1L3B1bHNjbXMvTURBXy8zOTcxZGFkMjljN2MwNDY2NTBlOTM3ODM1NjBmMzFiNC5qcGeRkwXNAzfNAiTeAAGhMQQ\" alt=\"Yourealstar YXI96 Pro\" transform=\"resizeCropAuto\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" width=\"823\" height=\"548\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></picture> </a> </div> </div> </swiper-slide> </swiper-container> </div><h2>Display &amp; Bedienung</h2><p>Das 2,4-Zoll-Display löst mit 240 × 240 Pixeln auf und zeigt das Wärmebild in Farbe an. Für Innenräume ist es ausreichend hell. Die Menüführung ist einfach gehalten und beschränkt sich auf das Wesentliche. Mit wenigen Tasten navigieren Nutzer durch die Menüs, wechseln Farbprofile oder aktivieren die Taschenlampe. Die Kamera ist damit auch für Einsteiger ohne Vorkenntnisse schnell verständlich.</p><p>Eine App-Anbindung gibt es nicht – was den Funktionsumfang zwar einschränkt, gleichzeitig aber die Nutzung unkompliziert macht, da keine zusätzliche Installation notwendig ist. Wer einfach nur ein Gerät einschalten und sofort Ergebnisse sehen möchte, dürfte die YXI96 Pro als angenehm unkompliziert empfinden.</p><h2>Funktionen &amp; Bildqualität</h2><div> <a href=\"https://ocdn.eu/pulscms/MDA_/e358744d46fd51b5445a7de724503dce.jpg\" target=\"_blank\" data-pswp-src=\"https://ocdn.eu/pulscms/MDA_/e358744d46fd51b5445a7de724503dce.jpg\" data-pswp-width=\"240\" data-pswp-height=\"320\"> <picture><img src=\"https://bestenliste-assets.heise.de/1/gKRk9lBaHR0cHM6Ly9vY2RuLmV1L3B1bHNjbXMvTURBXy9lMzU4NzQ0ZDQ2ZmQ1MWI1NDQ1YTdkZTcyNDUwM2RjZS5qcGeRkwXM8M0BQN4AAaExBA\" alt=\"Testaufnahmen Yourealstar YXI96 Pro\" transform=\"resizeCropAuto\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" width=\"240\" height=\"320\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"></picture> </a> <p><span>Testaufnahmen Yourealstar YXI96 Pro</span> <span>heise bestenlisten</span> </p> </div><p>Der verbaute Infrarotsensor löst mit 96 × 96 Pixeln auf – ein klarer Einsteigerwert, der für grundlegende Temperaturkontrollen im Nahbereich jedoch ausreicht. Der Temperaturbereich reicht von –20 °C bis 550 °C, sodass die Kamera sowohl für den Haushalt als auch für technische Anwendungen im Handwerk nutzbar ist.</p><p>Die thermische Empfindlichkeit von ≤ 60 mK ist solide und erlaubt die Darstellung von gängigen Temperaturunterschieden, wenn auch weniger präzise als bei höherwertigen Modellen. Zur Auswahl stehen fünf Farbprofile, mit denen sich die Temperaturdifferenzen optisch hervorheben lassen. Eine kleine Taschenlampe ist integriert und erweist sich bei Einsätzen in schlecht beleuchteten Räumen als nützliches Extra.</p><p>Für einfache visuelle Checks reicht die Auflösung aus, allerdings sind die Grenzen schnell erreicht: Feine Risse in der Dämmung oder kleine Kabelbrüche lassen sich nicht zuverlässig erkennen. Auf größere Distanzen verliert das Bild zudem stark an Schärfe, sodass die Kamera wirklich für den Nahbereich gedacht ist.</p><h2>Praxistest</h2><p>In der Praxis eignet sich die YXI96 Pro gut für einfache Checks im Haushalt: Ist ein Heizkörper gleichmäßig warm? Entweicht die Wärme durch ein Fenster? Wird ein Ladegerät übermäßig heiß? Solche Fragen beantwortet die Kamera zuverlässig.</p><p>Dank der eigenständigen Bauweise braucht es kein Smartphone, keine App und keine Internetverbindung – ein klarer Vorteil für Nutzer, die ein unkompliziertes Gerät suchen. Einschränkungen zeigen sich bei der Bildschärfe: Mit 96 × 96 Pixeln ist die Detailgenauigkeit sehr gering, kleine Objekte oder feine Strukturen lassen sich kaum unterscheiden. Für präzisere Messungen oder professionelle Anwendungen ist die Kamera daher nicht geeignet.</p><p>Im Alltag überzeugte die einfache Bedienung: einschalten, Motiv anvisieren, Farbprofil wählen und messen. Gerade für Gelegenheitsnutzer, die schnell eine grobe Einschätzung benötigen, ist dieser unkomplizierte Workflow angenehm. Wer dagegen regelmäßig arbeiten möchte, etwa im Handwerk oder in der Gebäudediagnose, wird die Limitierungen sehr schnell bemerken.</p><h2>Technische Daten</h2><table><tbody><tr><th>IR-Auflösung</th><td>256 × 192 Pixel</td></tr><tr><th>Messgenauigkeit (PCB)</th><td>±2&nbsp;°C</td></tr><tr><th>Bildwiederholrate</th><td>25 Hz</td></tr><tr><th>FOV</th><td>50° x 37.2°</td></tr><tr><th>NETD</th><td>≤40mK</td></tr><tr><th>Messbereich</th><td>-20 ℃ bis 550 ℃</td></tr><tr><th>Produktgröße</th><td>35,3 × 26 × 19,2 mm</td></tr><tr><th>Produktgewicht</th><td>15,6 g</td></tr><tr><th>Wasserdichtigkeit</th><td>keine</td></tr></tbody></table><h2>Preis</h2><p>Regulär kostet die Yourealstar YXI96 Wärmebildkamera knapp 100 Euro. Aktuell ist das Modell etwa bei Banggood mit dem Code <strong>BG842251 </strong>auf <a href=\"https://banggood.sjv.io/c/2403718/1107753/14074?u=https%3A%2F%2Fwww.banggood.com%2Fde%2FMUSTOOL-YXI96-YXI96Pro-Thermal-Imaging-Camera-Infrared-240%2B240-Visible-light-Resolution-96x96-Temperature-Range-20C-to-550C-TISR-Technology-Rechargeable-Battery-Photo-Video-Recording-Handheld-Thermal-Inspection-Device-p-2037120.html%3Fcur_warehouse%3DCN%26ID%3D6333809\" id=\"9a417e4d-9752-426f-b68b-8fa73b7c113a\" data-link-role-code=\"affiliate\" data-link-premium=\"affiliate_plus\">83 Euro</a> reduziert (inklusive Versandgebühren).</p><p><em>Hinweis: Beim Kauf in China-Shops gilt kein EU-Käuferschutz. Es drohen lange Lieferzeiten, zusätzliche Zoll- und Steuerkosten sowie Probleme bei Garantie und Rückgabe. Bei sicherheitsrelevanten Produkten besteht zudem das Risiko, dass sie nicht europäischen Standards entsprechen.</em></p><h2>Fazit</h2><p>Die Yourealstar YXI96 Pro ist eine einfache und robuste Wärmebildkamera für Einsteiger, die mit eigenem Display und intuitiver Bedienung punktet. Sie ist leicht zu handhaben, sofort einsatzbereit und deckt mit –20 °C bis 550 °C einen breiten Temperaturbereich ab. Die Erweiterung per SD-Karte und die integrierte Taschenlampe erhöhen die Praxistauglichkeit.</p><p>Auf der anderen Seite sind die Auflösung von 96 × 96 Pixeln und die Empfindlichkeit von ≤ 60 mK klar begrenzend. Für schnelle Kontrollen im Haushalt oder gelegentliche Hobbyanwendungen ist die Kamera vollkommen ausreichend. Wer jedoch detailliertere Wärmebilder benötigt, sollte zu einem höher auflösenden Modell greifen.</p><p>Insgesamt ist die YXI96 Pro ein Gerät, das primär durch seine Schlichtheit und sofortige Einsatzbereitschaft überzeugt. Für den Einstieg in die Welt der Thermografie ist sie brauchbar, für ambitionierte Nutzer jedoch eher ein Zwischenschritt. Wer einmal die Möglichkeiten höher auflösender Geräte kennengelernt hat, wird den Mehrwert schnell zu schätzen wissen.</p> </div></div>"},{"id":"http://heise.de/-11122064","title":"Trump legt Mondlandung per Dekret fest","link":"https://www.heise.de/news/Trump-legt-Mondlandung-per-Dekret-fest-11122064.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Trump-legt-Mondlandung-per-Dekret-fest-11122064.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/9/6/7/Artemis-1-702cbc90763c2067.png\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Mit der Mission Artemis 3 wollen die USA wieder Astronauten auf den Mond bringen. Das hat US-Präsident Trump jetzt auch schriftlich festgelegt.</p>","date":1766234100000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>US-Präsident Donald Trump hat per Dekret die Raumfahrt-Prioritäten seiner Regierung festgesetzt. Demnach sollen unter anderem bis 2028 wieder US-Amerikaner auf dem Mond landen, danach soll ein dauerhafter Außenposten auf dem Himmelskörper etabliert werden, wie es in dem Dokument mit dem Titel „Sicherstellen der amerikanischen Überlegenheit im All“ heißt. Außerdem müssten die amerikanischen Verteidigungskapazitäten im All gestärkt werden.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die nun <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/ensuring-american-space-superiority/\" rel=\"external noopener\" target=\"_blank\">offiziell festgelegten Ziele</a> unterscheiden sich allerdings nicht substanziell von den bisher formulierten, die teilweise auch noch aus der ersten Amtszeit von Trump zwischen 2017 und 2021 stammen. So plant die US-Raumfahrtbehörde Nasa – <a href=\"https://www.heise.de/news/Musk-Favorit-Jared-Isaacman-vom-US-Senat-als-kommender-NASA-Chef-bestaetigt-11119035.html\">seit dieser Woche offiziell geleitet</a> von dem von Trump vorgeschlagenen Milliardär und Weltraum-Touristen Jared Isaacman – schon seit 2017 mit dem Artemis-Programm die Rückkehr von US-Astronauten zum Mond.</p> <h3 id=\"nav_mondbasis_für__0\">Mondbasis für Mars-Missionen</h3> <p>Die einzelnen Teilschritte mussten allerdings <a href=\"https://www.heise.de/news/Artemis-Programm-der-NASA-Mondfluege-verschieben-sich-um-mindestens-ein-Jahr-9592570.html\">immer wieder verschoben werden</a>. Derzeit ist die Artemis 3-Mission, mit der nach mehr als einem halben Jahrhundert wieder US-Astronauten auf dem Mond landen sollen, für 2027 geplant. Auch das könnte sich allerdings noch verzögern. Das Dekret fordert nach einer Landung auch die Errichtung von ersten Teilen einer dauerhaften Mondbasis bis zum Jahr 2030. Sie soll dann unter anderem für Missionen zum Mars dienen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>An dem Artemis-Programm ist auch die europäische Raumfahrtbehörde ESA beteiligt. Vorgesehen sind bisher drei Teilnahmen von ESA-Astronauten an den Missionen. Erst kürzlich hatte die ESA bekannt gegeben, dass ein Deutscher <a href=\"https://www.heise.de/news/Esa-Chef-Ein-Deutscher-koennte-der-erste-Europaeer-auf-dem-Mond-sein-11095330.html\">im Rahmen von Artemis der erste Europäer sein könnte</a>, der einen Fuß auf den Mond setzt. Bis es so weit ist, sind jedoch noch andere Missionen des Programms geplant, die den Mond nur erreichen oder ihn umrunden sollen, ohne zu landen. Der erste, noch unbemannte, Artemis-Flug <a href=\"https://www.heise.de/news/Erste-Analysen-NASA-Mondmission-Artemis-1-hat-aussergewoehnlich-gut-geklappt-7475115.html\">klappte 2022 sehr erfolgreich</a>.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:nie@heise.de\" title=\"Nico Ernst\">nie</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11121722","title":"Hubble erfasst Kollision von zwei Himmelskörpern in relativ nahem Sternsystem","link":"https://www.heise.de/news/Hubble-erfasst-Kollision-von-zwei-Himmelskoerpern-in-relativ-nahem-Sternsystem-11121722.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Hubble-erfasst-Kollision-von-zwei-Himmelskoerpern-in-relativ-nahem-Sternsystem-11121722.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/7/9/4/hp-2a88f5bdc6acf199.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Das Weltraumteleskop Hubble hat in einem benachbarten Sternensystem Lichtpunkt entdeckt. Es sind mutmaßlich Trümmerwolken aus der Kollision von Himmelskörpern.</p>","date":1766156460000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Das Weltraumteleskop Hubble hat mutmaßlich den Zusammenprall zweier Himmelskörper im System des Sterns Fomalhaut detektiert – und das schon zum zweiten Mal in zwei Jahrzehnten. Wissenschaftler glaubten bisher, dass solche Ereignisse deutlich seltener stattfinden.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Fomalhaut ist ein Stern im Sternbild Piscis Austrinus oder Südlicher Fisch und einer der hellsten Sterne am Himmel. Der nur etwa 25 Lichtjahre entfernte Stern ist mit 440 Millionen Jahren noch vergleichsweise jung – die Sonne ist etwa 4,57 Milliarden Jahr alt. Fomalhaut gehört mit zwei Zwergsternen einem Dreifachsystem an, das von Staubringen umgeben ist, in denen Planeten entstehen.</p> <p>2004 und 2006 entdeckten Astronomen ein Objekt in einem dieser Gürtel, das sie für einen Exoplaneten hielten und das sie als Fomalhaut B bezeichneten. 2023 wollten sie den Planeten erneut mit dem Hubble-Teleskop betrachten, stellten aber fest, dass er nicht dort war, wo sie ihn erwarteten.</p> <p>Sie fanden aber einen Lichtpunkt an einer anderen Stelle, nahe der ersten. Beim Vergleich der Bilder habe sich jedoch gezeigt, dass die beiden Lichtpunkte nicht aus derselben Quellen stammen konnten, <a href=\"https://news.northwestern.edu/stories/2025/12/cosmic-crash-caught-on-camera\">sagte Jason Wang</a> von der Northwestern University. Sie haben Fomalhaut b umbenannt in Fomalhaut Circumstellar Source 1 (CS1), der zweite Lichtpunkt hat die Bezeichnung Fomalhaut CS2 bekommen.</p> <h3 id=\"nav_kollision_von__0\">Kollision von Planetesimalen</h3> <p>Die Forscher erklären das Auftreten und das Verschwinden der Lichtpunkte als Trümmerwolken, die durch die Kollision von Planetesimale, also Bausteinen von Planeten, entstanden. Aus der Helligkeit der Lichtpunkte CS1 und CS2 schlossen sie, dass die kollidierten Objekte selbst um die 60 Kilometer groß gewesen sein müssen – und damit zu klein, um selbst auf den Bildern des Weltraumteleskops sichtbar zu sein. Die sich ausbreitenden Trümmerwolken hingegen werden vom Zentralgestirn angeleuchtet.</p> <p>„Eine neue Lichtquelle im Staubgürtel, um einen Stern zu entdecken, hat uns überrascht. Das hatten wir nicht erwartet“, sagte Wang. „Unsere Hypothese ist, dass wir innerhalb von zwei Jahrzehnten zwei Kollisionen von Planetesimalen – kleinen Gesteinsobjekten, ähnlich wie Asteroiden – beobachtet haben. Kollisionen von Planetesimalen sind sehr seltene Ereignisse, und das ist das erste Mal, dass wir eine außerhalb unseres Sonnensystems gesehen haben.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Forscher waren zudem erstaunt, dass sie in etwa 20 Jahren gleich zwei solcher Kollisionen beobachtet haben: „Laut der Theorie sollte eine solche Kollision einmal in 100.000 Jahren oder noch seltener auftreten“, sagte Paul Kalas, Astronom an der University of California in Berkeley und Erstautor der Studie <a href=\"https://www.science.org/doi/10.1126/science.adu6266\" rel=\"external noopener\" target=\"_blank\">in der Fachzeitschrift Science</a>. Die zwei Sichtungen in 20 Jahren könnten seiner Ansicht nach Zufall gewesen sein, oder die theoretischen Modelle müssten angepasst werden.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Forscher wollen das Fomalhaut-System künftig mit dem James-Webb-Weltraumteleskop betrachten und erhoffen sich davon neue Erkenntnisse über CS 2 sowie über die Beschaffenheit der kollidierten Planetesimalen – und möglicherweise auch, neue Kollisionen zu beobachten.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11117168","title":"KI-Update Deep-Dive: Wie wir in den Redaktionen KI einsetzen","link":"https://www.heise.de/news/KI-Update-Deep-Dive-Wie-wir-in-den-Redaktionen-KI-einsetzen-11117168.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/KI-Update-Deep-Dive-Wie-wir-in-den-Redaktionen-KI-einsetzen-11117168.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/7/4/5/2/KIupdate_Titel_122023-0953f976150f021c.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Von der automatischen Transkription bis zur Bildgenerierung – KI-Werkzeuge sind in den heise-Redaktionen angekommen. Aber es bleibt alles in menschlicher Hand.</p>","date":1766152800000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\"> </a-collapse> <!-- RSPEAK_START --> <h3 id=\"nav_veränderungen__0\">Veränderungen durch KI im Alltag und in der Arbeit</h3> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Deepfakes, Fakenews, Faktenchecks… Das Nachrichtengeschäft ist nicht unbedingt leichter geworden durch generative Künstliche Intelligenz. Auch wir bei heise online, der c’t, der mac&amp;i, iX oder der Make müssen uns gegen die Flut aus KI-generierten Falschmeldungen stemmen. KI-Zusammenfassungen der Chatbots machen den Verlagen das Leben nicht einfacher. Aber es gibt auch viele Stellen, an denen KI uns sehr wohl sehr gut im Arbeitsalltag helfen kann.</p> <!-- RSPEAK_STOP --> <figure> <p><a href=\"https://heise.de/-9719449\" rel=\"external\" target=\"_blank\" title=\"[Link auf https://heise.de/-9719449]\"> <img alt=\"Eigenwerbung Fachdienst heise KI PRO\" decoding=\"async\" height=\"200\" loading=\"lazy\" onload=\"this.style=null;\" sizes=\"\" src=\"https://heise.cloudimg.io/width/200/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/9/9/7/4/5/2/24_DF_Button_Gewinner-bester-Podcast_klein-d14c565ebc48f4ae.jpg\" width=\"200\" data-old-src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E\" style=\"max-width: 100%; height: auto; max-height: 300px; object-fit: contain; border-radius: 6px; margin: 10px 0;\"> </a> </p> </figure> <!-- RSPEAK_START --> <p>Im letzten Deep-Dive des Jahres sind die Chefredakteure von heise medien, Volker Zota und Torsten Beeck, zu Gast im Podcast. Wir sprechen über die Entwicklungen der letzten Monate und die Vor- und Nachteile von KI. Mit dem Transkript dieser Podcastfolge wollen wir auch die Fragen unserer Leserinnen und Leser beantworten. Denn ob wir heutzutage noch eine Nachricht glauben, hat immer mehr damit zu tun, ob wir der Quelle vertrauen. Und nur durch Transparenz können wir das Vertrauen in unseren Journalismus erhalten. In diesem Sinne ist dies das vollständige Transkript des Interviews. Es wurde im Sinne der besseren Lesbarkeit editiert:</p> <p><strong>Isabel Grünewald</strong>: Hallo Torsten, schön, dass du da bist.</p> <p><strong>Torsten Beeck</strong>: Hi.</p> <p><strong>Isabel</strong>: Und hallo Volker.</p> <p><strong>Volker Zota</strong>: Hallo Isabel.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p><strong>Isabel</strong>: Die c’t gibt es seit mehr als 40 Jahren und seit 1983 hat sich sehr viel verändert, immer mal wieder in der Medienlandschaft. Aber wahrscheinlich nie so schnell und wahrscheinlich auch nie so tiefgreifend wie in den letzten drei Jahren. Torsten, welche Veränderungen hast du denn durch generative KI beobachtet?</p> <p><strong>Torsten</strong>: Ich bin ja erstmal auch Internetnutzer. Und was ich sehe, es gibt immer mehr AI-Slop, also Inhalte, die von KI erzeugt werden. Und ich glaube, so in der Anfangszeit, wo generative KI breit verfügbar wurde, gab es viel eher, ich würde sagen, so Dinge, die Spaß machen, einfach auch Quatsch, lustige Videos, Pinguine auf Trampolinen, solche Dinge. Was man aber natürlich auch sieht, KI übernimmt so ein bisschen die Sprache. Also wer sich auf LinkedIn bewegt, merkt, irgendwie klingt das alles sehr generisch. KI erzeugt inzwischen, glaube ich, über 50 Prozent der Inhalte im Internet. Das ist erstmal interessant, nehme ich erstmal so zur Kenntnis. Unsere Arbeit hat sich sicherlich auch in den letzten drei Jahren verändert. Wenn man recherchieren will und große Datenmengen bearbeiten will, hilft KI da einzusteigen. KI hilft dabei, Qualitätssicherung zu machen, also einfach mal zu checken, sind da Rechtschreibfehler in dem Text? Das geht alles sehr viel schneller als früher. Sie bietet die Möglichkeit, Datenanalysen zu machen. Also es ist eine ganze Menge. Da können wir gleich vielleicht auch nochmal ein bisschen tiefer einsteigen. Aber auf jeden Fall merkt man es an jeder Stelle. Und man merkt es auch im Alltag. Menschen sprechen mit KI irgendwie an der U-Bahn-Station, Schüler nutzen KI zum Hausaufgabenmachen. Also da ist wirklich, wirklich viel passiert.</p> <p><strong>Isabel</strong>: Volker, was war denn bei dir so der Auslöser, dich mit KI speziell im Newsroom oder in den Magazinen zu beschäftigen? War das eher der technologische Druck, dem man nicht ausweichen kann, ein ökonomischer Druck oder in erster Linie redaktionelle Neugier?</p> <p><strong>Volker</strong>: Oh Gott, ich glaube, von allem ein bisschen. Was ich sehr spannend fand, war am Anfang, was Torsten ja auch gerade schon mal angerissen hat, dass man natürlich viel rumgespielt hat. Ganz zuerst waren die Bildgeneratoren super spannend. Die waren zwar da schon ein Wow-Effekt, so was hat man halt in der Zeit noch nicht gesehen gehabt, dass man so schnell so Bilder erzeugen konnte. Das hat sich aber auch in den letzten drei Jahren wahnsinnig weiterentwickelt. Aber ich glaube, was ich besonders spannend fand, war halt eben zu schauen, was könnte da ein Hilfsmittel für uns sein. Zum Beispiel haben wir eine ganze Zeit lang sehr wenig Interviews geführt, weil das immer sehr aufwendig war, die zu transkribieren, und das hat sich halt komplett verändert. Es ist viel schneller geworden, man kann in ein paar Minuten die Sachen transkribieren, die Fehler rausmachen, schon mal was zur Freigabe schicken, ist das jetzt alles noch so, wolltest du das wirklich so gesagt haben, und dann ist man halt bei sowas viel schneller, sodass wir halt viel, viel mehr Interviews in den letzten Jahren haben, seitdem es eben so etwas z.B. so etwas wie Whisper von OpenAI gibt. Und das finde ich halt super spannend. Aber natürlich ist es so, dass ich im Prinzip seit, naja, jetzt ziemlich genau fast drei Jahren hier durch die Gegend gelaufen bin und gesagt habe, Leute, da kommt was auf uns zu. Das kam dann doch nicht ganz so schnell direkt bei uns an, zumindest, weil schon sehr früh angekündigt wurde, oder die Befürchtung war, was ist denn, wenn jetzt Suchmaschinen Antwortmaschinen werden? Und da dachten wir, naja, guck mal, passiert alles nicht so schnell. Und dann kam es jetzt dieses Jahr doch sehr, nicht überraschend, aber dann doch jetzt mit ziemlicher Wucht auf einen zu, weil Google insbesondere sich durchgerungen hat, eben da deutlich Veränderungen vorzunehmen. Aber ansonsten ist uns klar, dass wir gegen diesen, wie Torsten es ja auch nochmal schön gesagt hat, AI-Slop ankämpfen müssen. Nicht unbedingt, weil das schlecht ist, was da alles drin steht, ist nicht alles Quatsch, nur die Herausforderung ist eben, die Spreu vom Weizen zu trennen und noch zu erkennen, wo haben eigentlich Leute was gemacht, wo steckt jemand dahinter, der eine eigene Meinung hat oder ist es die Meinung der KI. Das ist leider mitunter gar nicht so einfach zu unterscheiden.</p> <h3 id=\"nav_ki_werkzeuge_im__1\">KI-Werkzeuge im Redaktionsalltag</h3> <p><strong>Isabel</strong>: Werden wir mal konkret. Das findet wahrscheinlich auch unser Publikum am interessantesten. Und wir tun jetzt einfach mal so, als würde ich nicht in der Redaktion arbeiten und gar nichts darüber wissen, was für Tools wir einsetzen. Torsten, wie nutzt du denn zurzeit KI im Arbeitsalltag?</p> <p><strong>Torsten</strong>: Ich ganz persönlich nutze sie vor allen Dingen, also ich habe am Montag eine Präsentation gemacht. Die besteht aus einem Konzept, das hat ungefähr 60 Seiten. Daraus ist diese Präsentation entstanden. Und wir haben einfach, um in diese Präsentation einzusteigen, die Präsentation selbst und das Konzept, also die 60 Seiten, in NotebookLM von Google geschmissen. Und daraus ist ein Video entstanden, das in 6 Minuten 60 Seiten, relativ komplexe Präsentationen, in ein ganz gutes Erklärvideo verwandelt. Mit kleinen Fehlern, mit kleinen, sagen wir mal, auch Merkwürdigkeiten, aber so, dass man in sechs Minuten ganz gut versteht, worum es in diesem doch recht aufwendigen Konzept geht. Also für solche Dinge kann man KI benutzen. Ansonsten natürlich die Möglichkeit, sich komplexe Themen zusammenfassen zu lassen, auch vielleicht mal schnell etwas zu beantworten oder Daten zu strukturieren. Was mir wirklich so im Alltag hilft, ist, einfach Geschwindigkeit zu gewinnen, also schnell zehn Gedanken in Spiegelstrichen zusammenzuhacken und daraus entsteht eine vernünftig lesbare E-Mail, die man auch in eine Runde schicken kann. Also überall da, wo es mir hilft, meine Gedanken irgendwie zu strukturieren und daraus irgendwas zu machen, was ich mit jemandem teilen kann, nutze ich KI quasi täglich.</p> <p><strong>Isabel</strong>: Und in welchen Phasen des redaktionellen Prozesses kommt KI bei uns bei heise zum Einsatz, Volker?</p> <p><strong>Volker</strong>: Also, wie gesagt, ich hatte ja schon angesprochen, das Thema Transkription, also da auf jeden Fall. Wir nutzen auch Language Tools zum Beispiel, um Rechtschreib- und Grammatikkontrolle zu machen. Momentan noch, ich bin nicht sicher, ob das noch Zukunft hat, so ein separates Tool, weil die LLMs da inzwischen sehr, sehr gut sind und ähnlich eingesetzt werden können. Also, da verwenden wir es. Wir verwenden auch LLMs, um zum Beispiel Artikel deutlich schneller ins CMS (Content Management System von heise online, Anm. d. Red.) zu bekommen. Und zwar, indem man ein, sag ich mal, nur rohformatiertes Manuskript hat, von einem Autor oder eine Agenturmeldung oder irgend so etwas. Und das ist normalerweise eine Klickarbeit für die Redaktion, diese Sachen dann ins CMS zu bekommen. Und da hat ein Kollege was gebastelt, mit dem das sehr, sehr einfach geht. Da wirft man diesen Text rein, man klickt nur einmal und dann wird das Ganze im CMS ausgefüllt, inklusive so Metadaten, die sozusagen vorbelegt werden, damit der Redakteur oder die Redakteurin dann schauen kann, ist das alles so richtig, Titelvorschläge und sowas werden gemacht, weil man da manchmal so ein bisschen ideenlos ist. Die Idee dabei ist natürlich, die nicht einfach stehen zu lassen, sondern dass die Leute dann gucken und wie gesagt, es geht dabei ohnehin um Autorenmanuskripte, also vorhandene Inhalte, die wir haben in unser Content-Management-System bekommen. Also da wird das sehr, sehr gerne genutzt. Wir nutzen das fürs Fact-Checking, denkt man ja manchmal erst mal nicht, man denkt ja immer, KIs halluzinieren, aber nur, wenn man sie, ich sage so gerne, wenn man sie falsch hält, dann passiert das. Tatsächlich geht es mit den Recherche-Prompts, die man so bauen kann, inzwischen sehr, sehr gut, eben auch Fakten zu checken, sodass man halt im Prinzip schauen kann, dass man, bevor man einem menschlichen Gegenleser oder einer fachkundigen Kollegin oder Kollegen etwas gibt, schon mal grobe Fehler rausnehmen kann, die einem selber nicht aufgefallen sind. Und man stellt immer wieder fest, wenn man so eine KI drüber laufen lässt, man hat doch immer Fehler gemacht. Also für solche Dinge unter anderem wird es genutzt. Und natürlich benutzen wir es für Bilderzeugung, weil wir halt viel mehr Inhalte produzieren als früher und da auch Bilder brauchen. Wobei wir gesagt haben, im nachrichtlichen Bereich wollen wir das nicht. Aber wenn es sozusagen um Ratgebertexte und andere Themen geht, wo es nicht um Produkte geht, die man fotografieren müsste, oder wo Menschen darauf vorkommen können, die irgendwie im realen Leben eine Relevanz haben, dann machen wir das auch mit KI-Aufmachern. Wo dann unsere Grafiker natürlich nicht nur einfach einen Prompt reinwerfen, sondern danach noch deutlich weiter bearbeiten.</p> <p><strong>Torsten</strong>: Ich glaube, was tatsächlich ganz wichtig dabei ist, wir nutzen KI, um bessere Texte zu produzieren. Wir nutzen KI aber nicht, um Texte zu produzieren. Ich glaube, das ist so genau die Grenze, an der wir dann halt sagen, wir wollen das als Hilfsmittel und als Werkzeug da einsetzen, wo es uns letztendlich auch oft lästige Aufgaben abnimmt. Also das, was Volker gerade erzählt hat, das ist nicht vergnügungssteuerpflichtig, alle Felder in dem Content-Management-System auszufüllen. Es macht viel mehr Spaß, zu recherchieren, einen guten Text zu schreiben und sich darauf zu konzentrieren. Und diese Aufgaben loszuwerden, ist etwas, was einfach, ja, das ist wirklich was, das hilft uns.</p> <!-- RSPEAK_STOP --> <a-collapse media=\"(min-width: 993px)\" sneak-peek=\"\" toggle-class-on-media=\"a-box--full-bordered\"> </a-collapse> <!-- RSPEAK_START --> <a-opt-in checkbox-text=\"Podcasts immer laden\" type=\"Podigee\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein externer Podcast (Podigee GmbH) geladen. </p> <p><label> Podcasts immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Podigee GmbH) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <h3 id=\"nav_das_hauseigene__2\">Das hauseigene KI-Tool als strategische Entscheidung</h3> <p><strong>Isabel</strong>: Jetzt haben wir bei Heise auch ein eigenes Tool, über das wir auch auf verschiedene Sprachmodelle Zugriff haben. Warum haben wir uns gerade auch für die Redaktion für ein eigenes Tool entschieden und nicht einfach gesagt, wir nehmen halt dieses bestimmte Sprachmodell X?</p> <p><strong>Torsten</strong>: Also das ist vor allen Dingen eine Frage von Kontrolle. Man kommt ganz schnell an Grenzen von Datenschutz, von wer hat eigentlich Zugriff auf diese Informationen. Wir als Redaktion haben ein erhöhtes Bedürfnis daran, dass bestimmte Informationen nicht einfach irgendwie als Trainingsdaten verwendet werden. Also erstmal so dieses Kontrollthema. Dann ist es auch etwas, wir müssen das einfach selber lernen und können. Also das ist auch tatsächlich was. Wir haben in der Vergangenheit oft Werkzeuge eingekauft, aber es gab hier, ich glaube insbesondere bei heise online und der c’t-Redaktion schon immer ein großes Bedürfnis, auch Sachen selber zu verstehen und selber zu machen. Und mit dem Team, das hier im Haus von heise I/O ein eigenes Tool entwickelt, mit dem man arbeiten kann, haben wir natürlich viel, viel mehr Einfluss darauf, was wir da entwickeln und wie wir das entwickeln und können mit den Kollegen, die daran arbeiten, permanent im Gespräch sein. Und insofern ergibt das total viel Sinn, da auch selbst zu investieren und auch selbst sich Gedanken zu machen, was man eigentlich insbesondere als Medienhaus braucht, aber auch nicht nur als Medienhaus, weil tatsächlich Medienproduzent ist im Prinzip ja inzwischen jeder. Also auch ein Schraubenfabrikant hat im Zweifelsfall irgendeinen Social-Media-Kanal und braucht dafür Inhalte. Das heißt, jeder bewegt sich irgendwie in diesem Bereich. Uns fällt das vielleicht als Redaktion ein bisschen leichter, einen Text zu schreiben. Es hilft uns aber natürlich, auch wenn man mit solchen Tools und auch mit unseren eigenen Tools arbeitet, zum Beispiel Derivate von Inhalten zu erstellen, also aus langen Artikeln andere Formate zu machen. Ich habe einen Artikel geschrieben, der ist zehn Seiten lang, den kann man ganz toll drucken und den kann man auch im Internet sehr gut nutzen, aber der ist noch kein gutes Videoskript und mit der richtigen Unterstützung kann halt auch jemand, der keine große Erfahrung darin hat, Videoskripte zu erstellen, zumindest schon mal so ein Rohkonzept erstellen mit einem guten Prompt. Und da haben wir dann auch nicht das Problem, dass wir uns da inhaltlich Gedanken machen müssen, dass die KI irgendwie Fehler macht, weil der Kollege oder die Kollegin, die den Text geschrieben hat, sitzt halt davor, die sich auskennt und die kann dann auch relativ schnell beurteilen, ist dieses Skript erst mal jetzt so als Basis gut, passt da inhaltlich alles, dann kann man da nochmal drüber gehen und man spart sich da einfach Zeit für Dinge, die dann einfach mehr Spaß machen, das, was ich eben schon sagte. Also letztendlich die Recherche, die richtigen Inhalte aufbereiten, gute Ideen haben, ist halt am Ende wichtiger als drei Stunden an einem Skript rumzuschrauben.</p> <p><strong>Volker</strong>: Da haben wir ja auch ein super Beispiel, fällt mir gerade ein, insbesondere eins, das dich ja selber betrifft, Isabel. Wir haben ja da auch noch einen Anwendungszweck, den ich vorhin unter anderem vergessen hatte. Wir nutzen ja deine digitalisierte oder trainierte Stimme, von der du ja vielleicht auch gleich noch mal was zu sagen kannst. Du sagst ja immer, das bist nicht du, das stimmt. Für uns klingt sie aber sehr ähnlich wie du, weil sie halt eine ähnliche Tonalität und Stimmfarbe etc. hat. Die nutzen wir ja, um zum Beispiel <em>Kurz informiert</em> zu machen, den werktäglichen Podcast von uns, den News-Podcast. Da werden halt aus unseren Nachrichtenartikeln Derivate gemacht, sozusagen als kurze Sprechtexte, und die werden dann wiederum von deiner trainierten Stimme als Podcast wiedergegeben. Und tatsächlich funktioniert das erstaunlich gut. Und hat dir natürlich Zeit verschafft, Dinge, die mehr Spaß machen, zu tun, nämlich zum Beispiel eine Staffel Bits und Böses wieder zumachen oder jetzt zusammen mit dem Kollegen die deutsche Version von Darknet Diaries. Also, das hättest du ja zeitlich überhaupt gar nicht hinbekommen.</p> <p><strong>Isabel</strong>: Oder auch das KI-Update.</p> <p><strong>Volker</strong>: Oder das KI-Update. Ach Gott, ich vergaß. Genau, das KI-Update.</p> <p><strong>Isabel</strong>: Ja, das stimmt. Also, ich glaube, es ist für jeden befremdlich, wenn man die eigene Stimme hört, die nicht wirklich hundertpro die eigene Stimme ist. Ich bin auch sehr froh, dass sie das nicht ist und ich hoffe auch, dass die KI-Stimmen noch möglichst lange so bleiben, dass sie zwar nett sind für so kurze Formate, aber sobald man ihnen länger zuhört, merkt man sehr schnell, dass sie nicht hundertpro verstehen, was sie da erzählen.</p> <h3 id=\"nav_skeptische__3\">Skeptische Neugier: Der Umgang mit neuen Technologien und internen Vorbehalten</h3> <p><strong>Torsten</strong>: Das merkt man aber tatsächlich gerade so, wenn es um eher die Informationsvermittlung geht. Also wenn wir jetzt ein gutes Gespräch führen, dann führe ich das lieber mit einem Menschen und nicht mit einer künstlichen Stimme, ganz klar. Aber ich sitze sehr oft morgens im Auto und höre deine synthetische Stimme und für die kurze Vermittlung von Informationen passt das finde ich ganz gut. Und sich dann darauf zu konzentrieren, also da geht es ja wirklich darum, Nachrichten vorzulesen. Wenn man dann tatsächlich ins Gespräch geht mit Menschen und man diese Zeit dann überhaupt dafür hat, das zu tun, ist es, glaube ich, ein guter Kompromiss, zu sagen, die einfachen kurzen Dinge, die funktionieren so und jetzt führen wir lieber ein Gespräch von Mensch zu Mensch und nicht von KI zu Mensch.</p> <p><strong>Isabel</strong>: Ja, das sehe ich auch so. Und ich hoffe, das bleibt auch noch lange so. Volker, du hattest erzählt, dass dich auch die Bildgeneratoren und so, dass da einfach auch ein privates Interesse und Faszination dabei war. Jetzt kommen fast täglich tausend neue Tools auf den Markt. Wo ist so die Grenze, die ihr zieht, wo ihr sagt, ja, das müssen wir ausprobieren, das wäre total cool und wo ist es zu gefährlich? Davon lassen wir lieber die Finger, Volker.</p> <p><strong>Volker</strong>: Ja, gefährlich wüsste ich jetzt noch nicht unbedingt. Im Prinzip ist es ja auch unsere Aufgabe, diese Sachen zu prüfen. Also auch wenn Dinge da sozusagen veröffentlicht werden, von denen wir erst mal sagen, um Gottes willen, das ist ja grauenhaft oder so. Keine Ahnung. Ich mag jetzt gar kein Beispiel nennen, weil dann habe ich jetzt irgendwie einen Gedanken drin. Aber natürlich ist es unsere Aufgabe als Journalisten, da auch reinzuschauen, zu prüfen. Ist das überhaupt richtig? Gibt's das? Funktioniert das wirklich so? Ist das so kritisch, wie man da jetzt anmerkt? Weil genau diese Problematik ja auch da ist. Du kriegst teilweise lauter Unfug aus der Welt. Das nutzen halt ganz viele Leute und tun so, als hätten sie ganz tolle KI-Tools oder ganz schlimme KI-Tools. Und dann stellt sich manchmal raus, dass das halt überhaupt nicht wahr ist. Deswegen, das ist unsere Aufgabe, so was zu prüfen. Und dann im Zweifel natürlich auch darüber etwas zu schreiben oder in irgendeinem anderen Medienformat zu veröffentlichen. Aber natürlich müssen wir auch vor Dingen warnen. Also das ist natürlich auch völlig klar. Es gibt halt Tools, die für Sexploitation etc. benutzt werden. Da muss man halt vor warnen. Und da muss man vor allem die Leute sozusagen befähigen, solche Dinge zu erkennen und dann auch die richtigen Wege zu finden. Wie melde ich das? Wie gehe ich eigentlich gegen solche Dinge vor? Das sind ja dann Aufgaben des Journalismus, solche Sachen zu klären und im Idealfall dann auch die Politik auf solche Sachen hinzuweisen.</p> <p><strong>Isabel</strong>: Jetzt haben wir gerade bei der c’t viele Kolleginnen und Kollegen, die schon sehr, sehr lange mit dabei sind und die vieles mitgemacht haben und sehr routiniert in ihrer Arbeit und absolute Experten in ihren Feldern sind. Gab es intern bei der Einführung bestimmter Tools Skepsis oder Widerstand gegen die Nutzung von KI? Wie seid ihr damit umgegangen, Torsten?</p> <p><strong>Torsten</strong>: Also Skepsis erwarten wir geradezu, weil ehrlich gesagt, das ist der Job der Leute. Wenn irgendwie neue KI-Tools auf den Markt kommen, dann gibt es eine Neugier bei allen, glaube ich. Und gleichzeitig schwingt da auch immer eine Skepsis mit, nämlich das zu verstehen, was da passiert. Also, weiß ich nicht, Anfang des Jahres, als DeepSeek, die chinesische KI, irgendwie verfügbar wurde, dann ist natürlich erst mal das Okay, man will das ausprobieren, das ist irgendwie spannend und gleichzeitig findet man dann eben auch heraus, dass die chinesische KI Fragen nach dem Platz des himmlischen Friedens irgendwie nicht beantworten mag. An solchen Dingen eben auch, wir gehen da natürlich auch immer mit einer großen Neugier, aber natürlich auch immer mit einem sehr kritischen Blick dran. Ganz ehrlich, alle Menschen, die Inhalte erstellen, bei denen schwingt eine gewisse Beunruhigung mit, braucht man mich in Zukunft noch. Und ich kann da die ganz einfache Antwort darauf geben: Ja, weil Recherchieren, Testen, Menschen anrufen, nachfragen, komplexe Zusammenhänge verstehen und erklären, da kann KI bei helfen, das wird KI so schnell nicht ersetzen können. Und ich verstehe, wenn man da auch durchaus sich gewisse Sorgen macht. Was ich erlebe, ist, dass viele in den Redaktionen Lust haben, damit rumzuprobieren. Das ist keine Altersfrage. Also wir haben hier viele Leute, die sehr, sehr tief in Themen drin sind, die auch sehr, sehr lange dabei sind und für die es ganz normal ist, auch KI als Hilfsmittel zu nutzen oder eben auch tatsächlich KI zu verstehen, zu erklären, Große Sprachmodelle. Also wir sind eben nicht nur Nutzer hier in der Redaktion, sondern wir versuchen natürlich auch, das zu verstehen. Wir kümmern uns auch um die Fragen, auf welcher Hardware läuft das? Wie kann ich das vielleicht zu Hause lokal betreiben? Welche Risiken stecken da drin in Sachen Datenschutz und Sicherheit? Alles rund um die Regulierung, die Abhängigkeit von Tech-Anbietern. Wo findet die KI Kreativitätsgrenzen? Sind wir vielleicht doch an einigen Stellen noch viel kreativer? Also wir probieren damit rum. Und ich glaube gerade hier in den Redaktionen ist sowas wie Skepsis oder auch so eine gesunde, wir gucken uns das erst mal genau an und wir wollen das erst mal komplett verstehen, bevor wir das tatsächlich gut finden. Das gibt es hier schon, aber die Neugier ist auf jeden Fall ganz, ganz groß. Aber ich habe auch in vielen, vielen Runden schon gehört, ja, die KI macht viele Fehler. Und ja, das ist so, deshalb muss man echt gut aufpassen, wo man das einsetzt. Und wenn ich so erlebe, dass Menschen Tools wie ChatGPT wie Suchmaschinen benutzen und sich auf die Antwort, die da rausfällt, verlassen, dann wundert man sich manchmal. Also ich weiß nicht, was habe ich gestern gesehen? Hat jemand Google Gemini gefragt, ist 2026 das Jahr nach 2025? Und die Antwort war nein, weil dieses Jahr ist 2025 und 2026 ist erst das übernächste Jahr.</p> <p><strong>Volker</strong>: Da ist Gemini ja auch besonders gut, also die schaffen echt immer so Klöpse zu bringen, da fällt einem gar nichts mehr zu ein.</p> <h3 id=\"nav_die_schwierige__4\">Die schwierige Messung von Produktivitätsgewinnen</h3> <p><strong>Torsten</strong>: Das sind sicherlich Dinge, die irgendwann auch mal weggehen werden, aber wenn man das halt so sieht, an so ganz einfachen Dingen, je komplexer es wird und je weniger ich selber die Inhalte verstehe, desto anfälliger bin ich dafür, auf Fehlinformationen reinzufallen oder auf Annahmen, die die KI trifft, aber nicht formuliert, reinzufallen. Insofern ist, glaube ich, tatsächlich auch für uns der beste Weg, dass die Leute, die die Inhalte auch erstellt haben, sprich die haben den Artikel geschrieben, die Tools selber nutzen und zum Beispiel daraus, ich sag mal, einen Social-Media-Post generieren oder vielleicht eben ein Skript für ein Video, weil die nämlich eben, die drücken nicht einfach nur auf den Knopf und sagen, ach ja, das ist ja super, was da rausgekommen ist, sondern die können eben auch, weil sie die Experten jeweils in ihren Gebieten sind, sehr schnell übersehen, ob das, was daraus entstanden ist, dann tatsächlich fachlich, inhaltlich auch hilft. Und wenn es bei der Formatierung uns hilft oder weil man vielleicht irgendwie eine Präsentation schnell erstellen kann. Meine Aufgabe ist es nicht, Präsentationen zu erstellen, aber ich muss es trotzdem ständig machen. Ja, und das ist super. Das ist super, wenn ich selber nachdenken kann, aber mir jemand mehr hilft, dass die Präsentation am Ende gut aussieht und gut strukturiert ist, dann kann ich da sehr gut mit leben und ich glaube, das ist auch das, was hier in den Teams so der Blick darauf ist.</p> <p><strong>Isabel</strong>: Jetzt hört man relativ häufig und wir berichten auch im KI-Update immer mal wieder über neue Studien, dass Unternehmen, gerade in Deutschland, KI zwar einsetzen wollen und es auch tun, es aber wahnsinnig schwer ist, irgendeine Art von Produktivitätsgewinn festzustellen. Volker, habt ihr da irgendwie Kennzahlen? Merkt ihr, dass es was bringt oder ist das ein langer, langsamer Prozess?</p> <p><strong>Volker</strong>: Also ich würde erst mal anfangen, warum viele das wahrscheinlich nicht so direkt als Produktivitätsgewinn sehen, ist, weil natürlich die meisten Unternehmen bestimmte Toolsets benutzen, mit denen sie lange Zeit schon arbeiten, und das ist ganz oft natürlich auch aus dem Microsoft-Kosmos, dann hat Microsoft seinen Copilot überall reingesteckt, aber die Produkte, die damit, sag ich mal, erweitert wurden, sind alle noch nicht so ausgereift gewesen, dass es wirklich gut funktioniert. Und dann ist es halt anders als wie bei Torstens Beispiel, wo man jetzt sagt, wow, das ist ja cool, dass man so ein Fünf-Minuten-Erklärvideo kriegt, ohne groß was dafür getan haben zu müssen. Und das ist halt ganz oft in den Standardabläufen ja nicht so. Wenn ich also bestimmte Arbeitsabläufe habe, dann muss die KI ja da den Mehrwert bringen, damit sie entlasten kann. Und das war oft nicht tief genug integriert. Da stellen wir halt auch fest, wir kriegen jetzt erst größere, ich sage mal, Effizienzgewinne eben durch solche unterstützenden Tools, die eben helfen, die Sachen schneller in ein Content-Management-System zu kriegen, wo man das Transkribieren hat, wo man vorher halt Tage oder Stunden dran gesessen hat. An den Stellen sehen wir Produktivitätsgewinne, aber ansonsten ist es so, dass auch je nachdem, in welchem Arbeitsfeld zum Beispiel ein Redakteur bei uns unterwegs ist, da auch die Effizienzgewinne total unterschiedlich sind. Also es kann sein, dass es im Newsroom deutlich leichter ist, Effizienzgewinne zu haben, als zum Beispiel, wenn ich Hardware teste. Da passt KI da erstmal nicht in den Workflow rein. Und dann ist ja auch die Frage, was kann sie denn tun? Und wie Torsten sagte, bei manchen Dingen ist es dann ja auch eine Herausforderung, dass die KI dann auch das tut, was ich eigentlich so möchte, dass sie tut. Und das ist auch was, was man lernen muss. Also deswegen kann ich das nur unterstreichen, was Torsten gesagt hat. Für uns ist es super wichtig, dass wir persönlich mit diesen Dingen umgehen und lernen und auch die Herausforderungen und Schwierigkeiten der KIs sehen. Also an welchen Stellen kommen die einfach nicht weiter. Es ist ja bis heute so, dass die meisten KIs daran scheitern, zu sagen, wie viele 'E's im Wort Erdbeere sind, auf der anderen Seite aber in der Lage sind, Abiklausuren zu lösen. Und das ist halt, ja, das klingt ja erstmal komplett schizophren. Und das ist was, das lernt man nur, man lernt also die Unzulänglichkeiten der KI nur zu verstehen, wenn man mit ihr arbeitet. Und erst dann kann man rausfinden, wie kann ich es eigentlich für meinen eigenen Workflow nutzen. Und ich glaube, das ist einer der Gründe, weswegen so viele erstmal gar nicht Produktivitätsgewinne an irgendeiner Stelle gesehen haben, weil alle gedacht haben, super, KI kann das doch alles, und dann feststellen, so einfach ist das nicht. Man muss halt die KI wirklich dahin zwingen, das zu tun, was man eigentlich braucht, um dann Effizienzgewinne zu sehen. Und das ist, glaube ich, in der Redaktion bei uns genauso und hat deswegen auch länger gedauert, als wir dachten, weil man eben, ja, das Beispiel Social-Media-Post nicht auf jeden übertragen kann. Das funktioniert grundsätzlich, das ist was, wo man sieht, guck mal, da könnte ich was gewinnen. Aber wenn der Redakteur oder die Redakteurin halt ganz andere Aufgaben hat, die in ihrem Alltag die Zeit kosten, dann sieht man halt, dass dieser einzelne Prozess einem nicht viel bringt. Da vertut man sich halt gerne. Deswegen glaube ich, ist es eine Herausforderung.</p> <p><strong>Torsten</strong>: Und wir haben auch tatsächlich in allen Bereichen Probleme, also wir reden jetzt ja über LLMs und wie gehen wir mit Texten und so um. KI kann ja inzwischen schon deutlich mehr, also weiß ich nicht, digitale Zwillinge von Fabriken erstellen und so. Ich glaube, wo alle Unternehmen, die jetzt nicht unbedingt Medienproduktion machen, aber wir sind da natürlich auch von betroffen, im Zweifelsfall erstmal merken, so schnell geht das nicht voran, weil die Schnittstellen letztendlich fehlen und die strukturierten Daten, weil Unternehmen eben bisher nicht in APIs gedacht haben und wie kann ich die Daten untereinander austauschfähig machen und wie bringe ich die zusammen und wie kann das Tool Daten erfassen und sie woanders sichtbar machen. Man hat eher so in einzelnen Lösungen gedacht. Ich will das und das sehen, dafür habe ich das Tool, da gucke ich rein und dann sehe ich das. Wenn man wirklich mit KI da Fortschritte machen will, beziehungsweise auch Effizienzgewinne machen will, dann muss man erstmal diese Daten irgendwie strukturiert zur Verfügung stellen und dann ist es am Ende auch so, wir machen hier hochindividualisierte Dinge. Sehr, sehr unterschiedliche Arten von Themen, sehr, sehr unterschiedliche Themen. Hier kann auch nicht jeder alles, das heißt, jeder ist hier so ein spezielles Rädchen in der großen Maschine. Richtig Spaß, in Anführungsstrichen, macht das erst, wenn sehr viele Leute sehr ähnliche Dinge tun. Also, wenn man irgendwie in einem Unternehmen 500 Controller hat, die dafür sorgen, dass die Zahlen stimmen, dann kann man gut investieren, um da vielleicht irgendwie effizienter zu werden. Diese Art von Skalierung, die hat man in der Redaktion am Ende auch nicht.</p> <h3 id=\"nav_herausforderunge__5\">Herausforderungen für die Medienlandschaft und ein Blick in die Zukunft</h3> <p><strong>Isabel</strong>: Gibt es Tätigkeiten, wo du sagst, Torsten, das bleibt auf jeden Fall in menschlicher Hand?</p> <p><strong>Torsten</strong>: Es bleibt alles in menschlicher Hand. Also überall, wo bei uns ein Text entsteht, da steht immer ein Name drüber und das ist mehr als Human in the Loop, das machen Menschen. Und diese Menschen nutzen, so wie sie einen Stift nutzen und einen Computer nutzen, nutzen sie an einigen Stellen auch KI. Also zum Beispiel, eine Kollegin fährt raus, führt ein Interview, hat davon eine Audioaufzeichnung. Da ist das natürlich ein totaler Gewinn, wenn ich das in eine Maschine reinschmeißen kann und dann kommt da ein strukturierter Text raus, an dem ich arbeiten kann. Und den kann ich dann nochmal glattziehen. Die Leistung ist, das Interview geführt zu haben, kluge Fragen gestellt zu haben, vorher recherchiert zu haben und das am Ende nachher so zusammenzustellen, dass es Spaß macht, das zu lesen. Die Leistung ist ja nicht, das abzutippen. Das heißt, an der Stelle ist das total, total hilfreich. Manchmal ist es einfach hilfreich, eine gute Illustration schnell zu erstellen. Wenn sich da jemand darüber Gedanken macht, was muss denn da abgebildet sein, auf welche Weise, und dafür eine generative Bild-KI nutzt, um nachher eine coole Illustration zu haben, super. Aber wenn es darum geht, einen guten Text zu schreiben, gute Fragen zu stellen, zu recherchieren, zu testen, all das, was uns hier als Redaktion ausmacht, da hilft uns KI tatsächlich auch gar nicht. KI hilft uns dann im Zweifelsfall zum Beispiel, weiß ich nicht, ein Wissenschaftsredakteur, der eine ganze Handvoll Papers lesen muss, der kann so ein Paper erstmal in die KI schmeißen, um mal eine Zusammenfassung zu bekommen, ob das vielleicht irgendwie spannend sein könnte und ob das ihm irgendwie weiterhilft. Und dann kann man tatsächlich da tiefer reingehen. Was nicht passieren wird, ist, dass ein Wissenschaftsredakteur ein Paper irgendwo reinwirft und da fällt dann ein Artikel raus. Das wollen wir nicht und das ist auch nicht unser Anspruch und das ist es ehrlich gesagt auch nicht das, was unsere Leser von uns erwarten. Die erwarten nämlich Einschätzung und die Expertise der Kolleginnen und Kollegen. Ansonsten ist es tatsächlich so, dann braucht man uns nämlich tatsächlich nicht mehr, weil dann kriegt man so ein gesundes Mittelmaß. Das kann dann im Zweifelsfall jeder. Das, was hier an Expertise in der Redaktion ist, das kann eben KI tatsächlich nicht.</p> <p><strong>Isabel</strong>: Volker, wie kennzeichnen wir KI ganz klar? Ab wann kennzeichnen wir KI, wie erkennen unsere Leserinnen und Leser das?</p> <p><strong>Volker</strong>: Also wir kennzeichnen jedes Aufmacherbild, wo KI den wesentlichen Teil erzeugt hat, sozusagen. Und natürlich steht da aber auch dran, wer es dann weiter bearbeitet hat, zum Beispiel. Wenn wir reine KI-Texte haben oder hätten, dann ist das auch so, dass wir das da dran schreiben. Zum Beispiel machen wir das bei Übersetzungen. Wir haben einen Teil von heise online auch auf Englisch übersetzt. Das machen wir auch mithilfe von LLMs. Da guckt danach zwar noch jemand drüber, aber wir schreiben trotzdem extra dann dran, Achtung, diese Artikel sind, ich sag mal, semi-automatisch übersetzt, weil ich meine, zwar guckt einer drüber, aber das Eigentliche ist halt natürlich eine Übersetzung, die eben durch die Maschine passiert ist, da schreiben wir das auch dran. Ansonsten wäre es so, und da ist es immer so ein bisschen schwierig, weil da diskutieren immer alle gerade drüber, wie muss man das eigentlich machen, auch vor dem Hintergrund der Kennzeichnungspflicht, die nächstes Jahr wegen des AI-Acts in Kraft tritt. Wie viel KI darf denn drin sein? Und wir sagen dann immer, okay, wie sollen wir denn das so definieren, dass die Leute nicht sagen, ich darf sie gar nicht nutzen oder ich nutze sie nur noch? Deswegen haben wir halt gesagt, ein Artikel ist immer so, wie es Torsten gesagt hat, die Redaktion, die Redakteure, die da drüber stehen, die haben die Verantwortung. Wir wollen nicht, dass jemand einen kompletten Artikel aus der KI generiert. Die KI ist quasi ein Hilfsmittel und im Prinzip kann man sagen, wir wollen nicht, dass Absätze zum Beispiel komplett aus der KI fallen. Der Artikel soll im Grundgerüst natürlich von dem Menschen auf jeden Fall geschrieben sein. Und es kann nicht sein, dass irgendwie eine KI sozusagen den Artikel vorgibt und ich gucke nur noch einmal drüber und bin fertig. Das kann nicht das Ziel sein. Der Witz ist allerdings, dass sich alle sehr, sehr schwer tun. Ab wann muss man denn diese Kennzeichnung machen? Also ich lese das die ganze Zeit, weil wir das auch für die Redaktion nochmal transparent machen müssen. Da kann man gar keine harten Grenzen nehmen. Man kann nämlich nicht so ein Tool nehmen und sagen, so 30 Prozent dürfen KI sein, das ist halt irgendwie Quatsch. Und deswegen, Torsten hat es ja auch eben schon gesagt, bei uns sitzen Experten für bestimmte Themen und wir haben zum Glück gar nicht die Sorge, dass die Leute auf die Idee kommen zu sagen, ich mach jetzt meinen ganzen Kram mit KI, weil die Arten der Artikel in den allermeisten Fällen sich nicht mit KI schreiben lassen. Aber wie gesagt, man darf sich unterstützen lassen und da muss ich dann auch nicht drüber schreiben, dass es KI gewesen ist. Also zum Beispiel vielleicht als Ergänzung zu Torsten noch. Was KI auch super kann, ist, einen Artikel, den ich geschrieben habe, anschauen, analysieren und feststellen, da hapert es mit dem roten Faden, oder da sind noch Fragen offen, und dann kannst du auf jeden Fall, und das ist, glaube ich, die Maxime von uns, den Artikel besser machen. Also natürlich muss man nicht in jedem Artikel alle Fragen beantworten, dann hat man ein Mammutwerk, das wollen wir gar nicht, aber das inspiriert vielleicht für weitere Recherchen, das inspiriert zu weiteren Artikeln, und das ist das, was uns dann weiterhilft, auch nochmal Fragen zu beantworten, bevor die Leser uns dieselben Fragen stellen. Weil das ist ja das, wir wollen ja nicht, dass die Leute nachher, wenn sie einen Artikel gelesen haben, mit offenen Fragen da stehen. Und das heißt, da hilft die KI natürlich auf jeden Fall weiter. Aber grundsätzlich wollen wir keine KI-generierten Artikel haben, und wenn sie KI-generiert sind, dann kennzeichnen wir es auch. Es gibt ja Artikelformen, wo es durchaus sinnvoll sein könnte, wenn wir sozusagen umformulierte Sachen haben, oder deine KI-Stimme was vorliest. Da ist es ja auch sehr klar, das wird so anmoderiert, dass es die KI-Stimme ist.</p> <p><strong>Isabel</strong>: Kommt KI auch irgendwie bei uns zum Einsatz, um mit den Leserinnen und Lesern besser, unmittelbarer in Kontakt zu treten, Torsten?</p> <p><strong>Torsten</strong>: Ah, jein. Also wir haben so ein kleines Experiment am Laufen. Quasi der heise-Chatbot, der es ermöglicht, auf das Archiv zuzugreifen und quasi das gesammelte Wissen der letzten 40 Jahre zu nutzen und Fragen zu stellen. Und wir denken natürlich darüber nach, wie wir solche Tools auch unseren Lesern sinnvoll zur Verfügung stellen können und wie wir darüber auch Interaktionen schaffen können oder auch andere Einstiegspunkte. Am Ende ist das gar nicht so einfach, weil dieser Anspruch, dass wir coole Produkte machen wollen, wir wollen aber vor allen Dingen auch richtige Inhalte vermitteln. Solange wir das an der Stelle dann nicht garantieren können, tun wir uns dann halt auch wieder, ich sag mal, wir tun uns ein bisschen schwer. Wir sind da nicht einfach so, dass wir sagen, naja, wir veröffentlichen das erstmal, mal gucken, was wohl passiert, sondern wir haben natürlich auch einen Anspruch daran, wenn wir das unseren Lesern, unseren Abonnenten anbieten, dass wir dann sagen, ja, hier hast du auch ein Tool, da kannst du dich genauso drauf verlassen, wie auf das, was du sonst bei uns gewohnt bist. Und das ist noch schwierig.</p> <p><strong>Volker</strong>: Das ist die Frage, ob das überhaupt jemals wirklich vollständig funktionieren kann. Ich glaube, das muss man immer mit einer Prise Salz sehen, was aus der KI rauskommt. Wir können es halt nicht garantieren. Das ist halt nicht deterministisch in dem Sinne. Also schon relativ, aber halt nicht vollständig. Und deswegen ist es halt so ein bisschen doof, wenn man sozusagen Falschantworten erzeugen würde. Und die Leute haben natürlich einen großen Spaß daran. Also wir sind ja nicht nur so in der Redaktion, sondern unsere Leserinnen und Leser sind ja auch so wie wir, so ein bisschen skeptisch, so ein bisschen genauer hinschauend. Und die wollen natürlich dann direkt aus so einem Chatbot rauskitzeln, dass da halt Quatsch bei den Antworten entsteht. Und das macht's natürlich auch nicht einfacher. Also dann kriegen wir das halt um die Ohren gehauen, das Ding.</p> <p><strong>Isabel</strong>: Jetzt hattet ihr schon mal am Anfang erwähnt, die Suche mit KI-Suchmaschinen beziehungsweise KI-Antwortmaschinen macht es für Medienhäuser generell nicht unbedingt einfacher. Würdet ihr euch Regelungen oder Einschränkungen zum Einsatz von KI im Journalismus wünschen, die von staatlicher Seite, von EU-Seite durchgesetzt werden, Torsten?</p> <p><strong>Torsten</strong>: Na ja, wir leben im Moment in einer Zeit, in der Unternehmen die Inhalte von Medien nehmen, sie verarbeiten und ohne jede Quellenangabe, Lizenzierung, Bezahlung verwerten und ihren Kunden wiederum teilweise einfach gegen Geld zur Verfügung stellen. Sprich, unsere Seiten werden gescraped, unsere Inhalte werden gescraped und damit werden Modelle trainiert, die am Ende es überflüssig machen, im dümmsten Fall, zu uns zu kommen. Das ist so das Grundszenario. Und das sieht ein bisschen wie das Ende des Urheberrechts aus, so wie es momentan passiert. Insofern, wenn wir auch in Zukunft noch Journalisten haben wollen und eine unabhängige Presse, dann wird man auch auf regulatorischer Ebene etwas tun müssen, weil so wird das nicht funktionieren. Schlicht und ergreifend, weil es uns dann irgendwann immer schwerer fallen wird, den Journalismus, den wir machen, auch zu bezahlen. Denn hier arbeiten mehr als 100 Leute in der Redaktion, die wir bezahlen wollen und müssen. Und wenn wir diese Expertise auch in Zukunft haben wollen, dann müssen wir die auch anständig bezahlen. Und dementsprechend wird das halt schwierig, wenn da keiner mehr zu uns kommen muss, weil die KI letztendlich einmal unsere Inhalte abgegriffen hat und die paraphrasiert wieder rauswerfen kann. Also ja, es wäre eine gute Idee, und zwar gar nicht so sehr für uns als Unternehmen, aber auch für uns als Gesellschaft, dass wir eine Antwort darauf finden, wie kriegen wir es denn hin, auch in Zukunft Journalismus finanzierbar zu machen? Es wird am Ende nicht reichen, dass irgendwo in irgendeiner KI-Zusammenfassung fünf kleine Links auftauchen. Das ist schon mal besser als nichts. Das wird aber nicht dazu führen, dass man eine Monetarisierung als Unternehmen und als Publisher oder als Verlag hinbekommt, mit der man am Ende auch qualifizierte Journalisten langfristig bezahlen kann.</p> <p><strong>Isabel</strong>: Volker, welche Risiken machen dir denn so am meisten Sorgen? Ist es da mehr die Desinformation, die Halluzination, der Bias oder auch schlicht der Verlust von Vielfalt in der Medienlandschaft?</p> <p><strong>Volker</strong>: Ja, alles. Also relativ, nein, es ist recht einfach zu antworten. Ich wollte nur noch kurz bei dem Thema eben ergänzen. Wir hatten sowas ja in ganz kleinem, im Vergleich dazu, schon vor Jahren, als es nur um die Google Snippets ging. Also Google nimmt sich Texte von uns, zeigt sie in den Suchmaschinen an. Da war aber noch mehr Vorteil für uns als Publisher zu sehen, weil wir sozusagen über die Google Suche Reichweiten erzeugt haben. Das war Googles Argument. Ihr kriegt auch über uns die Reichweiten, also macht euch mal locker und jammert nicht rum, dass wir sozusagen kurze Textausschnitte von euch verwenden. Und das hat sich jetzt natürlich mit dieser AI Overview und jetzt dem AI Mode, der kommt, sehr, sehr stark verändert. Insofern ist es völlig richtig, was Torsten sagt. Wir müssen dagegen was tun, weil die Medienvielfalt, die wäre das Letzte, was verloren geht. Die geht nämlich dann verloren, wenn die ganzen unabhängigen Publisher pleitegehen. Man hat bei dem Leistungsschutzrecht, das man versucht hat, über Jahre einzuklagen, als es nur um die Google-Suchergebnisse ging, gesehen, erstens, das dauert, zweitens, bis so eine Regulation überhaupt greift. Und das, was Google dann nachher draus gemacht hat, ist ein Witz. Also damit kann man halt keinen Ausgleich an der Stelle schaffen, um Leute bezahlen zu können. Und das droht halt jetzt genauso. Und die Medienvielfalt stirbt halt dann, wenn die ganzen Publisher pleitegehen und die unabhängigen Leute das nicht mehr machen können. Davor ist halt das Risiko, dass die Leute gar nicht mehr bei uns ankommen. Das heißt, wenn man die AI-Overviews hat, da kann man noch so oft sagen, guck, da kommt Quatsch raus. Das passiert oft. Dann merken es die Leute auch. Aber in den meisten Fällen, in über 90 Prozent der Fälle, steht da irgendeine Antwort, die erstmal die Leute zufriedenstellt. Mal abgesehen davon, dass alle anderen Suchergebnisse sehr nach unten gedrückt werden in den Ergebnislisten. Das hat ja wahrscheinlich schon jeder mal gesehen. Und das ist halt ein großes Risiko. Damit verdrängst du schon mal die Medienvielfalt. Aber du machst sie vor allem irgendwie nach und nach mürbe, weil sie pleitegehen werden, weil einfach nicht mehr Leute nachkommen und neue Leute einen kennenlernen. Nun ist Google nicht alles, muss man auch sagen, aber alle anderen Suchmaschinenanbieter gehen in eine ähnliche Richtung und damit wird man sehr stark abhängig von Google Discover zum Beispiel. Das ist ja bisher nicht irgendwie KI-getrieben im eigentlichen Sinne, aber sobald Google am Algorithmus schüttelt, das haben wir auch bei Facebook früher gesehen, da sind ganze Medien wieder verschwunden, die darauf gesetzt haben und sich darauf verlassen haben, Google Discover wird es schon richten oder damals Facebook wird es schon richten. Und das ist natürlich ein Risiko für uns alle, und da hat auch Torsten völlig recht, das ist halt nicht nur ein Risiko für die Publisher oder die Medienlandschaft, sondern das ist ein Risiko für die Gesellschaft, was da passiert. Weil im Endeffekt bleibt dann nachher alles und auch die ganze, sag ich mal, Medienkontrolle, die Kontrolle über die Inhalte mehr oder weniger, bei großen Big-Tech-Unternehmen. Und das sind wenige amerikanische Unternehmen, die quasi dann einen Großteil der Informationslandschaft der Welt prägen könnten. Und das finde ich halt ein großes Problem.</p> <p><strong>Isabel</strong>: Ja, auf jeden Fall. Das ist ein bisschen ein deprimierender Schlusspunkt. Darum noch die Frage: Welche Fähigkeiten sollten denn Menschen, die jetzt in den Journalismus gehen wollen, junge Menschen, sich aneignen, um in dieser KI-geprägten Welt gute Journalistinnen und Journalisten werden zu können?</p> <p><strong>Torsten</strong>: Also, ich glaube, erst mal, was Journalisten ausmacht, ist, dass sie neugierig sind, dass sie Lust haben, Dinge auszuprobieren, dass sie sich auch trauen, mit Menschen zu sprechen. Menschen haben ja immer mehr Probleme, einfach zum Telefon zu greifen und mal jemand anzurufen. Insofern hilft das, wenn man das schon mal kann. Und das andere ist halt eben tatsächlich, diese gesunde Skepsis mitzubringen und Lust zu haben, hinter die Dinge zu gucken. Das ist im Grunde genommen egal, ob man im Bereich Politik oder im Bereich Technologie unterwegs ist. Wenn man verstehen will, wie Dinge funktionieren, dann muss man manchmal unter die Motorhaube gucken oder sehr viele Fragen stellen oder sehr viele Daten wälzen. Die Möglichkeiten, die KI uns jetzt bietet, ist tatsächlich, schnell solche Datenmengen zum Beispiel zu beherrschen. Das heißt, mach dich schlau in dem Bereich, mach dich schlau, wie man solche Datenmengen analysiert. Guck dir genau an, was da passiert. Man kann da jetzt noch nicht mal so richtig Tipps geben, welche Tools es gibt, weil es passiert da gerade so viel und das sehen wir ja auch, deshalb machen wir ja auch in so einer hohen Frequenz zum Beispiel einen Podcast zu dem Thema, weil wir einfach merken, hey, da passiert so viel. Das, was du heute gesagt hast, das kannst du morgen schon nicht mehr aufschreiben, weil es schon nicht mehr stimmt. Also ich glaube, es bringt nichts, sich davor zu verschließen. Es bringt auch überhaupt nichts zu sagen, ja, das ist alles doof. Diese Tools und diese Macht auch, die dahinter steckt, die geht nicht wieder weg. Umso mehr braucht es Menschen, die verstehen, wie Dinge funktionieren, die sie erklären können, die auch die Fehler sehen und erklären können. Und ich glaube, gerade Tech-Journalismus ist noch nie spannender gewesen. Also, da passiert so viel. Und gerade, weil Technologie einfach überall ist. Als die c’t angefangen hat, vor über 40 Jahren, da war das wirklich totaler Nerdkram. Da musste man Programmzeilen abtippen und konnte lernen, wie man Platinen ätzt. Heutzutage ist einfach jeder, und zwar wirklich jeder, der irgendeinen Job hat, mit KI irgendwie beschäftigt. Jeder Brotbackautomat hat inzwischen einen Internetanschluss. Und KI wird in viel mehr Lebensbereiche eindringen. Wenn ich irgendwo anrufe, kann ich mir nicht mehr sicher sein, ob da überhaupt ein Mensch noch sitzt oder ob ich da mit einer KI spreche. Jeder braucht auch Informationen dazu. Das heißt, diesen gesamten Komplex zu verstehen und zu hinterfragen, ist etwas, was, finde ich, unglaublich spannend ist und was auch die Arbeit als Journalist für uns weiterhin extrem notwendig und interessant macht, weil wirklich in jedem Lebensbereich werden wir damit konfrontiert und es wird eher mehr als weniger.</p> <p><strong>Isabel</strong>: Das ist ein schöner Schlusspunkt. Damit kann ich auch das Publikum gut in die Weihnachtstage entlassen, denn heute ist das letzte KI-Update in diesem Jahr, aber wir bleiben auch im neuen Jahr neugierig und informieren mit viel Leidenschaft. Danke, dass ihr heute bei mir wart.</p> <p>Das KI-Update startet wieder mit aktuellen Folgen am 05. Januar 2026.</p> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:igr@heise.de\" title=\"Isabel Grünewald\">igr</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11120806","title":"#TGIQF: Das Quiz rund um Computerpionier Konrad Zuse","link":"https://www.heise.de/news/TGIQF-Das-Quiz-rund-um-Konrad-Zuse-11120806.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/TGIQF-Das-Quiz-rund-um-Konrad-Zuse-11120806.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/3/2/9/Overlay_TGIQF_48_-91ed5b35e88d9f94.png\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Mit dem Z3 war Konrad Zuse seiner Zeit voraus: Er erfand den ersten echten Computer. Unser Quiz widmet sich dem IT-Pionier. Knobeln Sie mit!</p>","date":1766145660000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Konrad Zuse, Erfinder des Computers, starb vor 30 Jahren, am 18. Dezember 1995, im Alter von 85 Jahren im hessischen Hünfeld. Mit seinem Z3 schrieb er mitten im Zweiten Weltkrieg Computergeschichte: Das knapp eine Tonne schwere Gerät war ein vollautomatischer Rechner, der in binärer Gleitkommarechnung arbeitete, mit Speicher und Lochstreifen-Programmleser.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Er gilt als erster funktionsfähiger Universalrechner der Welt. Somit realisierte Konrad Zuse das, was sich knapp 100 Jahre vorher Ada Lovelace vorstellte, <a href=\"https://www.heise.de/news/TGIQF-Das-Quiz-rund-um-Ada-Lovelace-Mutter-aller-Programmiernerds-11113583.html\" rel=\"external noopener\" target=\"_blank\">die letzte Woche in unserem Quiz zu Gast war.</a></p> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\" is-open=\"\" media=\"(min-width: 993px)\" toggle-class-on-media=\"a-box--full-bordered\"> </a-collapse> <!-- RSPEAK_START --> <p>Doch ihre Überlegungen waren nicht der Grund, weshalb Zuse den Computer erfand. Was war es stattdessen? Das wollen wir von Ihnen wissen in unserem Quiz rund um Konrad Zuse.</p> <p>In der heiseshow stellte Quizmaster Markus Will der Stammbesatzung um Captain Volker Zota und Malte Kirchner drei Fragen vorab: <a href=\"https://www.youtube.com/live/igtiyvfClQY?si=dyvzXh5gC8Dw2vDr&amp;t=4352\" rel=\"external noopener\" target=\"_blank\">Es gab einen Sieger und eine leichte Gedicht-Eskalation:</a> Und es begab sich in jener Zeit, dass Volker ein von Milliarden Schaltungen geschaffenes Weihnachtsgedicht vortrug, was sogar nach der Sendung in einem weihnachtlichen, wie rockigen Lied vertont wurde.</p> <a-opt-in checkbox-text=\"Umfragen/Quiz immer laden\" type=\"Drid\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein(e) Umfrage/Quiz (Drid GmbH) geladen. </p> <p><label> Umfragen/Quiz immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Drid GmbH) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <p> <a href=\"https://www.heise.de/downloads/18/4/9/9/9/3/2/9/Weihnachtsfrieden_im_Tiefsinnrasch__Version_1_.mp3\" target=\"_blank\"> Download des Lieds als MP3 </a> </p> <p><em><strong>„Weihnachtsfrieden im Tiefsinnrasch</strong></em></p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p><em>Christbaum tanzt,</em><br><em>weiß wie die Kälte in der Uhr.</em><br><em>Schnell – schneller –</em><br><em>die Engel falten Papier aus Schnee.</em></p> <p><em>Frieden tropft,</em><br><em>langsam, tief,</em><br><em>aus einer Kerze,</em><br><em>die das Licht vergisst.</em></p> <p><em>Weihnachten murmelt rückwärts:</em><br><em>naHcethiew, naHcethiew –</em><br><em>ein Echo in kaltem Zimt.</em></p> <p><em>Der Engel reibt sich die Flügel wund,</em><br><em>weil niemand mehr an ihn glaubt,</em><br><em>außer der Christbaum,</em><br><em>der heimlich summt:</em><br><em><strong>Frieden brennt kalt.</strong>“</em></p> <p>Nutzung auf eigene Gefahr. Für Störungen der Besinnlichkeit im Weihnachtsbetrieb kann heise online keine Haftung übernehmen.</p> <p>Sie können in Ruhe in 10 Fragen maximal 100 Punkten erreichen. Die Punktzahl kann gern im Forum mit anderen Mitspielern verglichen werden. Halten Sie sich dabei aber bitte mit Spoilern zurück, um anderen Teilnehmern nicht die Freude am Quiz zu verhageln. Lob und Kritik ist wie immer gern genommen.</p> <p>Bleiben Sie zudem auf dem Laufenden und erfahren Sie das Neueste aus der IT-Welt: Folgen Sie uns bei <a href=\"https://mastodon.social/@heiseonline\" rel=\"external noopener\" target=\"_blank\">Mastodon</a>, auf <a href=\"https://www.facebook.com/heiseonline/\" rel=\"external noopener\" target=\"_blank\">Facebook</a> oder <a href=\"https://www.instagram.com/heiseonline/\" rel=\"external noopener\" target=\"_blank\">Instagram</a>. Und schauen Sie auch gern beim <a href=\"https://federation.network/@heiseBotti\" rel=\"external noopener\" target=\"_blank\">Redaktionsbot Botti</a> vorbei.</p> <p>Und falls Sie Ideen für eigene Quiz haben, schreiben Sie einfach eine Mail an den <a href=\"mailto:mawi@heise.de\">Quizmaster aka Herr der fiesen Fragen</a>.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:mawi@heise.de\" title=\"Markus Will\">mawi</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11120824","title":"Ariane 6 setzt beim fünften Flug Galileo-Satelliten im All aus","link":"https://www.heise.de/news/Ariane-6-setzt-beim-fuenften-Flug-Galileo-Satelliten-im-All-aus-11120824.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Ariane-6-setzt-beim-fuenften-Flug-Galileo-Satelliten-im-All-aus-11120824.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/3/3/8/hp-ca8c3e6bea17475d.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Die europäische Trägerrakete Ariane 6 hat ihren fünften Start erfolgreich absolviert. Sie hat erstmals zwei Galileo-Satelliten in den Orbit transportiert.</p>","date":1766141820000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Das europäische Satellitennavigationssystem Galileo hat Zuwachs durch zwei neue Satelliten bekommen. Ins All gebracht wurden sie von der europäischen Trägerrakete Ariane 6.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Start der Mission VA266 war am 17. Dezember um 6.01 Uhr unserer Zeit vom Startplatz Kourou im französischen Übersee-Departement Französisch-Guayana aus. An Bord hatte sie die Galileo-Satelliten SAT 33 und SAT 34, die das Bremer Raumfahrtunternehmen OHB gebaut hat.</p> <a-opt-in checkbox-text=\"YouTube-Video immer laden\" type=\"Youtube\"> <div> <h2>Empfohlener redaktioneller Inhalt</h2> <p> Mit Ihrer Zustimmung wird hier ein externes YouTube-Video (Google Ireland Limited) geladen. </p> <p><label> YouTube-Video immer laden </label> </p> <p> Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden. Damit können personenbezogene Daten an Drittplattformen (Google Ireland Limited) übermittelt werden. Mehr dazu in unserer <a href=\"https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html\">Datenschutzerklärung</a>. </p> </div> </a-opt-in> <p>Für die Mission war die Rakete mit zwei Boostern ausgestattet – diese Ariane 62 genannte Konfiguration sei eigens für Galileo entwickelt worden, <a href=\"https://www.esa.int/Applications/Satellite_navigation/Galileo_s_first_Ariane_6_launch_strengthens_European_resilience\" rel=\"external noopener\" target=\"_blank\">sagte Toni Tolker-Nielsen</a>, Leiter des Bereichs Raumtransporte bei der Europäischen Raumfahrtagentur (European Space Agency, ESA). Nach knapp vier Stunden habe die Ariane die beiden Satelliten in einer Höhe von etwa 23.000 Kilometern ausgesetzt, <a href=\"https://newsroom.arianespace.com/arianespace-startet-das-satellitenpaar-galileo-l14-erfolgreich-an-bord-einer-ariane-6?lang=deu\" rel=\"external noopener\" target=\"_blank\">teilte Arianespace mit</a>.</p> <h3 id=\"nav_höchster_flug__0\">Höchster Flug der Ariane 6</h3> <p>Der fünfte Flug der Ariane war in doppelter Hinsicht eine Premiere: Es war der erste Start der Ariane 6 für das Galileo-Programm; der Erstflug der Rakete <a href=\"https://www.heise.de/news/Ariane-6-Erstflug-Hilfsantrieb-der-Oberstufe-ausgefallen-9795647.html\">fand im Juli vergangenen Jahres statt</a>. Zudem war es der bislang höchste Flug der Rakete.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die beiden Satelliten sollen in etwa drei Monaten einsatzbereit sein. Dann wird die Galileo-Konstellation aus 29 aktiven Satelliten bestehen. Zwei weitere Starts der Ariane 6 mit je zwei Galileo-Satelliten an Bord sind laut ESA „in naher Zukunft geplant.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>In diesen Missionen werden die letzten vier Galileo-Satelliten der ersten Generation ins All gebracht. „Bald stehen die Galileo-Satelliten der zweiten Generation bereit, die noch genauere und zuverlässigere Ortungs-, Navigations- und Zeitbestimmungsdienste bieten werden“, sagte Francisco-Javier Benedicto Ruiz, Leiter des Bereichs Navigation bei der ESA.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:wpl@heise.de\" title=\"Werner Pluta\">wpl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11120630","title":"Erneuerbare Energien übertreffen Kohle: „Science“ kürt Durchbruch des Jahres","link":"https://www.heise.de/news/Boom-erneuerbarer-Energien-zum-Durchbruch-des-Jahres-gekuert-11120630.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Boom-erneuerbarer-Energien-zum-Durchbruch-des-Jahres-gekuert-11120630.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/2/4/1/shutterstock_2440497807-1e55c5fbc680db1d.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>„Science“ kürt Boom erneuerbarer Energien zum Durchbruch des Jahres 2025. Erstmals lieferten Solar und Wind weltweit mehr Strom als Kohle.</p>","date":1766130600000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <!-- RSPEAK_STOP --> <a-collapse has-indicator=\"\"> </a-collapse> <!-- RSPEAK_START --> <p>Das Wissenschaftsmagazin „Science“ hat den weltweiten Boom <a href=\"https://www.heise.de/thema/Erneuerbare-Energie\">erneuerbarer Energien</a> zum „Durchbruch des Jahres 2025“ gekürt. „Es war das erste Jahr, in dem weltweit mehr Strom aus erneuerbaren Energien – einschließlich Wind- und Solarenergie – erzeugt wurde als aus Kohle“, schreibt der Chefredakteur der „Science“-Journale, Holden Thorp, <a href=\"https://www.science.org/content/article/breakthrough-2025\" rel=\"external noopener\" target=\"_blank\">im Editorial</a>.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die gesamte Situation sei dem Punkt, an dem die weltweiten Emissionen aus fossilen Brennstoffen ihren Höchststand erreichen und anschließend zu sinken beginnen, sehr nahegekommen, so Thorp. „Dieser Meilenstein könnte nun nur noch wenige Jahre entfernt sein.“</p> <h3 id=\"nav_china_als__0\">China als globaler Motor der Energiewende</h3> <p>Viele der Technologien, die zu dem bemerkenswerten Aufstieg der Erneuerbaren geführt hätten, seien in den USA entwickelt worden, „doch die Weiterentwicklung, Perfektionierung und industrielle Fertigung dieser Technologien haben in China stattgefunden.“ China ziehe daraus erhebliche wirtschaftliche Vorteile und liefere 80 Prozent der weltweiten Solarzellen, 70 Prozent der Windturbinen und 70 Prozent der Lithiumbatterien.</p> <p>„China hat dies wirklich gemeistert – mithilfe der Größe seiner Wirtschaft, seiner Fertigungskapazitäten und des harten Wettbewerbs im eigenen Land“, sagte Li Shuo vom <a href=\"https://asiasociety.org/policy-institute\" rel=\"external noopener\" target=\"_blank\">Asia Society Policy Institute</a> dem Fachjournal. So wurden dem „Science“-Beitrag zufolge die Preise für erneuerbare Energien drastisch gesenkt. Dies habe dazu geführt, dass Wind- und Solarenergie in weiten Teilen der Welt zur kostengünstigsten Energiequelle geworden seien.</p> <p>Chinas eigene Energielandschaft habe sich entsprechend gewandelt: Die Solarstromerzeugung sei in den letzten zehn Jahren um mehr als das Zwanzigfache gestiegen. Allein im Jahr 2024 installierte China „Science“ zufolge neue Solar- und Windkapazitäten, die der Leistung von etwa 100 Atomkraftwerken entsprechen.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <h3 id=\"nav_globaler_export__1\">Globaler Export und Energiesicherheit als Treiber</h3> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Chinas stark wachsende Exporte grüner Technologien veränderten „Science“ zufolge auch den Rest der Welt. Länder im Globalen Süden und Europa kauften diese Technologien, um die Energiesicherheit zu erhöhen und Kosten zu senken. Die Importe von Solarmodulen nach Afrika und Südasien sind laut „Science“ stark gestiegen, da die Menschen in diesen Regionen erkannt hätten, dass Solardächer kostengünstig Licht, Handys und Ventilatoren mit Strom versorgen können.</p> <h3 id=\"nav_es_gibt_dennoch__2\">Es gibt dennoch weiter viel Gegenwind</h3> <p>Die Analyse betont jedoch auch, dass trotz des rasanten Fortschritts die globalen Kohlenstoffemissionen weiter ansteigen. Das Ziel, die globale Erwärmung auf 1,5 Grad im Vergleich zum vorindustriellen Zeitraum zu begrenzen, ist zahlreichen Experten zufolge inzwischen unerreichbar.</p> <!-- RSPEAK_STOP --> <div data-component=\"RecommendationBox\"><a-collapse sneak-peek-elements=\"3\" sneak-peek-elements-selector=\"article\"></a-collapse></div> <!-- RSPEAK_START --> <p>Es bleiben laut „Science“ Herausforderungen bestehen: China setze den Bau neuer Kohlekraftwerke fort. Auch politischer Widerstand wie die Handelshemmnisse für chinesische Solarmodule und die Politik der US-Regierung gegen die Entwicklung von Wind- und Solarenergie erschwerten den Fortschritt. Die Infrastruktur, die nötig sei, um Wind- und Solarenergie voll auszuschöpfen, stelle eine weitere Hürde dar.</p> <h3 id=\"nav_hoffnung_auf__3\">Hoffnung auf weiteren Fortschritt</h3> <p>Hoffnung liege dagegen auf technologischem Fortschritt – etwa längeren Rotorblättern für Windturbinen sowie neuen Perowskit-Solarzellen, die in Verbindung mit Silizium mehr Licht einfangen und die Effizienz steigern.</p> <p>Der entscheidende Punkt sei jedoch die Motivation, heißt es in „Science“. Während Käufer im Jahr 2004 noch einen Aufpreis aus Umweltbedenken zahlten, sei heute das Eigeninteresse – durch geringere Kosten und höhere Energiesicherheit – die Hauptantriebskraft. „Diese Änderung der Motivation könnte der wichtigste Durchbruch von allen sein.“</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:afl@heise.de\" title=\"Andreas Floemer\">afl</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"},{"id":"http://heise.de/-11120622","title":"Drohnen weisen tödliches Virus in Walatem nach","link":"https://www.heise.de/news/Drohnen-weisen-toedliches-Virus-in-Walatem-nach-11120622.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag","content":"<p><a href=\"https://www.heise.de/news/Drohnen-weisen-toedliches-Virus-in-Walatem-nach-11120622.html?wt_mc=rss.red.ho.beitrag.atom.beitrag.beitrag\"><img src=\"https://www.heise.de/scale/geometry/450/q80//imgs/18/4/9/9/9/2/3/7/Walinfektion-b9876228aaecfe43.jpeg\" class=\"webfeedsFeaturedVisual\" alt=\"\" /></a></p><p>Mit einer ungewöhnlichen Methode haben Forscher in ausgeblasenem Walatem ein tödliches Virus nachgewiesen: Drohnen fangen Tröpfchen aus dem Walatem ein. </p>","date":1766129220000,"feedTitle":"Heise Wissen","fullContent":"<div id=\"readability-page-1\" class=\"page\"><div dir=\"ltr\"> <p>Ein Zusammenschluss von Wissenschaftlern des King's College London, der Royal (Dick) School of Veterinary, der Nord University und weitere beteiligte Partner haben mit Drohnen im ausgeblasenen Atem frei lebender Wale das potenziell tödliche Virus Cetacean Morbilli entdeckt. Untersucht wurden Buckel-, Pott- und Finnwale in Nordnorwegen. Die Forscher gehen davon aus, dass das Virus oberhalb des Polarkreises verbreitet ist.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Verschiedene Virusarten wie Cetacean Morbillivirus, Herpes, das Vogelgrippevirus (Avian Influenza Virus – AIV) und das Bakterium Brucella spp. werden in Zusammenhang mit teils massenhaften Wal- und Delfinstrandungen im Nordostatlantik gebracht.</p> <p>Um Aufschluss über die Gesundheit von Walen zu erlangen, hat das Forschungsteam eine unorthodoxe Methode gewählt, um die Wale in freier Wildbahn nicht-invasiv zu untersuchen. Die Forscher verwendeten handelsübliche Drohnen, unter denen sterile Petrischalen befestigt waren, um damit über die Blaslöcher auftauchender Wale zu fliegen und Tröpfchen des ausgeblasenen Walatems einzufangen.</p> <p>Wie die <a href=\"https://www.heise.de/thema/Wissenschaft\">Wissenschaftler</a> in der Studie <a href=\"https://link.springer.com/article/10.1186/s12917-025-05152-6\" rel=\"external noopener\" target=\"_blank\">„Deep breath out: molecular survey of selected pathogens in blow and skin biopsies from North Atlantic cetaceans“</a> schreiben, die in BMC Veterinary Research veröffentlicht ist, sei dies eine bahnbrechende Neuerung, um Krankheitserreger bei lebenden Walen ohne Stress oder Schaden festzustellen und zu überwachen. Dadurch können Erkenntnisse über Krankheiten in den sich schnell verändernden Ökosystemen der Arktis gewonnen werden.</p> <p>Zwischen 2016 und 2025 wurden unterschiedliche Proben von lebenden und toten Walen in Form von Blasproben, Hautbiopsien und in einem Fall eine Organprobe entnommen und untersucht. Die Forscher stießen dabei in Buckelwalgruppen in Nordnorwegen, bei einem Pottwal und einem gestrandeten Grindwal in schlechtem Gesundheitszustand auf das Cetacean Morbillivirus, ein hochpathogenes Virus, das Wale und Delfine infizieren kann. Das Virus löst schwere Atemwegserkrankungen und neurologische Immunschäden aus, die zum Tod der Tiere führen können. Entdeckt wurde das Virus erstmals 1987. Damals hatte es ein Massensterben in Walpopulationen ausgelöst.</p> <h3 id=\"nav_ausbreitung__0\">Ausbreitung möglich</h3> <p>Neben dem Cetacean Morbillivirus wurden in den Ausblasproben auch Herpesviren bei Buckelwalen in Norwegen, Island und Kap Verde nachgewiesen. Nicht gefunden wurden dagegen das Vogelgrippevirus und das Brucella-Bakterium. Die Wissenschaftler haben Sorge, dass sich die Viren aufgrund der dichten Winterfutteransammlungen unter den Tieren nun ausbreiten. Wale, Seevögel und Menschen agierten in dieser Zeit eng miteinander.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Um aussagefähige Erkenntnisse sammeln zu können, streben die Forscher eine Langzeitüberwachung der Wale an. Der Ausbruch der Erreger wird auch mit alten und neuen Stressfaktoren in Verbindung gebracht. Deren Auswirkungen könnten mit kontinuierlicher Überwachung der Walgesundheit ermittelt werden.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p>Die Finanzierung der Studie erfolgte durch das King's College London sowie das Research Council of Norway. Die Studie wurde in Kooperation mit der Arctic University of Norway, der University of Iceland und der Umwelteinrichtung BIOS-CV auf Kap Verde erstellt.</p> <!-- RSPEAK_STOP --> <!-- RSPEAK_START --> <p> <!-- RSPEAK_STOP --> <span>(<a href=\"mailto:olb@heise.de\" title=\"Oliver Bünte\">olb</a>)</span> <!-- RSPEAK_START --> </p> <!-- RSPEAK_STOP --> <a-gift has-access=\"\"> </a-gift> </div></div>"}]}